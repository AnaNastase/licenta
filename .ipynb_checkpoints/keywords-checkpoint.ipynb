{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "184c0c36-046b-408e-af72-815a97190459",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "import spacy\n",
    "import pyLDAvis.gensim_models\n",
    "import en_core_web_md\n",
    "from gensim.corpora.dictionary import Dictionary\n",
    "import yake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8c1abff3-4ab1-41c0-a7ab-41e6d12c0133",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read csv\n",
    "authors = pd.read_csv('top_20_authors.csv')\n",
    "publications = pd.read_csv('publications-top_20_authors.csv', sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8f725448-49d4-451d-8590-888e07082835",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a dictionary containing the combined abstracts for each author\n",
    "author_publication_pairs = list(zip(publications['user_id'], publications['abstract_text']))\n",
    "\n",
    "authors_texts = {author_id:\"\" for author_id in authors[\"id\"]}\n",
    "for author_id, abstract in author_publication_pairs:\n",
    "    if abstract and isinstance(abstract, str):\n",
    "        authors_texts[author_id] = authors_texts[author_id] + \"\\n\" + abstract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d9e83d5d-1eb4-44fb-9384-4fcdd3f659bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "In this paper will be applied concepts like amortized complexity or self-adjustment to binary search trees. Motivation comes from the fact that the search trees have multiples drawbacks. It will be developed and analyzed the splay tree, a self-adjusting form of binary search trees.\n",
      "In this paper we introduce a novel spatial exploration and coverage algorithm based on reflex agents using a pheromone map as storage and communication medium. The algorithm proposed in this paper outperforms many of the popular reflex agent exploration algorithms in terms of exploration performance measured as the cumulative path length.\n",
      "This paper addresses the problem of online spatial exploration by using reflex agents controlled by neural networks (multilayer perceptrons) optimized using a form of genetic algorithms in combination with a pheromone map that acts as information storage and exchange medium. We have used a fitness function which also contains information about the structure of the problem and progressively changes with the number of generations, ranging from an emphasis on basic behavior related to obstacle avoidance and moving towards the exploration frontier in the early generations to an emphasis on the exploration performance as the number of generations’ increases. We have shown that the reflex agents optimized using the technique proposed in this paper are capable to solve the exploration problem even with a small number of neurons.\n",
      "In this paper, we propose an exploration algorithm based on a modification of the original node counting algorithm which provides compact spatial Exploration capabilities for reflex agents and it is capable of multi-agent operation by using a pheromone map as information storage and exchange medium. The algorithm proposed in this paper outperforms in terms of cumulative path length all other popular exploration algorithms based on reflex agents that we included in the comparison.\n",
      "In this paper we present a constraint based strategy for collaborative spatial exploration. Using multiple agents and a set of soft constraints modeled as costs we have developed a collaborative system where each agent chooses its next state optimally with respect to compactness and distance based rules, which can model real-world soft constraints. Using random successor state reordering, this exploration system is capable to obtain a stochastic behavior, yet keeping the path planning optimality at each time step. The constraints are imposed at each time step by using graph search algorithms for planning the route to determine the next location that should be visited by the intelligent agent.\n",
      "In this paper we present a brief survey of the ant based multi-agent exploration algorithms and a performance comparison of these algorithms obtained by analyzing them in a variety of scenarios.\n",
      "Large archives of satellite images have been created over time. The existence of these archives enables us to extract evolutions of the same of same geographic area over time, creating satellite image time series (SITS). As SITS represent an amount of information far greater than individual images, their analysis is complex and difficult. In this paper we propose a new unsupervised SITS analysis method based on the latent Dirichlet allocation (LDA) model, a hierarchical model originally developed for text analysis. In this model documents are represented as random mixture of latent topics, each topic being characterized by a distribution over words. This paper extends the use of LDA model for satellite image time series analysis by proposing a description language for SITS modeling according to the LDA model, and is applied on a SITS of 11 Landsat TM scenes acquired in 2007.\n",
      "In this paper we focus on the extraction and analysis of long-term satellite image time series, and on applications in urban development monitoring. A Satellite Image Time Series (SITS) comprised of more than 100 data sets, covering a time span of over 25 years is extracted from the current Landsat data archives, Then we create stacks of intra-annual images, which are analyzed by applying a series of direct multidate classifications in order to extract the annual built-up surface. The evolution of the built-up areas is then compared against population dynamics for the studied area.\n",
      "In this paper we perform land cover classification using hyperspectral data acquired by the EO-1 Hyperion spaceborne platform using Latent Dirichlet Allocation text modeling tool, experiments being carried on a Hyperion data scene acquired on 13 May 2011, covering an agricultural area located east of Bucharest, Romania.\n",
      "In this paper we propose a new method for unsupervised data model discovery in hyperspectral data, by adopting the Latent Dirichlet Allocation (LDA) text modeling tool. The proposed method relies on defining a representation of hyperspectral data that allows LDA analysis, by defining a correspondence between hyperspectral profiles and visual words. As such, we can use Latent Dirichlet Allocation as a method for discovery of latent (intrinsic and natural) meaningful grouping of the spectral bands. Based on the model parameters we propose several use scenarios for hyperspectral data analysis, allowing us to identify semantically meaningful structures in the observed scene. Experiments using the proposed method were carried on an EO-1 Hyperion data set imaging an agricultural area in Romania, acquired in June 2009.\n",
      "In this paper, we present data analytics for a quantitative analysis in a rapid mapping scenario applied for damage assessment of the 2013 floods in Germany and the 2011 tsunami in Japan. These scenarios are created using preand postdisaster TerraSAR-X images and a semi-automated processing chain. All our dataset is tiled into patches and Gabor filters are applied as a primitive feature extraction method to each patch separately. A support vector machine with relevance feedback is implemented in order to group the features into categories. Once all categories are identified, these are semantically annotated using reference data as ground truth. In our investigation, nondamaged and damaged categories were retrieved with their specific taxonomies defined using our previous hierarchical annotation scheme. The classifier supports rapid mapping scenarios (e.g., floods in Germany and tsunami in Japan) and …\n",
      "The ill-defined nature of the segmentation problem makes the selection of the optimal image partition difficult. One can characterize image segmentation as an attempt to find the best possible representation of a data set using a certain number of ldquoobjects.rdquo This can be regarded as data information compression, resulting in the distortion of the original values. Data sets are well represented when the correct number of regions is chosen. The concept behind this approach is similar to the main problem of rate distortion theory: A finite set of code words is chosen to approximate the numbers or source symbols as well as possible. In our approach, the number of regions is equivalent to the number of code words. The mean of a region provides canonical representation of respective group members, and the distortion function is the mean-square error assuring a good evaluation method for image segmentation.\n",
      "The paper presents an information theory approach for change detection, using Earth observation images. Correlation coefficient and Kullback-Leibler divergence are used as similarity measures allowing to find out where did change occur. Further, for an image characterization method, rate distortion theory is implemented to delimitate image complex regions, with high probability to have changed.\n",
      "High level image understanding and content extraction requires image regions analysis to reveal the spatial interaction between them. This paper aims to engender new attributes for scene description considering the relative position of the objects inside. A visual grammar of the scene is built using an extension for a Knowledge Based Image Information Mining system (KIM). The objects are extracted using statistical models and machine learning through the KIM system, according to the user interest. Further, an affine invariant descriptor of the relative position between two objects is computed. This is the force histogram and it is considered to be a spatial signature which characterizes configurations of regions based on the attraction forces between the composing objects. Thereby, new patterns could be defined using similar object configurations, in order to enhance the effectiveness of the content-based image retrieval inside large databases.\n",
      "This paper demonstrates how knowledge driven methods and the associated data analysis algorithms are changing the paradigms of user-data interactions, providing an easier and wider access to the Earth Observation data. Some information theory based algorithms are proposed for anomaly and change detection on SPOT images, relative to a widespread humanitarian crisis scenario: floods. The outcomes of these algorithms define an informational representation of the image, revealing the spatial distribution of a particular theme. Using image analysis and interpretation, the multitude of features from a scene are classified into meaningful classes to create sematic maps.\n",
      "An image can be decomposed into different elementary descriptors depending on the observer interest. Similar techniques as used to understand words, regarded as molecules, formed by combining atoms, are proposed to describe images based on their information content. In this paper, we use primitive feature extraction and clustering to code the image information content. Our purpose is to describe the complexity of the information based on the combinational profile of the clustered primitive features using entropic measures like mutual information and Kullback-Leibler divergence. The developed method is demonstrated to asses image complexity for further applications to improve Earth Observation image analysis for sustainable humanitarian crisis response in risk reduction.\n",
      "Modern knowledge discovery systems, empowered by visual data exploration techniques, enable the user to discover and understand the data content. Considering patch-level processing, the visual exploration of Earth Observation archives aims to identify groups of items sharing similar semantic content. Each patch is further represented by certain descriptors, i.e., spectral signatures or Weber local descriptors, to capture structural signature. Later on, the content of the archive is illustrated by a 3-D projection of the high-dimensional space of the descriptors. Aspiring to prove the visual data mining potential, this letter intends to determine the capability of dimensionality reduction techniques to achieve a meaningful 3-D projection of the high-dimensional space. Several real-world data sets were used, i.e., University of California, Merced Land Use data set and a Landsat 7 Enhanced Thematic Mapper Plus image\n",
      "With a continuous increase in the number of Earth Observation satellites, leading to the development of satellitar image time series (SITS), the number of algorithms for land cover analysis and monitoring has greatly expanded. This paper offers a new perspective in dynamic classification for SITS. Four similarity measures (correlation coefficient, Kullback-Leibler (KL) divergence, conditional information, normalized compression distance (NCD)) based on image pairs from the data are employed, resulting in a series of maps describing different types of changes observed in the original series. The proposed algorithm performs a classification of the newly developed time series using a Latent Dirichlet Allocation model (LDA). This statistical method was originally used for text classification, thus requiring a word, document, corpus analogy with the elements inside the image. The experimental results were computed using 11 Landsat images over the city of Bucharest and surrounding areas.\n",
      "The new European missions Sentinel 1 and Sentinel 2 bring added value to the Earth Observation market for land applications by providing timely high quality products with complementary information. The efficient and effective exploitation of the vast amounts of data already delivered by Sentinel 1, combined with the data delivered by Sentinel 2 is mandatory in order to get improved capabilities for the understanding and modelling of land cover classes dynamic and synergy. In this context, this paper discusses a potential methodology for Sentinel 1 and Sentinel 2 joint analysis and highlights the benefits brought by the increased information yielded by putting together these two kinds of data. To this end, the proposed approach follows the next steps: data pre-processing and registration, data representation and combined feature extraction, data classification and interpretation. The results are emphasized on urban and agricultural areas of high heterogeneity.\n",
      "This paper aims to reveal a methodology used to quantitatively evaluate the impact of an earthquake on a region, considering multi temporal high resolution optical images. The proposed approach was initiated in the frame of GEODIM Project whose goal is to develop a Romanian downstream emergency response service in order to contribute to current disaster and risk management approach based on Earth observation data. The project is focused on developing experimental processing algorithms and mapping products for natural disasters (floods, earthquakes, landslides) damage assessment in urban areas based on very high resolution optical and SAR satellite imagery acquired worldwide. The prospective scenario considers knowledge discovery from pre and post event satellite images by mapping the extracted data features into semantic classes and symbolic representations like ``buildings'', ``vegetation'', ``streets'', ``bare land'' and ``damaged buildings'', etc.\n",
      "The number of hydrological (flood, mass movement), meteorological (tropical storm, extratropical storm, convective storm, local storm), climatological (extreme temperature, drought, wildfire) and geophysical (earthquake, tsunami, volcanic activity) events continue to increases in the last decades at global level. According to different research, statistics and databases (UNISDR, EM-DAT) floods are the most frequent in the last decades worldwide and especially in Romania. On the other hand, the probabilistic hazard results for Romania indicate that, in the future, the highest damages will be produced by floods and earthquakes. In this context, it has become necessary to develop an emergency response service. The emergency service, named GEODIM, integrates the GIS geodatabases: roads, rivers, administrative units, land cover/land use, satellite data (optical and synthetic aperture radar), in-situ measurements, in order to support the disaster management. The Earth Observations data offers the capabilities to monitor the disasters at a large scale, being able to identify areas where the events are not in-situ observed or to monitor large vulnerable areas potentially affected by disasters. The paper presents the downstream emergency response service for disaster hazard in Romania, based on Earth Observation data and other geo-information information.\n",
      "Visual data mining methods are of great importance in exploratory data analysis having a high potential for mining large databases. As the data feature space is generally n-dimensional, visual data mining relies on dimensionality reduction techniques. This is the case for image feature spaces which can be visualized by giving each data point a location in a three dimensional space. This paper aims to present a comparative study of several dimensionality reduction methods considering as input image feature spaces, in order to detemine an optimal visualization method to illustrate the separation of the classes. At the beginning, to check the performance of the envisaged method, an artificial dataset consisting of random vectors describing six, 20-dimensional Gaussian distributions with spaced means and low variances was generated. Further, two real images datasets are used to evaluate the contributions of dimensionality reduction algorithms related to data visualization. The analysis focuses on the PCA, LDA and t-SNE dimensionality reduction techniques. Our tests are performed on images for which the computed features include the color histogram and Weber descriptors. ?? 2015 IEEE.\n",
      "In this paper we present the result of data analytics techniques applied to a database comprising of 32 SLC SM TerraSAR-X images, acquired over the area of Bucharest, Romania. The methodology follows a two step approach. The first stage consists of a coarse identification of potentially changed areas using a supervised learning image annotation tool with relevance feedback. Gabor texture features are used to describe image patches. The patch size is derived as a function of the resolution and pixel spacing of the data. In the second stage we apply an information theory strategy to refine the regions previously shown to exhibit class dynamics within the image stack, with pixel accuracy. Finally, a series of analytical indicators (absolute extent of areas affected by change, class evolution trends, inter-class correlations) are derived, in order to generate a predictive model for the selected test site.\n",
      "Natural hazards such as floods, avalanches, volcanic eruptions or earthquakes inflict losses to human settlements and manmade infrastructure and have negative impact on the local economy and environment. The growing number of satellite missions and space services facilitates the access to information for researches and decision makers. Space imagery offers the necessary support for risk prevention and mitigation, but requires human visual inspection which can be subjective, time consuming and ineffective. This paper aims to prove the efficiency of an intelligent knowledge driven EO information mining system in supporting natural hazards' management, by combining large database systems with visual capabilities. Two scenarios are envisaged both considering damage assessment for natural hazards like earthquakes and tsunami.\n",
      "When we try to understand satellite images, we can apply data mining techniques that include spatial reasoning.\n",
      "Nowadays the earth observation sensors provide images containing detailed information relevant for applications related to hazard or security matters. Unfortunately, image information mining, its interpretation and transformation in products useful to the rescue or decision teams is still a laborious task, effectuated many times by visual inspection and manual annotations of the images, thus not appropriate to react in prerequisite time. This papers presents a data analysis processing chain, which by interactive operations, enables analysis and interpretation of large volumes of images with high accuracy, flexibility and much faster than any existing methods.\n",
      "Land mines left behind from wars worldwide are one of the century's main unsolved problems of war and remain the focus of humanitarian mine detection. Unlike the military demining, only requiring a safe corridor for the troops to move through, the humanitarian demining requires that the entire land area be free of mines, without any hazard to the environment. The detection of mined fields, compared with other scene classification tasks, has a very high complexity. The large number of models and the huge dimensionality of the feature space, mainly for hyperspectral data, make it difficult to select the appropriate data sets and the primitive features of the images by using classical methods. This task can be solved using the information stored in a knowledge based image information mining system. Also, this paper presents remote sensing image processing techniques in order to identify the suspected mined areas.\n",
      "The data mining systems solve the problem of handling Earth Observation archives counting on a feature vectors based description of the data. Increasing the dimensionality of the feature vectors would offer an effective perspective of the dataset's content. The modern systems provide visual exploration of data projecting their high-dimensional feature space in a 3-D space. The dimensionality reduction methods represent the main way to achieve such representation. Several dimensionality reduction methods have been proposed to identify the mapping, bot not all of them retain the same dataset properties. In order to compare their performance, the development of formal measures like Trustworthiness or the measures based on Co-ranking matrix was mandatory. These measures objectively evaluate the similarity between the structure detected in the original and the reduced space. In this paper we evaluate six\n",
      "The content of Earth Observation archives continues to explosively grow generating the need to extract valuable knowledge from these repositories. A traditional approach for remote sensing image retrieval is to compute the similarity between the user's query and the archive using a query by example system. Additionally, effective data mining involves the user into data exploration, making use of his knowledge to initiate and validate new hypothesis. This paper brings into focus a visualization based approach to mining the EO data. This method aims to map the existing data correlations in the multidimensional information space to the spatial correlations revealed by the 3D space. The assessment of the results considers a single and global quality criterion, involving the number of the intrusions and extrusion to reveal the performance of dimensionality reduction methods.\n",
      "Nowadays the Earth Observation sensors provide images containing detailed information relevant for applications related to hazard or security matters. Unfortunately, image information mining, its interpretation and transformation in products useful to the rescue or decision teams is still a laborious task, effectuated many times by visual inspection and manual annotations of the images, thus not appropriate to react in prerequisite time. This papers presents a knowledge based image information mining concept as a tool, which by interactive operations, enables analysis and interpretation of large volumes of images with high accuracy, flexibility and incomparably much faster than any existing methods. Several scenarios are demonstrated to locate floods in the remote sensing images from Southwestern Romania.\n",
      "Selected Papers From the 11th Conference of the Spanish Association for Artificial Intelligence (CAEPIA 2005)-An Autonomous and User-Independent Hand Posture Recognition System for Vision-Based. [REVIEW]Elena Sanchez-Nielsen, Luis Anton-Canalis & Cayetano Guerra-Artal - 2006 - In O. Stock & M. Schaerf (eds.), Lecture Notes in Computer Science. Springer Verlag. pp. 4177--113 Selected Papers From the 11th Conference of the Spanish Association for Artificial Intelligence (CAEPIA 2005)-Tokenising, Stemming and Stopword Removal on Anti-Spam Filtering Domain. [REVIEW]Jose R. Mendez, Eva L. Iglesias, Florentino Fdez-Riverola, Fernando Diaz & Juan M. Corchado - 2006 - In O. Stock & M. Schaerf (eds.), Lecture Notes in Computer Science. Springer Verlag. pp. 449-458 The Use of Information Theory in Epistemology.William F. Harms - 1998 - Philosophy of Science 65 (3):472-501.\n",
      "Nowadays the Earth Observation sensors provide images containing detailed information relevant for applications related to hazard or security matters. Unfortunately, image information mining, its interpretation and transformation in products useful to the rescue or decision teams is still a laborious task, effectuated many times by visual inspection and manual annotations of the images, thus not appropriate to react in prerequisite time.\n",
      "Nowadays the Earth Observation sensors provide images containing detailed information relevant for applications related to hazard or security matters. Unfortunately, the process of EO image analysis, interpretation and transformation in products useful to the rescue or decision teams is still a laborious task, effectuated many times by visual inspection and manual annotations of the images, thus not appropriate to react in prerequisite time. This papers presents alternative solutions based on the use of Knowledge based Image Information Mining (KIM) system as a tool, which by interactive operations, enables analysis and interpretation of large volumes of images with high accuracy, flexibility and incomparably much faster than any existing methods. Several scenarios are demonstrated: floods location in the remote sensing images from South-Western Romania and risk assessment in demining.\n",
      "Exploratory visual analysis is often required to assist human operator to understand and interpret Earth Observation (EO) images. Optimal image representation offers cognitive support in discovering relevant facts about the scene with respect to a particular application. This is of crucial importance for training data sets selection in all Machine Learning tasks, particularly in the design of active learning tools for multispectral (MS) EO data. This paper proposes a deep neural network (DNN) based method to compress, learn and reveal the most significant information included in the spectral bands of EO data in support of relevant visualization for image content analysis. The advanced method uses a DNN to discover the most suggestive pseudo-color representation able to highlight the entire MS image content better than the particular 3 bands selection (R, G, B). We propose the use of information theory and the concept of mutual information to rank the spectral bands based on the amount of information contained, by applying the minimum-redundancy-maximum-relevance (mRMR) criterion on a the image so that we obtain the ranked bands. A DNN stacked autoencoder based paradigm is developed in order to extract and compress in three bands the overall information from the MS EO data. The developed method is demonstrated and validated for Sentinel 2 dataset.\n",
      "Visual exploration is a natural way to understand the content of a data archive. If the data are multidimensional, the dimensionality reduction is an appropriate preprocessing step before the data visualization. In literature, two types of approaches are devoted to dimensionality reduction: feature selection and feature extraction algorithms. Both techniques intend to project a high dimensional space into a new one, with reduced dimensionality, preserving data inherent information. This paper aims to identify the similarity degree between low and high dimensional representations of a data archive using the optimal number of semantic classes as a criterion. This number is estimated based on the rate distortion theory being computed both before and after dimensionality reduction. The projection of the low dimensional space was obtained using one feature selection and six feature extraction methods.\n",
      "The overall goal of this paper is to assess the potential of fully polarimetric SAR data for land-use mapping in the field of ecosystem monitoring. State of the art ecosystems' studies aim at integrating in-situ measurements acquired by smart sensor networks with Earth observation data analysis to ensure data quality services to multiple applications. The near real time observation using optical and SAR data contributes to evaluation of biodiversity threats in a very dynamic environment, Danube floodplain and inland delta. This paper addresses the need for consolidated approaches to extract biodiversity features from polarimetric SAR data. Two overlapping PolSAR images (L-band PALSAR and C-band RadarSAT 2) were classified in an unsupervised manner using the Entropynisotropylpha-Wishart algorithm in order to differentiate between various types of vegetation in the region of Braila Island, Romania, and\n",
      "Data visualization guides the process of indexing and retrieval, strengthening the link between low-level image features and high-level human understanding of image content. In this regard, we have described the semantic content of a multidimensional dataset using its descriptors to derive high-dimensional feature spaces. The dimensionality of these spaces is further reduced to three in order to provide a three-dimensional (3-D) representation of the dataset items. Our main challenge was to identify the transformation that projects the high-dimensional feature set into a 3-D space preserving its semantic content. To overcome this issue, we have compared the efficiency of 11 feature space transformations: one feature selection algorithm and ten dimensionality reduction methods. As long as the dataset properties, during mapping, may differ depending on the chosen algorithm, the performance comparison of\n",
      "Earth observation capabilities are used to respond to major disasters around the world, for humanitarian aid and security. Satellite derived information needs to be used in combination with additional data to be presented in a proper geospatial context for the work of civil protection agencies and relief organizations. This paper aims to reveal a methodology developed to quantitatively evaluate the impact of a natural disaster over a region. The proposed approach was initiated in the frame of GEODIM Project (http://geodim.meteoromania.ro) whose goal is to develop a Romanian downstream emergency response service in order to contribute to current disaster and risk management approach based on Earth observation data. The project is focused on developing experimental processing algorithms and mapping products for natural disasters (floods, earthquakes, landslides) damage assessment in urban areas based on very high resolution optical and SAR satellite imagery acquired worldwide. The usefulness of remote sensing data for natural disasters damage assessment clearly rely on the number of available images, their type and quality and last, but not least, the timeliness of the data sets, or how delayed are the available post disaster images relative to the damaging event. Previous work demonstrated the use of a semi-automated data processing method in order to reveal and determine the area affected by the disaster, considering both qualitative and quantitative approaches. The proposed scenarios consider knowledge discovery from pre and post event EO images by mapping the extracted data features into semantic classes and\n",
      "In SAR (Synthetic Aperture Radar) imagery, a major concern is related to finding a way of classifying the objects retrieved in the data acquisition made by a sensor. Dealing with complex-valued data requires finding an adequate descriptor that will provide enough information about the object captured and, in the end, will determine the type of the object. Taking into consideration the fact that the data acquisition model for SAR is based on chirp signals, an immediate choice for getting the desired features is the Chirplet Transform, which, practically, transforms the time space into a frequency-chirprate space. Therefore, the main purpose of the present paper consists in defining the multi-scale 2-D Chirplet Transform and finding a way of characterizing objects captured in a SAR image by using the method mentioned.\n",
      "This paper demonstrates the performance of a rapid mapping kind of approach considering knowledge discovery from Earth Observation images, to provide information support during response and immediate post-response by delivering products emphasizing the extent and impact of the event, by event understanding any type of natural or man made disaster. Knowledge discovery from Earth Observation images implies mapping low level descriptors (primitive features) extracted from the image into semantic classes in order to provide an interactive method for effective image information mining. In the frame of information theory a communication channel is considered between remote sensing imagery and the user who receive existing information in the data sources, coded as image semantic content. This channel has three components-Data Source Model Generation, Query and Data Mining. Data Source Model Generation uses image content analysis to generate a set of scene’s content descriptors. Further, the Query component involves the user and performs an image retrieval based on image content as query parameter. The query component relies on the Support Vector Machine classifier which is able to group descriptors into relevant semantic classes. The classifier supports rapid mapping scenarios and interactive mapping. The proposed concept is illustrated analyzing Earth Observation images acquired post (SPOT 4 and TerraSAR-X) floods disaster in Romania at the end of July 2008. Hundreds of towns and villages were affected and more than 20,000 people evacuated. The northeastern region of Romania was declared back then …\n",
      "This poster proposes a post disaster evaluation of the damages produced by the tsunami in the Tohuku-oki region considering knowledge discovery from TerraSAR-X (TSX) products, by mapping extracted primitive features into semantic classes, thus assuring an interactive technique for productive information mining. Knowledge discovery from Earth Observation images implies mapping low level descriptors (primitive features) extracted from the image into semantic classes in order to provide an interactive method for effective image information mining. In the frame of information theory a communication channel is considered between remote sensing imagery and the user who receives existing information in the data sources, coded as image semantic content. This channel has three components-Data Source Model Generation, Query and Data Mining. Data Source Model Generation uses image content analysis to generate a set of scene’s content descriptors. Further, the Query component involves the user and performs an image retrieval based on image content as query parameter. The query component relies on the Support Vector Machine classifier which is able to group descriptors into relevant semantic classes. The classifier supports rapid mapping scenarios and interactive mapping. The envisaged data mining process includes three stages: data annotation, data query and quantitative analysis of the results. The Data annotations step considers dataset description, data preparation and data classification in order to perform user annotations.\n",
      "This paper addresses the problem of multitemporal analysis of an available TerraSAR-X data time series covering the Sendai region in order to assess flood extent and damages caused by Tohuku-oki tsunami. Over the last decade the use of Earth Observation satellites to support disaster and emergency relief has considerably grown. In order to fully exploit highresolution satellite images a method based on patches (each image is divided into non-overlapping tiles) is proposed to extract relevant contextual information. The local features of each patch act as a compact content descriptor. Further on, considering the available descriptors, the next step is to cluster the data in order to find similar semantic classes. The concept of query by example is implemented by the mean of SVM classifier. The results include well-defined semantic classes, derived through semiautomatic methods thus developing an effective approach of multitemporal analysis which perfectly completes the classic rapid mapping services.\n",
      "This paper investigates the usefulness of the normalized compression distance (NCD) for image similarity detection. Instead of the direct NCD between images, the paper considers the correlation between NCD based feature vectors extracted for each image. The vectors are derived by computing the NCD between the original image and sequences of translated (rotated) versions. Feature vectors for simple transforms (circular translations on horizontal, vertical, diagonal directions and rotations around image center) and several standard compressors are generated and tested in a very simple experiment of similarity detection between the original image and two filtered versions (median and moving average). The promising vector configurations (geometric transform, lossless compressor) are further tested for similarity detection on the 24 images of the Kodak set subject to some common image processing. While the direct computation of NCD fails to detect image similarity even in the case of simple median and moving average filtering in 3 3 windows, for certain transforms and compressors, the proposed approach appears to provide robustness at similarity detection against smoothing, lossy compression, contrast enhancement, noise addition and some robustness against geometrical transforms (scaling, cropping and rotation). View Full-Text\n",
      "The paper presents a compression method for multichannel remote sensing images. The method is basically a DPCM scheme that uses a new stochastic model adapted for sets of correlated images. The model was tested on 2 sets of data having different spectral characteristics: multispectral/multitemporal data (SPOT-XS) and hyperspectral data (AVIRIS). The compression rates are derived from the Rate Distortion Function. They are compared, on the same basis, with the compression rates obtained by using the classical AR model for images. The new stochastic model is definitely superior when the image set is spectrally correlated. The compression scheme is given in 2 versions: a random order compression algorithm for data retrieval from image archives and a sequential order compression algorithm for image transmission. Both schemes are developed for lossy versions but they can easily be adapted for lossless compression too.\n",
      "Hyperspectral, multispectral and multitemporal satellite images are considered as 3D signals and processed using 3D signal techniques. The third dimension is given by the spectral/temporal channels and the idea to perform a 3D processing is an attempt to take advantage of the correlation existing between these channels in order to achieve higher data compression rates. Two methods are investigated and compared: a 3D linear predictor based on a low order Markov model and a 3D wavelet decomposition procedure. Although the compression rate depends highly on the structure of the data, the 3D algorithms perform always better than the 2D ones. This justifies the use of 3D signal processing techniques in remote sensing applications involving a large number of correlated spectral or temporal channels.\n",
      "Compressive Sensing is an alternative to the acquisition and compression of sparse signals. One of the CS applications is the single pixel camera that reconsiders the conventional imaging systems. The key part of the camera is a Digital Micro-mirror Device (DMD), which is operated by a binary sensing matrix. The paper objective is to evaluate the CS performances in the case of three different binary sensing matrices - Binary Random (BRandom), Binary Sparse (BSparse) and Low Density Parity Check (LDPC) code - and three sparsifying transforms: Discrete Cosine Transform (DCT), Discrete Wavelet Transform (DWT) and Total Variation (TV). The study concerns numeric images and it is done from the perspective of the Rate-Distortion characteristic. The experimental results indicate the couple LDPC - TV as the best solution and proves that visually lossless compression can be obtained by this approach.\n",
      "Spectrometry at submillimeter wavelengths (terahertz frequency range) is a promising field of applications but one which presents significant difficulties. The sources at these domains have generally low power, the measurements are noisy and the resolution of the measured spectra is limited by diffraction. We propose a method to improve the spectral resolution in Hadamard spectroscopy for the submillimeter spectral region. The method involves oversampling the spectrum using multiple shifted acquisitions and deconvolution. In order to find the most appropriate deconvolution method, several known algorithms are evaluated. They are: the Lucy-Richardson algorithm, the Maximum Entropy Method (MEM) and the Wiener filter. MEM proved to be the best one. It outperforms the other tested methods by a percentage over 16%.\n",
      "Remote sensing platforms acquire huge amounts of data every day. As a result, large archives of data have been created. In order to provide access to this data efficient search and retrieval methods have to be developed, such as image information mining systems. In this paper we present a framework for an image information mining system using the Latent Dirichlet Allocation text-mining algorithm to provide a high-level semantic model of data, the search being performed in the LDA model space.\n",
      "In the quest of developing more accurate methodologies for Earth Observation (EO) image retrieval, visualization and information content exploration, a deep understanding of the data being analyzed is needed. In this paper we propose a simple but efficient visual data mining methodology that can be used for these tasks. Our solution consists in a patch-based feature extraction to derive image features and the projection of the achieved high dimensional feature space in a 3D space using dimensionality reduction methods. Gabor, Spectral Histogram and Bag-of-Words descriptors are the features assigned to represent the content of the data while PCA and t-SNE are the methods designed to achieve the 3D representation. The quality of information provided by the 3D visualization of the data depends on the extracted features. Therefore, a Sentinel-2 scene with various thematic classes is used for feature extraction …\n",
      "This paper presents the first SAR imaging results obtained with a fixed ground-based system used in bistatic configuration having the TerraSAR-X satellite as transmitter of opportunity. The system's characteristics and signal processing flow are presented relative to the state of the art. Compared to previous works on bistatic SAR imaging where a significant amount of processing is dedicated to time/frequency synchronization between the satellite transmitter and ground receiver, we show that a bistatic SAR image with only meter-range geographic offset can be obtained using the state vectors from a monostatic image and minimal synchronization efforts consisting in acquisitions triggered by an amplitude threshold and stabilization of the local oscillator with a GPS-disciplined reference. We present the first bistatic image in ground geometry obtained over an area of Bucharest and compare it with a monostatic image\n",
      "In this paper, we propose a bistatic synthetic aperture radar (SAR) imaging procedure using a Sentinel-1 satellite as transmitter of opportunity and a stationary ground receiver. The procedure is designed for the standard operating mode of Sentinel-1 satellites - Terrain Observation with Progressive Scans SAR (TOPSAR) and essentially comprises the synchronization between satellite transmitter and ground receiver and the bistatic focusing algorithm. The proposed imaging method takes into account the particularities imposed by the antenna beam sweep from back to forth (specific for TOPSAR mode) and exploits the position vectors and transmission timestamps annotated in the ancillary data from the monostatic raw image. The methodology is demonstrated with a bistatic acquisition performed with Sentinel-1A over an area of Bucharest city, Romania.\n",
      "This paper presents an electronic target designed for bistatic/monostatic synthetic aperture radar systems. The electronic target features two distinct antennas, so it can have different directions for transmitting and receiving. The electronic target basically receives a signal, down-converts it to baseband, applies a controllable time delay on the complex envelope, up-converts the delayed signal and transmits it towards the receiver of the bistatic/monostatic system. Since the delay is controllable, it can be used as artificial target with adjustable range. Even if the electronic target is placed in a cluttered area, its radar reflection can be moved away from its physical position.\n",
      "The authors present several beat signal synchronisation methods developed in the framework of interferometric frequency modulated continuous wave (FMCW) radars. Their purpose is to determine by post-processing the start moment of the beat signal repetition interval. An uncertainty in computing the beginning of the repetition intervals is translated in a phase error, which limits the radar's interferometric capabilities. The performances of the proposed methods are tested on real data acquired with an FMCW radar platform.\n",
      "With a continuous increase in multi-temporal synthetic aperture radar (SAR) images, leading to enable mapping applications for Earth environmental observation, the number of algorithms for detection of different types of terrain changes has greatly expanded. In this paper, a SAR image change detection method based on normalized compression distance (NCD) is proposed. The procedure mainly consists in dividing two time series images in patches, computing a collection of similarities corresponding to each pair of patches and generating the change map with a histogram-based threshold. The experimental results were computed using 2 Sentinel 1A images over the city of Bucharest, Romania and 2 TerraSAR-X images over the Elbe River and its surrounding area, Germany.\n",
      "This paper makes an analysis of repeat-pass bistatic synthetic aperture radar (SAR) interferometry performed with a stationary ground-based receiver and a satellite as transmitter of opportunity. A numerical approach is developed in order to asses the sensitivity of the repeat-pass across-track bistatic interferometric phase to height (relative to the digital elevation model used for focusing) and displacements (in the bistatic lines of sight, between consecutive acquisitions). Compared to the monostatic case, the conversion from height/displacement to phase is not straightforward and is dependent on the considered geometry. The method is applied for a bistatic SAR interferogram generated over an area of Bucharest city, Romania, using a ground receiver with one imaging channel and Sentinel-1A/B as transmitter of opportunity.\n",
      "In this paper we present the early development of a SAR simulator for ground-based fixed-receiver bistatic geometry. Firstly, we describe the assumptions the simulator is based on, then a short presentation of the mathematical model that lays behind the simulator is given. Furthermore, we give some details about its implementation and finally, we present some results. ?? 2016 IEEE.\n",
      "Land cover changes may have very different nature, e.g., vegetation development, soil erosion, variation of humidity, or damage of buildings, only to enumerate few cases. In addition, synthetic aperture radar (SAR) observations are a doppelganger of the scene, imaging the scene signature rather than the scene itself. To overcome these challenges, SAR change detection methods generally adapt to the particular situations. We present seamless methods based on normalized compression distance (NCD) estimation. NCD is a similarity metric applied directly to the data, thus with no biases induced by feature estimators or classifiers. Since the diversity of changes is huge and extremely hard to derive typical classes, we introduce paradigm based both on an unsupervised and a supervised method. The change detection procedure mainly consists in dividing image dataset in patches, computing a collection of …\n",
      "<jats:p>This paper aims to present the basic functionality of a radar platform for real time monitoring of displacement and vibration. The real time capabilities make the radar platform useful when live monitoring of targets is required. The system is based on the RF analog front-end of a USRP, and the range compression (time-domain cross-correlation) is implemented on the FPGA included in the USRP. Further processing is performed on the host computer to plot real time range profiles, displacements, vibration frequencies spectra and spectrograms (waterfall plots) for long term monitoring. The system is currently in experimental form and the present paper aims to prove its functionality. The precision of this system is estimated (using the 3σ approximation) at 0.6 mm for displacement measurements and 1.8 mm for vibration amplitude measurements.</jats:p>\n",
      "This paper aims at presenting the basic functionality of a radar platform for real-time monitoring of displacement and vibration. The real time capabilities make the radar platform useful when live monitoring of targets is required. The system is based on the RF analog front-end of an USRP, and the range compression (time-domain cross-correlation) is implemented on the FPGA included in the USRP. Further processing is performed on the host computer to plot real time range profiles, displacements, vibration frequencies spectra and spectrograms (waterfall plots) for long term monitoring. The system is currently in experimental form and the present paper aims at proving its functionality. The precision of this system is estimated at 0.6 mm for displacement measurements and 1.8 mm for vibration amplitude measurements. Subjects: Signal Processing (eess. SP) Cite as: arXiv: 1811.05958 [eess. SP] (or arXiv: 1811.05958 v1 [eess. SP] for this version) Submission history From: Andrei Anghel [view email] [v1] Wed, 14 Nov 2018 18: 45: 45 UTC (1,034 KB)\n",
      "This paper presents the first results obtained by repeat-pass bistatic synthetic aperture radar (SAR) interferometry using a fixed C-band ground-based receiver and the Sentinel-1A/B satellites as transmitters of opportunity. The methodology developed to obtain repeat-pass bistatic SAR interferograms uses as input a stack of range compressed bistatic acquisition data and mainly consists in the following stages: raw inter-ferograms computation on a two-dimensional grid in ground geometry, atmospheric phase screen removal and topographic phase compensation. The displacements of a high-rise building were estimated using two stacks of bistatic SAR images acquired between April-June 2017 over an area of Bucharest city, Romania.\n",
      "This paper presents an electronic target designed for synthetic aperture radar systems. The electronic target features distinct antennas for transmitting and receiving. The electronic target basically receives a signal, down-converts it to baseband, applies a controllable time delay on the complex envelope, up-converts the delayed signal and transmits it towards the receiver of the SAR system. Since the delay is controllable, it can be used as artificial target with adjustable range. Even if the electronic target is placed in a cluttered area, its radar reflection can be moved away from its physical position. The performances of the electronic target when used for displacement measurements are evaluated.\n",
      "Ground-based fixed receiver bistatic synthetic aperture radar (SAR) is a technology increasingly used in urban monitoring, complementing and enriching the traditional monostatic SAR, but the acquisition geometry is more complex than in the monostatic case. Hence, in the design and configuration of real bistatic SAR systems simulations are needed. In this regard we have presented in [1] a simulator for this geometry that could be used as a way to explore the possibilities given by this configuration. One of the many SAR applications that could be transposed to the bistatic case is displacement measurement. It can be used in urban and non-urban environments, as a way of monitoring the change in the position of some objects of interest, like dams and buildings, using the interferometric phase obtained from two or more SAR acquisitions. This paper aims to investigate by simulation displacement measurements in ground-based fixed receiver bistatic geometry. ?? 2017 IEEE.\n",
      "This paper presents an advanced approach for land-cover change detection in remote-sensing imagery. Firstly, several supervised neural network change detection techniques have been considered and evaluated versus statistical supervised ones.; the chosen neural network models are Multilayer Perceptron (MLP), Radial Basis Function Neural Network (RBF), and Supervised Self Organizing Map (SOM), whereas the applied statistical classifiers are Bayes and Nearest Neighbor (NN). Secondly, we have investigated the following unsupervised change detection techniques: Self-Organizing Map (SOM)(neural clustering), versus K-means (statistical clustering), and Fuzzy C-means (FCM)(fuzzy clustering). The proposed model of change detection in multispectral satellite images has two main processing stages:(a) feature selection (using one of the three techniques: the concatenation of corresponding pixels (CON), the computation of absolute differences between corresponding pixels (ADIP), and the computation of absolute differences between reflectance ratios of corresponding pixels (ADIRR));(b) classification, using one of the above mentioned supervised or unsupervised models (for the two-class case:” change”,“no change”). The considered techniques are evaluated using a Landsat 7 ETM+ multi-temporal image, corresponding to a set of two images of the same area (400 x 400 pixels) in the region Markaryd, Sweden taken in 2002 and 2006. For model evaluation, a change map provided by the European Environmental Agency was taken as reference; we have used 2000 pixels for training and the rest of 158 000 pixels for test. The best …\n",
      "This paper presents a neural network approach for land-cover change detection in remote-sensing imagery. One has considered the following supervised neural classifiers: Multilayer Perceptron (MLP), Radial Basis Function Neural Network (RBF), and Supervised Self Organizing Map (SOM). For comparison, we have chosen two well-known statistical classifiers (Bayes and Nearest Neighbour (NN)). The proposed model of change detection in multispectral satellite images has two main processing stages:(a) feature selection (using one of the three techniques: concatenation algorithm (CON), the algorithm based on absolute differences of pixels (ADIP), and the algorithm based on difference of reflectance ratios (DIRR));(b) classification, using one of the above mentioned classifiers. The considered techniques are evaluated using a LANDSAT 7 ETM+ multitemporal image, corresponding to a set of two images of the same zone (400 x 400 pixels) in the region Markaryd, Sweden taken in 2002 and 2006. One has the change reference map; we have used 2000 pixels for training and the rest of 158 000 pixels for test. The best experimental result leads to the change detection rate of 88.24% for the test lot, proving the advantage of neural network models over the statistical ones.\n",
      "With a continuous increase in the number of Earth Observation satellites, leading to the development of satellite image time series (SITS), the number of algorithms for land cover analysis and monitoring has greatly expanded. This paper offers a new perspective in dynamic classification for SITS. Four similarity measures (correlation coefficient, Kullback-Leibler divergence, conditional information, and normalized compression distance) based on consecutive image pairs from the data are employed. These measures employ linear dependences, statistical measures, and spatial relationships to compute radiometric, spectral, and texture changes that offer a description for the multitemporal behavior of the SITS. During this process, the original SITS is converted to a change map time series (CMTS), which removes the static information from the data set. The CMTS is analyzed using a latent Dirichlet allocation (LDA) model capable of discovering classes with semantic meaning based on the latent information hidden in the scene. This statistical method was originally used for text classification, thus requiring a word, document, corpus analogy with the elements inside the image. The experimental results were computed using 11 Landsat images over the city of Bucharest and surrounding areas. The LDA model enables us to discover a wide range of scene evolution classes based on the various dynamic behaviors of the land cover. The results are compared with the Corinne Land Cover map. However, this is not a validation method but one that adds static knowledge about the general usage of the analyzed area. In order to help the interpretation of the results, we use several studies on forms of relief, weather forecast, and very high resolution images that can explain the wide range of structures responsible for influencing the dynamic inside the resolution cell.\n",
      "The main objective of this paper is to define an analysis model for high resolution spotlight SAR imagery, which is able to integrate the radiometric, as well as geometric and texture properties of the SAR data, in order to facilitate large data-base queries by informational content indexing of the images. The model proposed in this paper uses the information contained in the spectra of the SAR signal. A scene is described by a number of parameters computed based on Short-Time Fourier Transform. Considering the properties of the spotlight imaging mode, a phase correction algorithm is applied to the images prior to feature extraction. The classification is done using a Bayesian Support Vector Machine classifier. The method allowed for the recognition of more than thirty targets and structures in the scenes. The method is extended on quadpol TerraSAR-X data, where a Clifford-Fourier Transform is employed. This …\n",
      "When natural disasters occur, it is necessary for the authorities to make fast and effective decisions in order to prevent the occurrence of more damage, as well as to find solutions for the affected population that needs to be relocated. Satellite imagery can prove to be a useful instrument in decision support during emergency situations of such nature (floods), and especially SAR data, due to its all weather capabilities. This paper makes an assessment of the utility of satellite radar products (TerraSAR-X and Radarsat) in the frame of emergency situations management. A real case study is presented, where radar data were processed by human specialists on one hand, and automatically on the other hand, using an intelligent information extraction system.\n",
      "This paper addresses the problem of High Resolution Synthetic Aperture Radar (SAR) image semantic annotation using a Knowledge Based Information Mining (KIM) System. The authors propose the assessment of the capabilities of KIM to perform an automatic urban classification on TerraSAR-X data. Four test sites have been used in the experiment to prove that the system is generic and data independent. The performance is evaluated by matching the results with GeoEye optical representations of the selected areas. For the evaluation a number of three classes are presented and discussed (water bodies, green urban areas and tall buildings).\n",
      "Modern space missions equipped with SAR instruments provide high spatial resolution data. In such data features of urban objects, man-made structures, as well as natural targets can be identified. We propose a descriptive model based on the frequency spectra of the complex signal, that integrates the radiometric, geometric, and texture features, for scene and target indexing, to cope with the problem of large database queries and information retrieval. Considering the properties of the Spotlight imaging mode in particular, a phase correction algorithm is applied to the data, prior to feature extraction. The assignation of a particular scene to a certain class is done using a Bayesian Support Vector Machine classifier. The method allowed for the recognition of more than thirty targets and structures in the scenes.\n",
      "This work focuses on monitoring the ground motion and infrastructure stability in an urban environment, namely in the city of Bucharest. The city is located in the southeast of Romania and covers an urban area of about 285 km2. Due to its position on the banks of Dambovita River and high underground water levels, the risk of subsidence in the area is significant. Moreover, its closeness to Vrancea seismic area increases the risk of seismic induced deformation in the area. Bucharest is a fast developing city with the average construction rate of 8-20% new buildings with respect to the existing ones. Consequently, the civil engineering industry faced new challenges related to the need of having taller buildings with deeper underground levels, a developing network of subway lines and more bridges with large diameter pilars’ foundations. All these new works have an important impact upon the upper ground stability.\n",
      "A major drawback of classical SAR interferometry is its sensitivity to temporal and geometric effects, leading to a distortion of the final results. This problem can be solved by using multi-temporal techniques, like the Small Baseline Subset and Persistent Scatterers algorithms. Both use large datasets for monitoring land cover deformation, motion or for DEM generation. Despite the fact that using the Persistent Scatterers technique can lead to a maximization of the number of acquisitions used, the number of persistent points is greatly reduced by a decrease of the coherent values of the targets over time. In this article, the authors propose a method for the selection of temporal persistent points using image subsets that comply with the small baseline rule. This method is further used to increase the accuracy of deformation measurements over the subsets' time span.\n",
      "This paper presents a comparative assessment of Synthetic Aperture Radar interferometric techniques (InSAR) that allow the detection of deformation models along the line-of-sight of the radar. Given the susceptibility of these methods to several limitations that act as noise effects in the interferograms, known as decorrelation phenomena, multi-temporal InSAR techniques have been used for the exploiting of phase information acquired over long time intervals.\n",
      "Efficient long term monitoring of critical infrastructure is a difficult task, due to the presence of decorrelation artifacts, especially in non-urban areas. This tends to be an important drawback, given the errors that appear during the unwrapping phase, leading to unreliable deformation maps. The minimization of the artifacts' influence is performed by enhancing the phase estimate using a spatially adaptive multi-looking algorithm. Subsequently, a deformation estimation of linear motions is performed using a stacking-based approach. Results are presented on a database of 32 SLC SM TerraSAR-X images acquired over the area of Bucharest, Romania.\n",
      "During the past years, SAR techniques like Persistent Scatterer Interferometry (PSInSAR) have provided hyper-precision sensing at very large spatial scales. The continuous improvement in the quality of PS measurements comes from the constant development of new acquisition geometries embedded in various platforms. In this study we make a comparative assessment of the quality, number and density of Persistent Scatterers obtained using data acquired in different geometric configurations implemented on three platforms - ERS, ENVISAT, TerraSAR-X. All results were obtained by considering individual datasets of the same urban area (Bucharest), with a combined period of acquisitions of 22 years. The analysis is performed in terms of incidence angles, baseline, orbit type, look direction and PS dynamic range.\n",
      "Space imagery offers great support in various types of applications. The huge amount of information provided in a remote sensed manner facilitates the analysis of Earth surface. The image content classification is one of the first steps to follow in the data mining process. After forty years of research, this is still a topical and challenging issue. With the improving of the acquisition sensors specifications, the user requirements became more exacting. In order to give a proper solution to this problem, the present paper combines an intelligent knowledge-based information mining system with multispectral high resolution imagery. The presented application intends to provide a user-based classification for the urban area of Bucharest, Romania.\n",
      "Earth observation (EO) has become a valuable source of comprehensive, reliable, and persistent information for a wide number of applications. However, dealing with the complexity of land cover is sometimes difficult, as the variety of EO sensors reflects in the multitude of details recorded in several types of image data. Their properties dictate the category and nature of the perceptible land structures. The data heterogeneity hampers proper understanding, preventing the definition of universal procedures for content exploitation. The main shortcomings are due to the different human and sensor perception on objects, as well as to the lack of coincidence between visual elements and similarities obtained by computation. In order to bridge these sensory and semantic gaps, the paper presents a compound framework for EO image information extraction. The proposed approach acts like a common ground between the user's understanding, who is visually shortsighted to the visible domain, and the machines numerical interpretation of a much wider information. A hierarchical data representation is considered. At first, basic elements are automatically computed. Then, users can enforce their judgement on the data processing results until semantic structures are revealed. This procedure completes a user-machine knowledge transfer. The interaction is formalized as a dialogue, where communication is determined by a set of parameters guiding the computational process at each level of representation. The purpose is to maintain the data-driven observable connected to the level of semantics and to human awareness. The proposed concept offers flexibility and interoperability to users, allowing them to generate those results that best fit their application scenario. The experiments performed on different satellite images demonstrate the ability to increase the performances in case of semantic annotation by adjusting a set of parameters to the particularities of the analyzed data.\n",
      "Continuously expanding high-resolution and very high resolution multispectral image collections, provided by remote sensing satellites, require specific methods and techniques for data analysis and understanding. Even though there are several patch-based approaches for image classification and indexing, none of them are integrated within a standard. Having the goal to develop an MPEG-7 compliant descriptor for patch-based multispectral earth observation image classification and indexing, we propose a new feature extraction method able to extract maximum information from all the available spectral bands that Sentinel 2, the last generation of remote sensing satellites, provides. Using the polar coordinate transformation of the reflectance values, we obtain illumination invariant features, which can be used along with the scalable color descriptor present in MPEG-7 standard. Also, our method proves to enhance land cover classification of the areas affected by clouds and their shadows and provide similar classification results compared with the homogeneous texture descriptor (HTD), spectral histogram (SH), concatenated HTD with SH features, spectral indices (SIs), and bag-of-words-based descriptors, such as bag-of-SIs and bag-of-spectral-values on cloud-free areas.\n",
      "This paper introduces a tool designed to provide an innovative and insightful way of exploring Earth observation data content beyond visualization, by addressing a visual analytics process. The considered framework combines machine learning and visualization techniques, empowered through human interaction, to gain knowledge from the data. The proposed tool- eVADE leverages the methodologies developed in the fields of information retrieval, data mining and knowledge representation by the means of a visual analytics component. eVADE increases users capability to understand and extract meaningful semantic clusters together with quantitative measurements, presented in a suggestive visual way.\n",
      "This poster proposes a post disaster evaluation of the damages produced by the tsunami in the Tohuku-oki region considering knowledge discovery from TerraSAR-X (TSX) products, by mapping extracted primitive features into semantic classes, thus assuring an interactive technique for productive information mining. Knowledge discovery from Earth Observation images implies mapping low level descriptors (primitive features) extracted from the image into semantic classes in order to provide an interactive method for effective image information mining. In the frame of information theory a communication channel is considered between remote sensing imagery and the user who receives existing information in the data sources, coded as image semantic content. This channel has three components - Data Source Model Generation, Query and Data Mining. Data Source Model Generation uses image content analysis to generate a set of scene’s content descriptors. Further, the Query component involves the user and performs an image retrieval based on image content as query parameter. The query component relies on the Support Vector Machine classifier which is able to group descriptors into relevant semantic classes. The classifier supports rapid mapping scenarios and interactive mapping. The envisaged data mining process includes three stages: data annotation, data query and quantitative analysis of the results.The Data annotations step considers dataset description, data preparation and data classification in order to perform user annotations. Some query examples considering several scenarios include: Assessment of the transportation …\n",
      "Recently, various patch-based approaches have emerged for high and very high resolution multispectral image classification and indexing. This comes as a consequence of the most important particularity of multispectral data: objects are represented using several spectral bands that equally influence the classification process. In this letter, by using a patch-based approach, we are aiming at extracting descriptors that capture both spectral information and structural information. Using both the raw texture data and the high spectral resolution provided by the latest sensors, we propose enhanced image descriptors based on Gabor, spectral histograms, spectral indices, and bag-of-words framework. This approach leads to a scene classification that outperforms the results obtained when employing the initial image features. Experimental results on a WorldView-2 scene and also on a test collection of tiles created using Sentinel 2 data are presented. A detailed assessment of speed and precision was provided in comparison with state-of-the-art techniques. The broad applicability is guaranteed as the performances obtained for the two selected data sets are comparable, facilitating the exploration of previous and newly lunched satellite missions.\n",
      "Correctly annotated image datasets are important for developing and validating image mining methods. However, there is some doubt regarding the generalizability of the models trained and validated on available datasets. This is due to dataset biases, which occur when the same semantic label is used in different ways across datasets, and/or when identical object categories are labeled differently across datasets. In this paper, we demonstrate the existence of dataset biases with a sample of eight remote sensing image datasets, first showing they are readily discriminable from a feature perspective, and then demonstrating that a model trained on one dataset is not always valid on others. Past approaches to reducing dataset biases have relied on crowdsourcing, however this is not always an option (e.g., due to public-accessibility restrictions of images), raising the question: How to structure annotation tasks to efficiently and accurately annotate images with a limited number of nonexpert annotators? We propose a collaborative annotation methodology, conducting image annotation experiments where users are placed in either a collaborative or individual condition, and we analyze their annotation performance. Results show the collaborators produce more thorough, precise annotations, requiring less time than the individuals. Collaborators labels show less variance around the consensus point, meaning their assigned labels are more predictable and likely to be generally accepted by other users. Therefore, collaborative image annotation is a promising annotation methodology for creating reliable datasets with a reduced number of nonexpert annotators. This in turn has implications for the creation of less biased image datasets.\n",
      "<jats:p>Synthetic Aperture Radar (SAR) Tomography (TomoSAR) allows extending the 2-D focusing capabilities of SAR to the elevation direction, orthogonal to the azimuth and range. The multi-dimensional extension (along the time) also enables the monitoring of possible scatterer displacements. A key aspect of TomoSAR is the identification, in the presence of noise, of multiple persistent scatterers interfering within the same 2-D (azimuth range plane) pixel. To this aim, the use of multi-look has been shown to provide tangible improvements in the detection of single and double interfering persistent scatterers at the expense of a minor spatial resolution loss. Depending on the system acquisition characteristics, this operation may require also the detection of multiple scatterers interfering at distances lower than the Rayleigh resolution (super-resolution). In this work we further investigated the use of multi-look in TomoSAR for the detection of multiple scatterers located also below the Rayleigh resolution. A solution relying on the Capon filtering was first analyzed, due to its improved capabilities in the separation of the responses of multiple scatterers and sidelobe suppression. Moreover, in the framework of the Generalized Likelihood Ratio Test (GLRT), the single-look support based detection strategy recently proposed in the literature was extended to the multi-look case. Experimental results of tests carried out on two datasets acquired by TerraSAR-X and COSMO-SkyMED sensors are provided to show the performances of the proposed solution as well as the effects of the baseline span of the dataset for the detection capabilities of interfering scatterers.</jats:p>\n",
      "This paper presents a novel framework for multilabel classification of remote sensing images using Error-Correcting Output Codes (ECOC). Starting with a set of primary class labels, the proposed framework consists in transforming the multiclass problem into binary learning subproblems. The distributed output representations of these binary learners are then transformed into primary class labels. In order to obtain robustness with respect to scale, rotation and image content, a Bag-of-Visual Words (BOVW) model based on Scale Invariant Feature Transform (SIFT) descriptors is used for feature extraction. BOVW assumes an a-priori unsupervised learning of a dictionary of visual words over the training set. Experiments are performed on GeoEye-1 images and the results show the effectiveness of the proposed approach towards multilabel classification, if compared to other methods.\n",
      "Synthetic Aperture Radar (SAR) tomography presents the advantage of multiple stable targets detection within same pixel. Fast-sup-GLRT (generalized likelihood ratio test based on support estimation) algorithm proved to be an ideal compromise between detection capabilities and computational complexity. In this work, a multi-look version of this detector which exploits the advantages of Capon estimation is examined. Statistical analysis of estimation and detection processes are conducted to compare the performances of sequential non-linear least-squares (NLLS) search and Capon filtering of projected data for double PS identification. Main objective is to exploit the super-resolution advantages of NLLS method without the risk of multiple stable targets classification from the same scattering contribution. For the last desiderate, an additional verification is included within the detection step.\n",
      "<jats:p>Due to the constant increase in Earth Observation (EO) data collections, the monitoring of land cover is facilitated by the temporal diversity of the satellite images datasets. Due to the capacity of Synthetic Aperture Radar (SAR) sensors to operate independently of sunlight and weather conditions, SAR image time series offer the possibility to form a dataset with almost regular temporal sampling. This paper aims at mining the SAR image time series for an analysis of target’s behavior from the perspective of both temporal evolution and coherence. The authors present a two-level analytical approach envisaging the assessment of global (related to perceivable structures on the ground) and local (related to changes occurred within a perceivable structure on the ground) evolution inside the scene. The Latent Dirichlet Allocation (LDA) model is implemented to identify the categories of evolution present in the analyzed scene, while the statistical and coherent proprieties of the dataset’s images are exploited in order to identify the structures with stable electromagnetic response, the so-called Persistent Scatterers (PS). A comparative study of the two algorithms’ classification results is conducted on ERS and Sentinel-1 data. At global scale, the results fit human perception, as most of the points which can be exploited for Persistent Scatterers Interferometry (PS-InSAR) are classified within the same class, referring to stable structures. At local scale, the LDA classification demands for an extended number of classes (defined through a perplexity-based analysis), enabling further differentiation inside the evolutional character of those stable structures. The comparison against the map of detected PS reveals which classes present higher temporal correlation, determining a stable evolutionary character, opening new perspectives for validation of both PS detection and SITS analysis algorithms.</jats:p>\n",
      "Synthetic Aperture Radars (SAR) are currently one of the most popular systems in the remote sensing domain, being widely utilized in the earth observation field. Their range of applicability extends in both marine and terrestrial regions. In the maritime domain, SAR systems are intensively used for the study of oceanic waves, waves breaking, marine currents, underwater topography, oil stains, for monitoring the glacier's ice flow, and also for ships detection and localization. In the land areas, a class of applications which exploits the coherence propriety of SAR signals is able to retrieve information related to terrain's characteristics, like topography and displacements. In this work, a processing chain for linear deformation rates estimation is presented and implemented on a dataset of 30 SAR images of Buzau and Foc.ani cities regions (Romania). The algorithm is based on identification of targets with stable electromagnetic response, exploiting their temporal coherence to obtain reliable estimates. An iterative phase regression analysis is conducted exclusively in the set of detected stable targets. The main challenge is represented by the estimation of the residual component of the phase, due to its random nature. Main feature of the proposed processing chain consists in the fact that it includes a step for terrain's topography estimation, instead of using an external digital elevation model.\n",
      "Past and current EO (Earth Observation) satellite missions have gathered huge amount of data during the past decades. This offers the opportunity to retrieve significant information concerning the evolution of land cover for almost any point of interest (POI) on Earth's surface. This paper presents the evolution of land cover in the administrative area of Bucharest, Romania, over a time span of 33 years. In order to achieve this goal we use data acquired by multiple EO missions such as: Landsat 5 TM (Thematic Mapper), 7 ETM+ (Enhanced Thematic Mapper Plus), 8 OLI/TIRS (Operational Land Im-ager/Thermal InfraRed Sensor) and Sentinel-2 MSI (Multi-Spectral Instrument). We compute several spectral indexes in order to obtain information regarding the surface coverage evolution for categories such as vegetation, water bodies and build up.\n",
      "In this paper, we demonstrate the concepts of a prototype of a knowledge-driven content-based information mining system produced to manage and explore large volumes of remote sensing image data. The system consists of a computationally intensive offline part and an online interface. The offline part aims at the extraction of primitive image features, their compression, and data reduction, the generation of a completely unsupervised image content-index, and the ingestion of the catalogue entry in the database management system. Then, the user's interests-semantic interpretations of the image content-are linked with Bayesian networks to the content-index. Since this calculation is only based on a few training samples, the link can be computed online, and the complete image archive can be searched for images that contain the defined cover type. Practical applications exemplified with different remote sensing\n",
      "Basic textures as they appear, especially in high resolution SAR images, are affected by multiplicative speckle noise and should be preserved by despeckling algorithms. Sharp edges between different regions and strong scatterers also must be preserved. To despeckle images, the authors use a maximum aposteriori (MAP) estimation of the cross section, choosing between different prior models. The proposed approach uses a Gauss Markov random field (GMRF) model for textured areas and allows an adaptive neighborhood system for edge preservation between uniform areas. In order to obtain the best possible texture reconstruction, an expectation maximization algorithm is used to estimate the texture parameters that provide the highest evidence. Borders between homogeneous areas are detected with a stochastic region-growing algorithm, locally determining the neighborhood system of the Gauss Markov\n",
      "In this letter, we are interested in the annotation of large satellite images, using semantic concepts defined by the user. This annotation task combines a step of supervised classification of patches of the large image and the integration of the spatial information between these patches. Given a training set of images for each concept, learning is based on the latent Dirichlet allocation (LDA) model. This hierarchical model represents each item of a collection as a random mixture of latent topics, where each topic is characterized by a distribution over words. The LDA-based image representation is obtained using simple features extracted from image words. We then exploit the capability of the LDA model to assign probabilities to unseen images, in order to classify the patches of the large image into the semantic concepts, using the maximum-likelihood method. We conduct experiments on panchromatic QuickBird images\n",
      "Deep learning methods such as convolutional neural networks (CNNs) can deliver highly accurate classification results when provided with large enough data sets and respective labels. However, using CNNs along with limited labeled data can be problematic, as this leads to extensive overfitting. In this letter, we propose a novel method by considering a pretrained CNN designed for tackling an entirely different classification problem, namely, the ImageNet challenge, and exploit it to extract an initial set of representations. The derived representations are then transferred into a supervised CNN classifier, along with their class labels, effectively training the system. Through this two-stage framework, we successfully deal with the limited-data problem in an end-to-end processing scheme. Comparative results over the UC Merced Land Use benchmark prove that our method significantly outperforms the previously best stated results, improving the overall accuracy from 83.1% up to 92.4%. Apart from statistical improvements, our method introduces a novel feature fusion algorithm that effectively tackles the large data dimensionality by using a simple and computationally efficient approach.\n",
      "Automatic interpretation of remote-sensing (RS) images and the growing interest for query by image content from large remote-sensing image archives rely on the ability and robustness of information extraction from observed data. In Parts I and II of this article, the authors turn the attention to the modern Bayesian way of thinking and introduce a pragmatic approach to extract structural information from RS images by selecting from a library of a priori models those which best explain the structures within an image. Part I introduces the Bayesian approach and defines the information extraction as a two-level procedure: 1) model fitting, which is the incertitude alleviation over the model parameters, and 2) model selection, which is the incertitude alleviation over the class of models. The superiority of the Bayesian results is commented from an information theoretical perspective. The theoretical assay concludes with the …\n",
      "Object detection is an important and challenging problem in computer vision. Although the past decade has witnessed major advances in object detection in natural scenes, such successes have been slow to aerial imagery, not only because of the huge variation in the scale, orientation and shape of the object instances on the earth's surface, but also due to the scarcity of well-annotated datasets of objects in aerial scenes. To advance object detection research in Earth Vision, also known as Earth Observation and Remote Sensing, we introduce a large-scale Dataset for Object deTection in Aerial images (DOTA). To this end, we collect 2806 aerial images from different sensors and platforms. Each image is of the size about 4000 x 4000 pixels and contains objects exhibiting a wide variety of scales, orientations, and shapes. These DOTA images are then annotated by experts in aerial image interpretation using 15 common object categories. The fully annotated DOTA images contains 188, 282 instances, each of which is labeled by an arbitrary (8 d.o.f.) quadrilateral. To build a baseline for object detection in Earth Vision, we evaluate state-ofthe-art object detection algorithms on DOTA. Experiments demonstrate that DOTA well represents real Earth Vision applications and are quite challenging.\n",
      "We present an end-to-end trainable deep convolutional neural network (DCNN) for semantic segmentation with built-in awareness of semantically meaningful boundaries. Semantic segmentation is a fundamental remote sensing task, and most state-of-the-art methods rely on DCNNs as their workhorse. A major reason for their success is that deep networks learn to accumulate contextual information over very large receptive fields. However, this success comes at a cost, since the associated loss of effective spatial resolution washes out high-frequency details and leads to blurry object boundaries. Here, we propose to counter this effect by combining semantic segmentation with semantically informed edge detection, thus making class boundaries explicit in the model. First, we construct a comparatively simple, memory-efficient model by adding boundary detection to the SEGNET encoder-decoder architecture. Second, we also include boundary detection in FCN-type models and set up a high-end classifier ensemble. We show that boundary detection significantly improves semantic segmentation with CNNs in an end-to-end training scheme. Our best model achieves >90\\% overall accuracy on the ISPRS Vaihingen benchmark. (C) 2017 International Society for Photogrammetry and Remote Sensing, Inc. (ISPRS). Published by Elsevier B.V. All rights reserved.\n",
      "The authors present a concept of interactive learning and probabilistic retrieval of user-specific cover types in a content-based remote sensing image archive. A cover type is incrementally defined via user-provided positive and negative examples. From these examples, the authors infer probabilities of the Bayesian network that link the user interests to a pre-extracted content index. Due to the stochastic nature of the cover type definitions, the database system not only retrieves images according to the estimated coverage but also according to the accuracy of that estimation given the current state of learning. For the latter, they introduce the concept of separability. They expand on the steps of Bayesian inference to compute the application-free content index using a family of data models, and on the description of the stochastic link using hyperparameters. In particular, they focus on the interactive nature of their …\n",
      "<jats:p>This paper describes a deep learning approach to semantic segmentation of very high resolution (aerial) images. Deep neural architectures hold the promise of end-to-end learning from raw images, making heuristic feature design obsolete. Over the last decade this idea has seen a revival, and in recent years deep convolutional neural networks (CNNs) have emerged as the method of choice for a range of image interpretation tasks like visual recognition and object detection. Still, standard CNNs do not lend themselves to per-pixel semantic segmentation, mainly because one of their fundamental principles is to gradually aggregate information over larger and larger image regions, making it hard to disentangle contributions from different pixels. Very recently two extensions of the CNN framework have made it possible to trace the semantic information back to a precise pixel position: deconvolutional network layers undo the spatial downsampling, and Fully Convolution Networks (FCNs) modify the fully connected classification layers of the network in such a way that the location of individual activations remains explicit. We design a FCN which takes as input intensity and range data and, with the help of aggressive deconvolution and recycling of early network layers, converts them into a pixelwise classification at full resolution. We discuss design choices and intricacies of such a network, and demonstrate that an ensemble of several networks achieves excellent results on challenging data such as the &lt;i&gt;ISPRS semantic labeling benchmark&lt;/i&gt;, using only the raw data as input.</jats:p>\n",
      "For pt.I see ibid., p.1431-45 (1998). The authors present Gibbs-Markov random field (GMRF) models as a powerful and robust descriptor of spatial information in typical remote-sensing image data. This class of stochastic image models provides an intuitive description of the image data using parameters of an energy function. For the selection among several nested models and the fit of the model, the authors proceed in two steps of Bayesian inference. This procedure yields the most plausible model and its most likely parameters, which together describe the image content in an optimal way. Its additional application at multiple scales of the image enables the authors to capture all structures being present in complex remote-sensing images. The calculation of the evidences of various models applied to the resulting quasicontinuous image pyramid automatically detects such structures. The authors present examples …\n",
      "This paper deals with the automatic extraction of the road network in dense urban areas using a few-meters-resolution synthetic aperture radar (SAR) images. The first part presents the proposed method, which is an adaptation of previous work to the specific case of urban areas. The major modifications are 1) the clique potentials of the Markov random field that extracts the road network are adapted and 2) a multiscale framework is used. Results on shuttle mission and aerial SAR images with different resolutions are presented. The second part is dedicated to road extraction combining two SAR images taken with different flight directions (orthogonal and antiparallel passes), and the obtained improvement is analyzed.\n",
      "The problem of phase unwrapping of two-dimensional (2-D) phase signals has gained a considerable interest in recent years. It deals with the problem of estimating (reconstructing) an absolute phase from the observation of its noisy principal (wrapped) values. This; is an ill posed problem since many possible solutions correspond to a given observation, Many phase unwrapping algorithms have been proposed relying on different constraints for the phase signal sampling process or the nature (e,g,, smoothness, regularity) of the phase signal, We look at these algorithms from the Bayesian point of view (estimation theory) and analyze the role of the prior assumptions, studying their equivalencies to the regularization constraints already used, This study lead to the development of the two new phase unwrapping algorithms, presented in the last section of this paper, which are able to work in quite difficult conditions of aliasing and noise. The theoretical study of the analyzed schemes is illustrated by some experiments on synthetic phase signals.\n",
      "The progress in information retrieval, computer vision, and image analysis makes it possible to establish very complete bases of algorithms and operators. A specialist in remote sensing or image processing now has the tools that allow him, at least in theory, to configure applications solving complex problems of image understanding. However, in reality, earth observation (EO) data analysis is still performed in a very laborious way at the end of repeated cycles of trial and error. To overcome this, we proposed a novel advanced remote sensing information processing system knowledge-driven information mining (KIM). KIM is based on human-centered concepts (HCCs), which implements new features and functions allowing improved feature extraction, search on a semantic level, the availability of collected knowledge, interactive knowledge discovery, and new visual user interfaces. We assess the HCC methodology …\n",
      "In this paper, a wavelet-based speckle-removing algorithm is represented and tested on synthetic aperture radar (SAR) images. The SAR image is first transformed using a dyadic wavelet transform. The noise in the wavelet-transformed image is modeled as an additive signal-dependent noise with Gaussian distribution. The distribution of a noise-free image in a wavelet domain is modeled as a generalized Gauss-Markov random field (GGMRF). An unsupervised stochastic model-based approach to image denoising is represented. If the observed area is homogeneous, the parameters of the Gaussian distribution and GGMRFs are estimated from incomplete data using mixtures of wavelet coefficients. An expectation-maximization algorithm is used to estimate the parameters of both noisy and noise-free images. The unknown parameters are estimated using image and noise models that are defined in the wavelet domain for heterogeneous areas. Different inter- and intrascale dependences of wavelet coefficients were used to estimate the unknown parameters, The represented wavelet-based method efficiently removes noise from SAR images.\n",
      "During the last decades, satellites have acquired incessantly high-resolution images of many Earth observation sites. New products have arisen from this intensive acquisition process: high-resolution satellite image time-series (SITS). They represent a large data volume with a rich information content and may open a broad range of new applications. This paper presents an information mining concept which enables a user to learn and retrieve spatio-temporal structures in SITS. The concept is based on a hierarchical Bayesian modeling of SITS information content which enables us to link the interest of a user to specific spatio-temporal structures. The hierarchy is composed of two inference steps: an unsupervised modeling of dynamic clusters resulting in a graph of trajectories, and an interactive learning procedure based on graphs which leads to the semantic labeling of spatio-temporal structures. Experiments …\n",
      "This paper brings a solution for bridging the gap between the results of state-of-the-art automatic classification algorithms and high semantic human-defined manually created terminology of cartographic data.Using a recent pure-spectral rule-based fully automatic classifier to define the basic 'vocabulary', we provide a hybrid method to automatically understand and describe semantic rules that link existent mapping data according to different specifications with the end-results of unsupervised computer information mining methods. Following an agreement between the learning model and the cartographic scale implied, we exploit Latent Dirichlet Allocation model (LDA) to map heterogeneous pixels with similar intermediate-level semantic meaning into land cover classes of various mapping products. By discovering the set of rules that explain semantic classes in existent vector systems, we introduce the prototype of an interactive learning loop that uses the concept of direct semantics applied on satellite imagery. We solve a big problem in generating cartographic information layers from a fully automatic classification map and demonstrate it for the typical case of Landsat images.\n",
      "The new generation of spaceborne SAR instruments with meter or submeter resolution finds enormous applications for the observation of urban, industrial, in general of man-made scenes. Thus, targets are not any more observed in isolation, instead the groups of objects, e.g., house, bridge, and road, etc., need to be recognized in their spatial context. This paper proposes a feature extraction method for image patches in order to capture the spatial context. The method is based on the characteristics of the spectra of the SAR data, integrating radiometric, geometric, and texture properties of the SAR image patch. The method is demonstrated for TerraSAR-X High Resolution Spotlight data. To account for the spatial context in which a group of targets is located, it uses an image patch covering typically 200 × 200m 2 of the scene. A comparative evaluation of our descriptors and grey-level co-occurrence matrix (GLCM …\n",
      "We present an algorithmic protocol for the evaluation of a content-based remote sensing image information mining system. In order to provide users fast access to the content of large image databases, the system is composed of two main modules. The first includes computationally intensive algorithms for off-line data ingestion in the archive, image feature extraction, and indexing. The second module consists of a graphical man-machine interface that manages the information fusion for interactive interpretation and the image information mining functions. According to the system architecture, the proposed evaluation methodology aims to determine the objective technical quality of the system and includes subjective human factors as well. Since the query performance of a content-based image retrieval system mainly depends on the datasets stored in the archive, we first analyze the complexity of image data. Then …\n",
      "Compression-based similarity measures are effectively employed in applications on diverse data types with a basically parameter-free approach. Nevertheless, there are problems in applying these techniques to medium-to-large datasets which have been seldom addressed. This paper proposes a similarity measure based on compression with dictionaries, the Fast Compression Distance (FCD), which reduces the complexity of these methods, without degradations in performance. On its basis a content-based color image retrieval system is defined, which can be compared to state-of-the-art methods based on invariant color features. Through the FCD a better understanding of compression-based techniques is achieved, by performing experiments on datasets which are larger than the ones analyzed so far in literature.\n",
      "We present an intelligent satellite information mining system, a next generation architecture to help a user to rapidly gather information about courses of action, a tool to add value and to manage the huge amounts of historical and newly acquired satellite data-sets by giving to experts access to relevant information in an understandable and directly usable form and to provide friendly interfaces for information query and browsing. In a remote sensing image archive the data access by geographical position, time of acquisition or type of sensor is often less important than what is the content of the scene, i.e. structures, objects, scattering properties. Interesting applications involve complicated spatial and structural relationships among image objects.(1)\n",
      "In this paper, we propose to study the dependence of information extraction technique performance on synthetic aperture radar (SAR) imaging parameters and the selected primitive features (PFs). The evaluation is done on TerraSAR-X data, and the interpretation is realized automatically. In the first part of this paper (use case I), the following issues are analyzed: 1) finding the optimal TerraSAR-X products and their limits of variability and 2) retrieving the number of categories/classes that can be extracted from the TerraSAR-X images using the PFs (gray-level co-occurrence matrix, Gabor filters, quadrature mirror filters, and nonlinear short-time Fourier transform). In the second part of this paper (use case II), we investigate the invariance of the products with the orbit direction and incidence angle. On the one hand, the results show that using ascending looking is better than using descending looking with an average accuracy increase of 7%-8%, approximately. On the other hand, the classification accuracy for the incidence angle varies from a lower value of the incidence to an upper value of the incidence angle (depending on the sensor range) with 4%-5%. The test sites are Venice (Italy), Toulouse (France), Berlin (Germany), and Ottawa (Canada) and are covering as much as possible the huge diversity of modes, types, and geometric resolution configuration of the TerraSAR-X. For the evaluation of all these parameters (resolution, features, orbit looking, and incidence angle), the support-vector-machine classifier is considered. To evaluate the accuracy of the classification, the precision/recall metric is calculated. The first contribution of this paper is the evaluation of different PFs (proposed in the literature for different types of images) and adaptation of these for SAR images. These features are compared (based on the accuracy of the classification) for the first time for a multiresolution pyramid specially built for this purpose. During the evaluation, all the classes were annotated, and a semantic meaning was defined for each class. The second main contribution of this paper is the evaluation of the dependence on the patch size, orbit direction, and incidence angle of the TerraSAR-X. This type of evaluation has not been systematically investigated so far. For the evaluation of the optimal patch, two different patch sizes were defined, with the constrained that the size on ground needs to cover a minimum of one object (e. g., 200 x 200 m on ground). This patch size depends also on the parameters of the data such as resolution and pixel spacing. The investigation of orbit looking and incidence angle is very important for indexing large data sets that has a higher variability of these two parameters. These parameters influence the accuracy of the classification (e. g., if the incidence angle is closer to the lower bounds or closer to the upper bound of the satellite sensor range).\n",
      "This paper describes research that seeks to supersede human inductive learning and reasoning in high-level scene understanding and content extraction. Searching for relevant knowledge with a semantic meaning consists mostly in visual human inspection of the data, regardless of the application. The method presented in this paper is an innovation in the field of information retrieval. It aims to discover latent semantic classes containing pairs of objects characterized by a certain spatial positioning. A hierarchical structure is recommended for the image content. This approach is based on a method initially developed for topics discovery in text, applied this time to invariant descriptors of image region or objects configurations. First, invariant spatial signatures are computed for pairs of objects, based on a measure of their interaction, as attributes for describing spatial arrangements inside the scene. Spatial visual words are then defined through a simple classification, extracting new patterns of similar object configurations. Further, the scene is modeled according to these new patterns (spatial visual words) using the latent Dirichlet allocation model into a finite mixture over an underlying set of topics. In the end, some statistics are done to achieve a better understanding of the spatial distributions inside the discovered semantic classes.\n",
      "Advances in the image retrieval (IR) field have contributed to the elaboration of tools for interactive exploration and extraction of the images from huge archives associating the content of the images with semantic meaning. This paper presents an Earth-observation (EO) IR system based on enriched metadata, semantic annotations, and image content called EO retrieval. EO retrieval generates an EO-data model by using automatic feature extraction, processing the EO product metadata, and defining semantics, which later is fully exploited for supporting complex queries. In order to demonstrate the functionality of the system, we have created a semantic catalog of TerraSAR-X as application scenario. The database is composed of 39 high-resolution TerraSAR-X scenes comprising about 50 000 image patches (160 x 160 pixels) with their feature descriptors, 100 of metadata entries for each scene, and about 330 semantic annotations. Many query examples combining semantics, metadata, and image content for full exploitation of the image database are presented.\n",
      "This letter presents synthetic aperture radar (SAR) image despeckling using dyadic wavelet transform. Maximum a posteriori (MAP) estimation is used to despeckle a SAR image in the wavelet domain. A wavelet transformed speckle-free image is approximated with a Gauss–Markov random field, and a Gaussian model is chosen to approximate speckle in the wavelet domain. A speckle-free wavelet coefficient is estimated with Bayesian inference using image and noise model parameters, which produce the highest evidence. The experimental results showed that the despeckling algorithm removes speckle noise in the homogeneous areas better than the state-of-the-art methods, which operate in the wavelet and image domain. The proposed method is very simple and computationally not demanding.\n",
      "With the advent of high-resolution (HR) synthetic aperture radar (SAR) images from satellites like TerraSAR-X and TanDEM-X, interest is now on patch-oriented image categorization in contrast to the pixel-based classification in low-resolution SAR images. SAR image categorization requires the generation of a compact feature descriptor that accurately defines the content of the image patch under consideration. As phase information plays a critical role in SAR images, this paper proposes the use of a chirplet-derived transform, i.e., the fractional Fourier transform (FrFT), for generating a compact feature descriptor for single-look complex (SLC) SAR images. Representing a SAR signal in rotated joint time-frequency planes via the FrFT allows discovering the underlying backscattering phenomenon of the objects on the ground. SAR image projections on different planes of the joint time-frequency space using the FrFT …\n",
      "Users in all domains require information or information-related services that are focused, concise, reliable, low cost and timely and which are provided in forms and formats compatible with the users own activities. In the current Earth Observation (EO) scenario, the archiving centres generally only offer data, images and other low levelproducts. The users needs are being only partially satisfied by a number of, usually small, value-adding companies applying time-consuming (mostly manual) and expensive processes relying on the knowledge of experts to extract information from those data or images. In the future, these processes will become even more difficult to perform and to manage because of the growing diversity of the user communities, the greater sophistication of user needs requiring, for example, the fusion of multi-sensor or EO and non-EO data, and the exponential increase in the volume and complexity of the data archives, due to the rapid increases in:\n",
      "Satellite image time series (SITS) consist of a time sequence of high-resolution spatial data. SITS may contain valuable information, but it may be deeply hidden. This paper addresses the problem of extracting relevant information from SITS based on the information-bottleneck principle. The method depends on suitable model selection, coupled with a rate-distortion analysis for determining the optimal number of clusters. We present how to use this method with the Gauss-Markov random fields and the autobinomial random fields model families in order to characterize the spatio-temporal structures contained in SITS. Experimental results on synthetic data and SITS from SPOT demonstrate the performance of the proposed methodology.\n",
      "This paper proposes a new-wavelet-based synthetic aperture radar (SAR) image despeckling algorithm using the sequential Monte Carlo method. A model-based Bayesian approach is proposed. This paper presents two methods for SAR image despeckling. The first method, called WGGPF, models a prior with Generalized Gaussian (GG) probability density function (pdf) and the second method, called WGMPF, models prior with a Generalized Gaussian Markov random field (GGMRF). The likelihood pdf is modeled using a Gaussian pdf. The GGMRF model is used because it enables texture parameter estimation. The prior is modeled using GG pdf, when texture parameters are not needed. A particle filter is used for drawing particles from the prior for different shape parameters of GG pdf. When the GGMRF prior is used, the particles are drawn from prior in order to estimate noise-free wavelet coefficients and for those coefficients the texture parameter is changed in order to obtain the best textural parameters. The texture parameters are changed for a predefined set of shape parameters of GGMRF. The particles with the highest weights represents the final noise-free estimate with corresponding textural parameters. The despeckling algorithms are compared with the state-of-the-art methods using synthetic and real SAR data. The experimental results show that the proposed despeckling algorithms efficiently remove noise and proposed methods are comparable with the state-of-the-art methods regarding objective measurements. The proposed WGMPF preserves textures of the real, high-resolution SAR images well.\n",
      "This letter presents the despeckling of synthetic aperture radar (SAR) images within the bandelet and contourlet domains. A model-based approach is presented for the despeckling of SAR images. The speckle-reduced estimate is found using the first-order Bayesian inference, and the best model's parameters are estimated using the second-order Bayesian inference. Synthetic and real images are used for evaluating the qualities of the despeckling methods. The experimental results showed that the combination of Bayesian inference and bandelet transform outperforms the contourlet-based despeckling algorithm using synthetic data and objective measurements.\n",
      "Earth observation image-understanding methodologies may be hindered by the assumed data models and the estimated parameters on which they are often heavily dependent. First, the definition of the parameters may negatively affect the quality of the analysis. The parameters could not be captured in all aspects, and those resulting superfluous or not accurately tuned may introduce nuisance in the data. Furthermore, the diversity of the data, as regards sensor type, spatial, spectral, and radiometric resolution, and the variety and regularity of the observed scenes make it difficult to establish enough valid and robust statistical models to describe them. This letter proposes algorithmic information theory-based analysis as a valid solution to overcome these limitations. We will present different applications on satellite images, i.e., clustering, classification, artifact detection, and image time series mining, showing the generalization power of these parameter-free data-driven methods based on the computational complexity analysis.\n",
      "This paper addresses the problem of building an index of compressed object databases. We introduce an informational similarity measure based on the coding length of two part codes. Then, we present a methodology for compressing the database by taking into account interobject redundancies and by using the informational similarity measure. The method produces an index included in the code of the data volume. This index is built such that it contains the minimal sufficient information to discriminate the data-volume objects. Then, we present an optimal two-part coder for compressing spatio-temporal events contained in satellite image time series (SITS). The two-part coder allows us to measure similarity and then to derive an optimal index of SITS spatio-temporal events. The resulting index is representative of the SITS information content and enables queries based on information content.\n",
      "We present a framework for scene understanding from interferometric synthetic aperture radar data that is based on Bayesian machine learning and information extraction and fusion. A generic description of the data in terms of multiple models is automatically generated from the original signals. The obtained feature space is then mapped to user semantics representing urban scene elements in a supervised step. The procedure is applicable at multiple scales. We give examples of urban area classification and building recognition of Shuttle Radar Topography Mission data and of building reconstruction from submetric resolution Intermap data.\n",
      "In order to apply the statistical approach to the classification of multisensor remote sensing data, one of the main problems lies in the estimation of the joint probability density functions (pdfs) f(Xmega (k)) of the data vector X given each class omega (k), due to the difficulty of defining a common statistical model for such heterogeneous data. A possible solution is to adopt non-parametric approaches which rely on the availability of training samples without any assumption about the statistical distributions involved. However, as the multisensor aspect involves generally numerous channels, small training sets make difficult a direct implementation of non-parametric pdf estimation. In this paper, the suitability of the concept of dependence tree for the integration of multisensor information through pdf estimation is investigated. First, this concept, introduced by Chow and Liu, is used to provide an approximation of a pdf defined in an N-dimensional space by a product of N-1 pdfs defined in two-dimensional spaces, representing in terms of graph theoretical interpretation a tree of dependencies. For each land cover class, a dependence tree is generated by minimizing an appropriate closeness measure. Then, a non-parametric estimation of the second order pdfs f(x(j)(j),omega (k)) is carried out through the Parzen approach, based on the implementation of two-dimensional Gaussian kernels. In this way, it is possible to reduce the complexity of the estimation, while capturing a significant part of the interdependence among variables. A comparative study with two other non-parametric multisensor data fusion methods, namely: the Multilayer Perceptron (MLP) and K-nearest neighbors (K-nn) methods, is reported. Experimental results carried out on a multisensor (ATM and SAR) data set show the interesting performances of the fusion method based on dependence trees with the advantage of a reduced computational cost with respect to the two other methods.\n",
      "The increasing number and resolution of earth observation (EO) imaging sensors has had a significant impact on both the acquired image data volume and the information content in images. There is consequently a strong need for highly efficient search tools for EO image databases and for search methods to automatically identify and recognize structures within EO images. Content Based Image Retrieval (CBIR) and automatic image annotation systems have been designed to tackle the problem of image retrieval in large image databases. These two systems achieve a common goal, that is to learn the mapping function between low-level visual features and high-level image semantics. A setup, which has hardly been explored in annotating systems and which is the rule rather than the exception, is the case when the training database used to learn the mapping function is not exhaustive regarding semantic …\n",
      "With the advent of very high resolution (VHR) synthetic aperture radar (SAR) images, local content description is becoming a critical issue for indexing. Conventional SAR image analysis techniques, like segmentation and pixel-level classification, are likely to fail as high-level semantic description should be considered for better discrimination. Therefore, we propose to use image-patch-based analysis method for SAR image interpretation. Inspired by ratio edge detector, in this letter, a new feature extraction method represented by the mean ratios in different directions is proposed for VHR SAR image content characterization. Based on the mean ratio, two simple yet powerful and robust features are proposed for SAR image patch indexing. One is the bag-of-word model using not only the basic statistics, i.e., local mean and variance, but also the mean ratios in different directions. The second one is an adaptation of the Weber local descriptor to SAR images by substituting the gradient with the ratio of mean differences in vertical and horizontal directions. To evaluate the proposed features, image patch indexing based on active learning using a SAR image database consisting of high-resolution TerraSAR-X patches is performed. Comparison with the state-of-the-art features, particularly texture features, has shown improved performance for SAR image categorization.\n",
      "Intelligent query and retrieval techniques from remote sensing archives become more and more important with the increasing number of satellites in orbit acquiring more and more data. At the same time the increasing resolution of the sensors produces images of higher complexity. To allow easy access to this information, thus to enhance usage of the data, content-based query techniques are mandatory.We present the structure of a new intelligent remote sensing image archive providing query by image content. First we capture the information in the image using a family of robust signal models which are not selected according to a certain application but instead are able to describe the information in a condensed way. In a next level of information processing the images in the archive are clustered using conjectural models. Finally, the application-oriented user query is answered on a semantic level. In this way, users of various fields of remote sensing applications are able to see their data in the archive.\n",
      "The large volume of detailed land cover features, provided by high resolution Earth observation (EO) images, has attracted considerable interest in the discovery of these features by learning systems. In this letter, we perform latent Dirichlet allocation on the bag of words (BoW) representation of collections of EO image patches to discover their semantic-level features, the so-called topics. To assess the discovered topics, the images are represented based on the occurrence of different topics, called bag of topics (BoT). The value added by BoT to the BoW model of image patches is then measured based on existing human annotations of the data. In our experiments, we compare the classification accuracy results of BoT and BoW representations of two different remote sensing image data sets, a multispectral optical data set and a synthetic-aperture-radar data set. Experimental results demonstrate that BoT can …\n",
      "In order to obtain focused inverse synthetic aperture radar (ISAR) images, an accurate translational motion compensation is required. The phase adjustment step corresponds to. ne compensation and must be properly designed. The authors introduce the Renyi entropy for autofocusing ISAR images. The Renyi entropy of order alpha is a generalisation of the standard Shannon entropy. When alpha tends to be the unity, the Renyi entropy tends to be the Shannon entropy. Here, we ---demonstrate-that-minimising-the-Renyi-entropy-for-alpha = 2 is equivalent to maximising the contrast for ISAR autofocusing. Furthermore, it is also shown that maximising the peak value is equivalent to minimising the Renyi entropy for alpha tending to infinity. On the other hand, the authors propose to minimise the Renyi ---entropy-with-alpha = 0.5 to reconstruct an accurate ISAR image. Simulated data have been used to verify that, in terms of mean squared ---error,-the-proposed-method-with-alpha = 0.5 outperforms other autofocusing algorithms such as the method based on contrast maximisation or the one based on the minimisation of the standard Shannon entropy. The method has also been applied to real data.\n",
      "With the launch of the German TerraSAR-X system in June 2007, a new generation of high-resolution spaceborne synthetic aperture radar (SAR) data is available, which should facilitate the interpretation of urban environments. Our overall objective in this letter is to provide a semiautomatic tool for urban area interpretation using SAR data. We propose in this letter to fuse different automatic object extractors in order to provide more reliable pieces of interpretation. Our fusion is a coarseto- fine approach. First, a segmentation of the image is performed to partition the scene into regions having similar properties. The second step consists in detecting bright and dark linear structures which are, in general, linked to the presence of buildings and roads (main classes in urban areas), respectively. The last step gives the final image interpretation using contextual knowledge. Evaluation of the proposed approach in mapping urban areas was carried out using real TerraSAR-X data over the city of Las Vegas in the U. S.\n",
      "Synthetic aperture radar (SAR) images are affected by multiplicative noise called speckle. This noise makes automatic image classification and image interpretation difficult. Thus, many methods have been developed to remove speckle from SAR images while preserving the useful information of the scene such as texture and geometry. In this letter, a comparison between three different despeckling methods based on a Bayesian approach and Gibbs random fields is made. The used methods are Gauss-Markov random field (GMRF) and autobinomial modeling, which operate in the image domain, and the GMRF approach, which operates in the wavelet domain. Our methods are evaluated with synthetic and real SAR data (TerraSAR-X images). The experimental results show that, with these three methods, the speckle is well removed while structures are preserved; quantitative measures show that the autobinomial method provides the best smoothness and sharpness criteria in real SAR data, while the wavelet-based method generates the smallest bias.\n",
      "Nonnegative Matrix Factorization (NMF) has been widely used for different purposes such as feature learning, dictionary leaning and dimensionality reduction in data mining and computer vision. In this work, we present a label constrained NMF, namely Discriminative Nonnegative Matrix Factorization (DNMF), which utilizes the label information of a fraction of the data as a discriminative constraint. The labeled samples are used in a regularization term, which is a linear regression based on the samples, coupled with the main objective function of NMF. In contrast to recently proposed semi-supervised NMF techniques, the proposed approach does not merge the samples with the same label into a single point. However, the algorithm enforces the samples with the same label to be aligned on the same axis in the new representation. The performed experiments on synthetic and real datasets expose the strength of our proposed method compared to the state-of-the-art methods. (C) 2015 Elsevier B.V. All rights reserved.\n",
      "In the context of multi-temporal SAR change detection for earth monitoring applications, one critical issue is to generate accurate change map. A common method to generate change map is to apply logarithm to the ratio image. However, due to the speckle effect and without consideration of contextual information, it is usually not efficient for accurate change detection. In this paper, an unsupervised change detection method in wavelet domain based on statistical wavelet subband modeling is proposed. The motivation is to capture textures efficiently in wavelet domain. Wavelet transform is applied to decompose the image into multiple scales and probability density function of the coefficient magnitudes of each subband assumed to be Generalized Gaussian Distribution (GGD) and Generalized Gamma Distribution (G) are obtained by fast parameter estimation. Closed-form expression of Kullback-Leibler divergence …\n",
      "Speckle hinders information in synthetic aperture radar (SAR) images and makes automatic information extraction very difficult. The Bayesian approach allows us to perform the despeckling of an image while preserving its texture and structures. This model-based approach relies on a prior model of the scene. This paper presents an evaluation of two despeckling and texture extraction model-based methods using the two levels of Bayesian inference. The first method uses a Gauss-Markov random field as prior, and the second is based on an auto-binomial model (ABM). Both methods calculate a maximum a posteriori and determine the best model using an evidence maximization algorithm. Our evaluation approach assesses the quality of the image by means of the despeckling and texture extraction qualities. The proposed objective measures are used to quantify the despeckling performances of these methods …\n",
      "Presently Earth Observation (EO) satellites acquire huge volumes of high resolution images very much over-passing the capacity of the users to access the information content of the acquired data. Thus, in addition to the existing methods for EO data and information extraction, new methods and tools are needed to explore and help to discover the information hidden in large EO image repositories. This article presents a categorisation based Relevance Feedback (RF) search engine for EO images repositories The developed method is presented as well results obtained for a SPOT5 satellite image database.\n",
      "Currently, the amount of collected Earth Observation (EO) data is increasing considerably with a rate of several Terabytes of data per day. As a consequence of this increasing data volume, new concepts for exploration and information retrieval are urgently needed. To this end, we propose to explore satellite image data via an image information mining (IIM) approach in which the main steps are feature extraction, classification, semantic annotation, and interactive query processing. This leads to a new process chain and a robust taxonomy for the retrieved categories capitalizing on human interaction and judgment. We concentrated on land cover categories that can be retrieved from high-resolution synthetic aperture radar (SAR) images of the spaceborne TerraSAR-X instrument, where we annotated different urban areas all over the world and defined a taxonomy element for each prevailing surface cover category. The annotation resulted from a test dataset comprising more than 100 scenes covering diverse areas of Africa, Asia, Europe, the Middle East, and North and South America. The scenes were grouped into several collections with similar source areas and each collection was processed separately in order to discern regional characteristics. In the first processing step, each scene was tiled into patches. Then the features were extracted from each patch by a Gabor filter bank and a support vector machine with relevance feedback classifying the feature sets into user-oriented land cover categories. Finally, the categories were semantically annotated using Google Earth for ground truthing. The annotation followed a multilevel approach that allowed the fusion of information being visible on different resolution levels. The novelty of this paper lies in the fact that a semantic annotation was performed with a large number of high-resolution radar images that allowed the definition of more than 850 surface cover categories. This opens the way toward an automated identification and classification of urban areas, infrastructure (e.g., airports), geographic objects (e.g., mountains), industrial installations, military compounds, vegetation, and agriculture. Applications that may result from this work can be a semantic catalog of urban images to be used in crisis situations or after a disaster. In addition, the proposed taxonomies can become a basis for building a semantic catalog of satellite images. Finally, we defined four powerful types of high-level queries. Querying on such high levels provides new opportunities for users to search an image database for specific parameters or semantic relationships.\n",
      "The Hierarchical Segmentation (HSEG) algorithm is an approach for producing high quality, hierarchically related image segmentations. The VisiMine image information mining system utilizes clustering and segmentation algorithms for reducing visual information in multispectral images to a manageable size. The project discussed herein seeks to enhance the VisiMine system through incorporating hierarchical segmentations from HSEG into the VisiMine system.\n",
      "SAR images have shown to be of high complexity and to require dedicated processing techniques. This paper presents two applications of the wavelet and multiresolution theory to the enhancement and characterization of SAR data. The rst application describes an improved method for speckle reduction. The second method uses a fractal-based texture measure to provide elements for SAR image segmentation. The methods have been applied to airborne C-band SAR images.\n",
      "As the data acquisition capabilities of earth observation (EO) satellites have been improved significantly, a large amount of high-resolution images are downlinked continuously to ground stations. The data volume increases rapidly beyond the users’ capability to access the information content of the data. Thus, interactive systems that allow fast indexing of high-resolution images based on image content are urgently needed. In this paper, we present an interactive learning system for semantic annotation and content mining at patch level. It mainly comprises four components: primitive feature extraction including both spatial and temporal features, relevance feedback based on active learning, a human machine communication (HMC) interface and data visualisation. To overcome the shortage of training samples and to speed up the convergence, active learning is employed in this system. Two core components of …\n",
      "Pattern retrieval is a fundamental challenge in machine learning but is often subject to the problem of gathering enough labeled examples of the target pattern, and also to the computational complexity inherent to the training and the evaluation of complex classifier functions on large databases. In this paper, we propose a hierarchical top-down processing scheme for pattern retrieval in high-volume high-resolution optical satellite image repositories. We learn via a multistage active learning process a cascade of classifiers working each at a certain scale on a patch-based representation of images. At each stage of the hierarchy, we seek to eliminate large parts of images considered as nonrelevant, the purpose being to set the focus at the finest scales on more promising and as spatially limited as possible areas. Our scheme is based on the fact that by reducing the size of the analysis window (i.e., the size of the patch …\n",
      "This paper presents the image information mining based on a communication channel concept. The feature extraction algorithms encode the image, while an analysis of topic discovery will decode and send its content to the user in the shape of a semantic map. We consider this approach for a real meaning based semantic annotation of very high resolution remote sensing images. The scene content is described using a multi-level hierarchical information representation. Feature hierarchies are discovered considering that higher levels are formed by combining features from lower level. Such a level to level mapping defines our methodology as a deep learning process. The whole analysis can be divided in two major learning steps. The first one regards the Bayesian inference to extract objects and assign basic semantic to the image. The second step models the spatial interactions between the scene objects based on Latent Dirichlet Allocation, performing a high level semantic annotation. We used a WorldView2 image to exemplify the processing results.\n",
      "Multitemporal analysis of co-registered optical re-mote sensing images has gained an ever increasing attention due the availability of several satellite platforms with revisit times. Automatic change detection processed on this type of data are of great interest for fast and efficient decision making in the context of environment monitoring. In this work, a novel pixel-based approach is presented derived from a new informational measure integrating shared and variational informations. A simple and efficient thresholding process is presented such that the method is fully automatic. Experimental results carried out on synthetic and real data, co-registered optical images, demonstrate that this new measure outperforms other information-based approaches.\n",
      "Remote sensing (RS) image retrieval based on visual content is of great significance for geological information mining. Over the past two decades, a large amount of research on this task has been carried out, which mainly focuses on the following three core issues of image retrieval: visual feature, similarity metric and relevance feedback. Along with the advance of these issues, the technology of RS image retrieval has been developed comparatively mature. However, due to the complexity and multiformity of high-resolution remote sensing (HRRS) images, there is still room for improvement in the current methods on HRRS data retrieval. In this paper, we analyze the three key aspects of retrieval and provide a comprehensive review on content-based RS image retrieval methods. Furthermore, for the goal to advance the state-of-the-art in HRRS image retrieval, we focus on the visual feature aspect and delve how to use powerful deep representations in this task. We conduct systematic investigation on evaluating factors that may affect the performance of deep features. By optimizing each factor, we acquire remarkable retrieval results on publicly available HRRS datasets. Finally, we explain the experimental phenomenon in detail and draw instructive conclusions according to our analysis. Our work can serve as a guiding role for the research of content-based RS image retrieval.\n",
      "Many methodologies and similarity measures based on data compression have been recently introduced to compute similarities between general kinds of data. Two important similarity indices are the normalized information distance (NID), with its approximation normalized compression distance (NCD), and the pattern recognition based on data compression (PRDC). At first sight NCD and PRDC are quite different: the former is a direct metric while the latter is a methodology which computes a compression distance with an intermediate step of encoding files into texts. In spite of this, it is possible to demonstrate that they are both based on estimates of Kolmogorov complexities (when this is known for the former but not for the latter). Finally, this results in the definition of a new measure: the model conditioned data compression based similarity measure (McDCSM), which is a modified version of PRDC, and is the topic …\n",
      "In this paper, we present Gibbs random field models in the form of a powerful toolbox for spatial information extraction from remote sensing images. These models are defined via parametrised energy functions that characterise local interactions between neighbouring pixels. After shortly revisiting the information theoretical concept and defining a family of Gibbs models, we give a tour through examples of different kinds of spatial information extraction. These examples range from parameter estimation and analysis, via selection of the model that best describes the image data, up to the segmentation of the whole image into regions with uniform properties of the model. Finally, the concept of across-image segmentation of spatial information leads to an application for content-based queries from remote sensing image archives. (C) 2000 Elsevier Science Ltd. All rights reserved.\n",
      "In this letter, we carry out a comparative study of statistical models for multilook synthetic aperture radar amplitude images. Ten state-of-the-art statistical models are selected for comparison. To achieve a fair evaluation, we estimate all model parameters using the method of log-cumulants and apply the method to an image pyramid with varying pixel spacing (and resolution). The pyramid is created by different image product generation options. In addition to pixel spacing and resolution, we also consider the homogeneity of a scene for performance evaluation and we apply three performance measures. Through this study, it was found out that some models perform well for all resolutions, while the performance of other models depends heavily on the image content.\n",
      "A new method for semantic retrieval of color images employing data compression is presented. While typical content-based image retrieval systems operate in some parameter space, the introduced data-driven technique uses as features the very image data, represented as sets of recurring patterns collected in dictionaries. In a first offline step, the images are quantized in the Hue Saturation Value space and converted into strings, after being modified to preserve some vertical information in the process, and representative dictionaries are extracted from each string with a data compression algorithm; subsequently, the dictionaries are matched in pairs and the distance between each couple of them is estimated. On the basis of the computed distances, the system enables the user to retrieve images with similar content to a given query image. Compression-based classification techniques, being data-driven, have the …\n",
      "This paper proposes to perform authorship analysis using the Fast Compression Distance (FCD), a similarity measure based on compression with dictionaries directly extracted from the written texts. The FCD computes a similarity between two documents through an effective binary search on the intersection set between the two related dictionaries. In the reported experiments the proposed method is applied to documents which are heterogeneous in style, written in five different languages and coming from different historical periods. Results are comparable to the state of the art and outperform traditional compression-based methods.\n",
      "Very large volumes of heterogenous data, like multimedia, earth observation images, scientific and engineering measurements, for instance, are continuously generated and stored. A typical case is the field of earth observation. The widespread availability of high resolution images does not only explore the volumes of data, but also brings order at magnitude in the image detail, thus enormously increasing the information content. However, today's concepts and technologies are still limited in communicating the information content to people for use in real life applications. In this paper, we overview a new concept for knowledge-driven image information mining (KIM) and both analyze and evaluate it from the perspective of human-machine communication. The KIM concept enables the information communication from a very large image repository to users via the Internet. The communication is at a semantic level of representation and is adapted to the user's conjecture.\n",
      "Feature extraction and classification using synthetic aperture radar (SAR) images has been a very active research field over recent last years. Although a lot of features have been proposed and many classifiers have been employed, but there are few works on comparing these features for different TerraSAR-X (TSX) product. In principle, there are many features like gray level co-occurrence matrix, Gabor filters, quadrature mirror filters, and non-linear short time Fourier transform that can be very useful for TSX image classification. However, many of these features may be completely irrelevant for classification when different TSX products (standard or special process products) are used. Therefore, an important research direction is to identify the best features and appropriate TSX product for them using the Support Vector Machine and as a measure of the classification accuracy the precision -recall. The precision …\n",
      "Information content and compression are tightly related concepts that can be addressed through both classical and algorithmic information theories, on the basis of Shannon entropy and Kolmogorov complexity, respectively. The definition of several entities in Kolmogorov’s framework relies upon ideas from classical information theory, and these two approaches share many common traits. In this work, we expand the relations between these two frameworks by introducing algorithmic cross-complexity and relative complexity, counterparts of the cross-entropy and relative entropy (or Kullback-Leibler divergence) found in Shannon’s framework. We define the cross-complexity of an object x with respect to another object y as the amount of computational resources needed to specify x in terms of y, and the complexity of x related to y as the compression power which is lost when adopting such a description for x, compared to the shortest representation of x. Properties of analogous quantities in classical information theory hold for these new concepts. As these notions are incomputable, a suitable approximation based upon data compression is derived to enable the application to real data, yielding a divergence measure applicable to any pair of strings. Example applications are outlined, involving authorship attribution and satellite image classification, as well as a comparison to similar established techniques. View Full-Text\n",
      "Presents a comparison of compression algorithms using the discrete cosine transform-DCT (JPEG) and discrete wavelet transform-DWT applied to remotely sensed images. The statistical behaviors of the DCT and DWT are addressed and the implications for the performance of the image compression algorithms are compared for optical and SAR images. These SAR images were despeckled during compression. Qualitative and quantitative results are presented.\n",
      "In this paper, we consider the problem of remote sensing image classification, in which feature extraction and feature coding are critical steps. Various feature extraction methods aim at an abstract and discriminative image representation. Most of them are either theoretically too complex or practically infeasible to compute for large datasets. Motivated by this observation, we propose a simple yet efficient feature extraction method within the bag-of-words (BoW) framework. It has two main innovations. First and most interestingly, this method does not need any complex local feature extraction; instead, it uses directly the pixel values from a local window as low level features. Second, in contrast to many unsupervised feature learning methods, a random dictionary is applied to feature space quantization. The advantage of a random dictionary is that it does not need the time-consuming process of dictionary learning yet …\n",
      "Advances in remote sensing technologies have allowed us to send an ever-increasing number of satellites in orbit around Earth. As a result, satellite image archives have been constantly increasing in size in the last few years (now reaching petabyte sizes), and have become a valuable source of information for many science and application domains (environment, oceanography, geology, archaeology, security, etc.). TELEIOS is a recent European project that addresses the need for scalable access to petabytes of Earth Observation data and the discovery of knowledge that can be used in applications. To achieve this, TELEIOS builds on scientific databases, linked geospatial data, ontologies and techniques for discovering knowledge from satellite images and auxiliary data sets. In this paper we outline the vision of TELEIOS (now in its second year), and give details of its original contributions on knowledge \n",
      "This paper advocates an automatic technique to discover the optimum combination of three spectral features of a multispectral satellite image that enhance visualization of learned targets/objects. The method is an application-free, single-click user effort, spectrally and spatially balanced, fast-response, low-cost, information-based feature selector that comes to optimize maybe the most important problem in the computer-assisted work of the human operator: visualization of target areas. The new tools developed to assist image experts in their work need to be tailored to the new products offered by the sub-meter spatial resolution multispectral imaging sensors. The spectral bands of the satellite image are ranked using measures of mutual information-the minimum-redundancy-maximum-relevance mRMR criterion-and the top three are automatically displayed on screen. The evaluation of results is performed in terms of both quality (expert-driven visual analysis) and quantity (color metrics) and shows that this approach can become a powerful tool in support of image analysis operations.\n",
      "This letter presents the despeckling of single-look complex (SLC) synthetic aperture radar (SAR) images using nonquadratic regularization. The objective function consists of an image model, a gradient, and a prior model. The Huber-Markov random field (HMRF) models the prior. A numerical solution is achieved through extensions of half-quadratic regularization methods using complex-valued SAR data. The proposed method using the HMRF prior together with nonquadratic regularization shows the superior results on SLC synthetic and actual SAR images.\n",
      "We present Bayesian information extraction methods for feature extraction from metric resolution interferometric radar data. The extracted information is naturally related to a three-dimensional environment. We consider this information for the reconstruction of complex urban settlement areas. We target the higher complexity of the scene that is captured by the high resolution of the sensors by using hierarchical models of the data. Their stochastic nature allows us to deal with the uncertainties that are inherent in both the acquisition process and in the data themselves. We present results of the application of the described concept to the separation and characterization of typical man-made objects appearing in urban areas.\n",
      "Modem sensor systems have and are continuing to acquire data which serve as valuable information sources for scientists in multiple research and application disciplines. The intrinsic complexity of image data and their large volumes makes their archiving as ''file systems'' difficult and inefficient. We propose a unified treatment of the archivation of very diverse image products from the point of view of content-based picture query and retrieval systems.\n",
      "Synthetic Aperture Radar (SAR) systems, like any coherent imaging system, are subject to I) speckling effects, which considerably reduce the useful detail within the acquired scenes and, II) strong geometric distortions. Furthermore, the resolution of SAR systems is comparable to the size of many of the objects of interest in the scene. Out paper proposes a unified treatment of these problems within the framework of probabilistic inference. Despeckling and segmentation are the main objectives only in the first case. In the second case, due to the strong geometric aberrations introduced by the SAR image formation system, the emphasis is on image resampling, with speckle reduction and image segmentation as collateral, but strongly related issues. In both cases, the model is built upon the statistical properties of the speckle noise and the SAR image formation equations.\n",
      "This paper proposes a new parameter based method of SAR image feature extraction and complex image information retrieval. The method's groundwork is the Fast Fourier Transform, each of the proposed parameters being built on a Fourier Transform basis. We suggest that by the use of several image bands formed of distinct spectral signatures of the original complex image, one can obtain a valid spectral characterization of the SAR image that can be afterwards subject to a clustering algorithm. The classification algorithm proposed in this paper is unsupervised K- means. The main advantages of the algorithm are the simplicity and robustness of the implementation.\n",
      "The eight papers in this special section describe some of the recent advances made in the field of image information mining (IIM) for Earth Observation in the development of tools, methods, and applications.\n",
      "Modern communication systems are managing huge volumes of data. The field of remote sensing (RS) data dissemination and interpretation is one of the most demanding. For the new generation of high resolution sensors the volume of data increases drastically. The diversification of applications and of the user's interest require new concepts for data access and interpretation. The main problems encountered in the design of such systems are data and information representation, coding and understanding, and the adaptation to the user conjecture. The key issue is the augmentation of the data with meaning, to take into consideration the model of user's understanding.\n",
      "Satellite images contain an enormous amount of spatial information. To capture that information we propose, in the framework of a stochastic modelling of the image, the use of Gibbs Markov random fields. We expand on a particular model suitable for the use with typical remote sensing images. We demonstrate the capabilities of that model with two examples. In particular, we perform directed queries for specific spatial information.\n",
      "Automatic information extraction from satellite images is the base of remote sensing image archives with content-based query services. Pyramidal image models based on multiscale Markov random fields in combination with a texture model proved to yield good classification and segmentation results. The texture model is used for initial soft classification and then the optimal segmentation given the classification is found using a hierarchical process. Segment probabilities are calculated in a fine-to-rough analysis and segmentation is performed by a rough-to-fine decision algorithm. Previously proposed models optimise the strength of the dependencies in a fixed hierarchical structure. In our model we allow the dependencies to switch, so that the hierarchical structure itself is optimised. Our model is exactly tractable, achieves very smooth segmentations, even at coarse scale, and can be fast computed.\n",
      "Synthetic aperture radar (SAR) image change detection is playing an important role in various Earth Observation (EO) applications. There exists a large number of different methods that have been proposed to address this issue. However, due to the fact that several kinds of changes with diverse characteristics can arise in SAR images, there is no consensus on their performances because most methods have been evaluated using different data sets, probably facing several kinds of changes, but without an in-depth analysis of the characteristics of SAR image changes. Therefore, two important problems arise. The first is what kind of change each approach can detect. The second is how much they can detect a kind of change. Although the importance to model any kind of changes has been realized, there is no principled methodology to carry out the analysis due to the difficulty in modeling various kinds of changes. In this paper, we propose a benchmark methodology to reach this goal by simulating selected kinds of changes in addition to using real data with changes. Six kinds of SAR changes for eight typical image categories are simulated, i.e., reflectivity changes, first-order, second-order, and higher order statistical changes, linear and nonlinear changes. Based on this methodology for change simulation, a comprehensive evaluation of information similarity measures is carried out. An explicit conclusion we have drawn from the evaluation is that the various methods behave very differently for all kinds of changes. We hope that this study will promote the advancement of this topic.\n",
      "TELEIOS is a recent European project that addresses the need for scalable access to petabytes of Earth Observation data and the discovery and exploitation of knowledge that is hidden in them. TELEIOS builds on scientific database technologies (array databases, SciQL, data vaults) and Semantic Web technologies (stRDF and stSPARQL) implemented on top of a state of the art column store database system (MonetDB). We demonstrate a first prototype of the TELEIOS Virtual Earth Observatory (VEO) architecture, using a forest fire monitoring application as example.\n",
      "Information mining opens new perspectives and a huge potential for information extraction from large volumes of heterogeneous images and the correlation of this information with the goals of applications. We present a new concept and system for image information mining, based on modelling the causalities which link the image-signal contents to the objects and structures within interest of the users. The basic idea is to split the information representation into four steps: 1. image feature extraction using a library of algorithms so as to obtain a quasi-complete signal description 2. unsupervised grouping in a large number of clusters to be suitable for a large set of tasks 3. data reduction by parametric modelling the clusters 4. supervised learning of user semantics, that is the level where, instead of being programmed, the systems is trained by a set of examples; thus the links from …\n",
      "More accurate interpretation of remotely sensed data is based on a concept combining synergistically signals, information or knowledge from different sources. The aim is information mining, extraction and presentation. A hierarchical structure of data fusion levels has been identified: on image signal level, on image features, on physical parameters extracted from images, on meta features resulting from image feature modelling, on feature grouping. The Bayesian perspective is discussed aiming at a variety of aspects. The power of the Bayesian approach is endowed ie by the possibility to analyse uniformly the uncertainties over scene parameters in data acquired from heterogeneous and incommensurable sources.\n",
      "Users of remote sensing images analyzing land cover characteristics are very much interested in classification schemes that define a consistent set of target categories. Up to now, a number of established classification schemes are mainly being used by interpreters of medium-resolution optical satellite images focusing on large-scale land cover. In contrast, we concentrate in this publication on the definition of a new classification scheme for high-resolution synthetic aperture radar (SAR) images that are mostly taken over built-up areas. Here, we can see many small details of buildings, industrial facilities, and infrastructure that have to be classified. However, the appearance of details in high-resolution SAR images is often difficult to understand for human observers, and, therefore, calls for an automated semantic annotation of the target objects that has to follow a number of specific scientific guidelines. We demonstrate that a selection of representative SAR images with subsequent feature extraction and relevance feedback classification during the generation of a classification scheme leads to a reliable definition of a new high-resolution multi-level SAR image classification scheme that can be applied globally for semantic annotation in an automated chain.\n",
      "Active learning has gained a high amount of attention due to its ability to label a vast amount of unlabeled collected earth observation (EO) data. In this paper, we propose a novel active learning algorithm which ismainly based on employing a low-rank classifier as the training model and introducing a visualization support data point selection, namely, first certain wrong labeled (FCWL). The training model is composed of the logistic regression loss function and the trace-norm of learning parameters as regularizer. FCWL selects those data points whose labels are predicted wrong but the classifier is highly certain about them. Our experimental results performed on different extracted features from a dataset of SAR images confirm at least 10% improvement over the state-of-the-art methods.\n",
      "Gauss-Markov random fields have been successfully used as texture models in a host of applications, ranging from synthesis, feature extraction, classification and segmentation to query by image content and information retrieval in large image databases. An issue that deserves special consideration is the selection of the neighbourhood order (model complexity), which should faithfully reflect the Markovianity of spatial interactions. Estimating the parameters for the wrong model will not capture the essential statistical properties of the texture in question: a lower order model will not be informative enough, while a higher order will clutter the description with superfluous information, fitting the noise rather than the data.We give a full Bayesian solution for estimating the model complexity, using an appropriate set of prior probabilities on the parameters. The closed-form decision criterion is derived by employing a Gaussian approximation of the posterior probability around the mode. The validity and benefits of this approach are demonstrated on two important problems arising in machine vision: texture replication and image classification. (C) 2002 Elsevier Science B.V. All rights reserved.\n",
      "Research on the semantic gap has considered differences between user and computer image interpretations and proposed methods to bridge it. These methods have been verified by comparing results to reference data or by measuring the degree of user acceptance. Although these methods result in a narrower semantic gap between computers and users, the resulting model for a specific user and search goal may still not be satisfactory to other users. Through an image annotation task with users, we find that this discrepancy is caused by the subjective biases present in the bridging methods, which we refer to as the “linguistic semantic gap.” Based on our findings, efforts to bridge the semantic gap should include different user perspectives to compensate the individual subjective biases, by increasing the diversity of data sets used in the domain. Moreover, models derived from proposed bridging methods could …\n",
      "In this paper, we describe an active learning scheme which performs coarse to fine testing using a multiscale patch-based representation of images to retrieve objects in large satellite image repositories. The proposed hierarchical top-down approach reduces step by step the size of the analysis window, eliminating each time large parts of the images considered as non-relevant. Unlike most object detection methods which requires large training sets and costly offline training, we use an active learning strategy to build a classifier at each level of the hierarchy and we propose an algorithm to propagate automatically the training examples from one level to the other.\n",
      "In this paper, we deal with the integration of multiple sources of information such as Earth observation (EO) synthetic aperture radar (SAR) images and their metadata, semantic descriptors of the image content, as well as other publicly available geospatial data sources expressed as linked open data for posing complex queries in order to support geospatial data analytics. Our approach lays the foundations for the development of richer tools and applications that focus on EO image analytics using ontologies and linked open data. We introduce a system architecture where a common satellite image product is transformed from its initial format into to actionable intelligence information, which includes image descriptors, metadata, image tiles, and semantic labels resulting in an EO-data model. We also create a SAR image ontology based on our EO-data model and a two-level taxonomy classification scheme of the …\n",
      "Dramatic growth in the volume of data made a compact and informative representation of the data highly demanded in computer vision, information retrieval, and pattern recognition. Non-negative Matrix Factorization (NMF) is used widely to provide parts-based representations by factorizing the data matrix into non-negative matrix factors. Since non-negativity constraint is not sufficient to achieve robust results, variants of NMF have been introduced to exploit the geometry of the data space. While these variants considered the local invariance based on the manifold assumption, we propose Farness preserving Non-negative Matrix Factorization (FNMF) to exploits the geometry of the data space by considering non-local invariance which is applicable to any data structure. FNMF adds a new constraint to enforce the far points (i.e., non-neighbors) in original space to stay far in the new space. Experiments on different …\n",
      "A huge amount of various remote sensing data have been acquired and archived during recent years. Information extraction from these data is still a challenging task, for example using the data classification. We propose the Bayesian approach to image classification using information fusion from different sources of data. The method of classification is based on the three processing steps: (1) information fission by feature extraction, (2) data and dimensionality reduction by unsupervised clustering, and (3) supervised classification with information fusion. The potential of the classification method is illustrated by the examples on ERS-1/2 Tandem interferometric synthetic aperture radar data. The continuity of tandem pairs of SAR images is ensured by already started or future missions such as TerraSAR-X, TanDEM-X, and COSMO-SkyMed.\n",
      "During the last decade, the exponential increase of multimedia and remote sensing image archives, the fast expansion of the world wide web, and the high diversity of users have yielded concepts and systems for successful content-based image retrieval and image information mining. Image data information systems require both database and visual capabilities, but there is a gap between these systems. Database systems usually do not deal with multidimensional pictorial structures and vision systems do not provide database query functions. In terms of these points, the evaluation of content-based image retrieval systems became a focus of research interest. One can find several system evaluation approaches in literature, however, only few of them go beyond precision-recall graphs and do not allow a detailed evaluation of an interactive image retrieval system. Apart from the existing evaluation methodologies, we aim at the overall validation of our knowledge-driven content-based image information mining system. In this paper, an evaluation approach is demonstrated that is based on information-theoretic quantities to determine the information flow between system levels of different semantic abstraction and to analyze human-computer interactions.\n",
      "Conventional satellite ground segments comprise mission operations and data acquisition systems, data ingestion interfaces, processing capabilities, a catalogue of available data, a data archive, and interfaces for queries and data dissemination. The transfer of data mostly relies on common computer networks or high capacity tapes. Future ground segments have to be capable of handling multi-mission data delivered by Synthetic Aperture Radar (SAR) and optical sensors and have to provide easy user access to support the selection of specific data sets, fuse data, visualize products and to compress data for transmission via Internet. In particular, the search for data sets has to support individual queries by data content and detailed application area (“data mining”) as well as capabilities for automated extraction of relevant features and the application oriented representation of results. In the case of SAR …\n",
      "In this paper we present a general formalism to model several levels of meta information on spatial content. In particular, we expand on a two-level procedure of Bayesian inference: model fitting and model selection. We study five cases of extraction of spatial information from remote sensing images using this scheme. In this way, we put together pieces of information obtained from different levels of interpretation of the original image data.\n",
      "This paper presents a classification overview and a comparative study of despeckling algorithms. Almost all of the existing good speckle reduction algorithms show high computational complexity. Promising results giving a very good compromise between image enhancement and algorithm complexity are obtained using multiscale analysis techniques.\n",
      "Future users of satellite images will be faced with a huge amount of data. The development of content-based image retrieval algorithms for remote sensing image archives will allow them to efficiently use the upcoming databases of large images. The authors present an image segmentation and feature extraction algorithm, that will enable users to search images by content. In their approach, images are modelled by multiscale Markov random fields (MSRF). This model is superior to spatial Markov random field models in that it is able to describe the long range as well as the short range behaviour of the image data. Image information extracted at multiple scales is incorporated naturally in the model. Additionally it is computationally less costly than the spatial random field models. The difference to similar work by Ch.A. Bouman et al. (1994) and A. Jain et al. (1992) is that the multiscale process is not only used to find …\n",
      "The major task of the scene understanding process is to find the scene which best explains the observed data. In general the observed data, the same radar signals, can be generated by different scenes. To identify the scene the author has to choose between competing hypotheses. The method analyzed within the present paper arises from the fundamental approach of considering the probability theory as a set of normative rules for conducting inference. The scene inversion is a model based approach, and the models carry the thematic information. Model comparison is a delicate task, more complex models can always fit better the data, so the maximum likelihood choice would lead to implausible over-parameterized models that generalize poorly. The author proposes as solution the Bayesian inference that penalizes the unnecessary complicated models and prefers the simpler and precise ones. The paper \n",
      "Estimations of the local roughness of Digital Elevation Models (DEMs) have been used both for a better geological understanding of terrain structures and for a more accurate DEM interpolation leading to higher resolution terrain maps. This work investigates two fractal dimension estimators for the characterization of the roughness of DEMs: the power spectrum estimator and the wavelet-based estimator. The performance of these methods is compared in terms of image segmentation capabilities. Since wavelets and fractals are related by the same multiresolution concept, we expect to have better results using the wavelet analysis method. This expectation is confirmed by experiments on synthetic images and real DEMs: measurements of fractal parameters using wavelet-based methods are more reliable than the same measurements performed using other methods. Finally we discuss some examples in which the fractal analysis of DEMs allows the separation of different roughness classes and reveals artifacts in the computation of elevation data.\n",
      "Many previous researches have already shown the advantages of multisensor land-cover classification. Here, we propose an innovative land-cover classification approach based on learning a joint latent model of synthetic aperture radar (SAR) and multispectral satellite images using multimodal latent Dirichlet allocation (mmLDA), a probabilistic generative model. It has already been successfully applied to various other problems dealing with multimodal data. For our experiments, we chose overlapping SAR and multispectral images of two regions of interest. The images were tiled into patches and their local primitive features were extracted. Then each image patch is represented by SAR and multispectral bag-of-words (BoW) models. The BoW values are both fed to the mmLDA, resulting in a joint latent data model. A qualitative and quantitative validation of the topics based on ground-truth data demonstrate that …\n",
      "The advent of submeter-resolution synthetic aperture radar (SAR) images from satellites such as TerraSAR-X has given a new dimension to SAR image understanding. Even though emphasis is always on discovering automatic means of target characterization, visual exploration of targets and objects is the first step in many applications. While considering the complex-valued SAR images, visual inspection of the targets in an image may provide incomplete and misleading information, as sometimes two entirely different behaving objects look quite similar in SAR images. Thus, a need was felt to develop a methodology to support visual target recognition and analysis. In this letter, we present a method which looks into the complex-valued spectrum of SAR images, thus allowing a detailed physical interpretation of the scattering behavior of objects. The presented method is a joint time-frequency analysis method …\n",
      "The increasing number and resolution of earth observation (EO) imaging sensors has had a significant impact on both the acquired image data volume and the information content in images. There is consequently a strong need for highly efficient search tools for EO image databases and for search methods to automatically identify and recognize structures within EO images. In this paper, we present a concept for an earth observation image data mining system mixing an auto-annotation component with a category search engine which combines a generic image class search and an object detection feature. The proposed concept relies thus on three distinct components which are detailed successively: in the first part, we describe the auto-annotation component, in the second part, the generic category search engine and in the third part, the object detection tool. In the concluding part of the paper, we provide an insight into how these three components can be related to each other and used in a complementary way to arrive at a system which combines the advantages of both the auto-annotation systems and the category search engines.\n",
      "With the launch of the German TerraSAR-X system, a new generation of high-resolution spaceborne SAR data is available. This opens new perspectives and challenges for the automatic interpretation of urban environments. In fact, a rich information content, previously hidden or not clearly distinguishable in low resolution images such as urban structures (small buildings, vehicles, etc), is now disclosed. However, only proper approaches are able to retrieve automatically this new detailed information. This paper provides solutions for the semi-automatic interpretation and mapping of urban areas using the high resolution provided by TerraSAR-X data. Our solutions take into the increase, with the high resolution, of the visibility of some man-made structures whose scattering response has improved with the high frequency X-band SAR sensor carried by the TerraSAR-X system. They are mainly based on two steps …\n",
      "Information content and compression are tightly related concepts that can be addressed by classical and algorithmic information theory. Several entities in the latter have been defined relying upon notions of the former, such as entropy and mutual information, since the basic concepts of these two approaches present many common tracts. In this work we further expand this parallelism by defining the algorithmic versions of cross-entropy and relative entropy (or Kullback-Leibler divergence), two well-known concepts in classical information theory. We define the cross-complexity of an object x with respect to another object y as the amount of computational resources needed to specify x in terms of y, and the complexity of x related to y as the compression power which is lost when using such a description for x, with respect to its shortest representation. Since the main drawback of these concepts is their uncomputability, a suitable approximation based on data compression is derived for both and applied to real data. This allows us to improve the results obtained by similar previous methods which were intuitively defined.\n",
      "This paper proposes complexity based analysis as a valid alternative to classic image analysis methodologies for Earth Observation imagery, which are heavily dependant on the assumed data models. These methods are totally model-free and data-driven, and may be successfully employed for image classification and indexing, regardless of spatial and radiometric resolution of the scene and sensor type.\n",
      "This paper gives an overview of the two levels of Bayesian inference: model fitting and model selection and shows how they can be used for the image texture analysis. The applied models are the Gauss-Markov and Gibbs auto-binomial Random Fields. In the second part the article introduces a linear model for the image wavelet coefficients able to explain the full description of the spatial, inter-scale and inter-band behavior of a multi-resolution decomposed image. The model parameters, model variance and evidence are used to characterize the image texture.\n",
      "A Bayesian approach for the denoising of digital elevation models (DEMs), which are assumed to be affected by nonstationary additive Gaussian noise, is presented. We take into account the nonstationary behavior by both locally estimating the noise properties, i.e. the variance, and the model parameters of an underlying Gauss-Markov process, which serves as prior information to characterize specific terrain properties. The resulting locally adaptive filter provides an MAP estimate of the noise-free DEM, which preserves sufficient detail while strongly reducing the noise. (Author)\n",
      "Remote sensing images exhibit an enormous amount of information. In order to extract this information in a robust way and to make it available as efficient indices for query by image content, the authors present a scheme of hierarchical stochastic description. The different levels in this hierarchy are derived from the different levels of abstraction: image data (0), image features (1), meta features (2), image classification (3), geometric features (4), and user-specific semantics (5). They describe this hierarchical scheme and the processes of Bayesian inference between these levels and present a case study using synthetic aperture radar (SAR) data.\n",
      "A novel treatment of interferometric SAR as a Bayesian estimation problem is presented. Application of the Bayesian approach involves devising: a model relating system geometry, surface topography and reflectivity to the measured radar signals, a stochastic model of the topographic surface embodying the dominant terrain characteristics of slope and curvature and a stochastic model of the surface reflective properties. This information is combined into a conditional probability density function of the model parameters given the measured data. System models are proposed, and possible algorithms for estimating model parameters are considered. The issue of formulating an error estimate is discussed.\n",
      "This paper presents two approaches for the analysis of multi-temporal and multisensory data analysis. The first approach focuses on a novel similarity measure, named Mixed Information, derived from information measures and assessment of its performance for multitemporal analysis in change detection. The second approach proposes the use of Kullback-Leibler divergence between marginal distributions, efficiently approximated by cumulant based expansion series. Comparison between mixed information and Kullback-Leibler divergence based change detection is performed to confirm the usefulness of joint metric for analyzing multitemproal and multisensory data. Experimental results obtained confirm justification of the mixed information in multitemporal analysis.\n",
      "We are dealing with large-scale high-dimensional image data sets requiring new approaches for data mining where visualization plays the main role. Dimension reduction (DR) techniques are widely used to visualize high-dimensional data. However, the information loss due to reducing the number of dimensions is the drawback of DRs. In this paper, we introduce a novel metric to assess the quality of DRs in terms of preserving the structure of data. We model the dimensionality reduction process as a communication channel model transferring data points from a high-dimensional space (input) to a lower one (output). In this model, a co-ranking matrix measures the degree of similarity between the input and the output. Mutual information (MI) and entropy defined over the co-ranking matrix measure the quality of the applied DR technique. We validate our method by reducing the dimension of SIFT and Weber …\n",
      "The collected Earth Observation (EO) data volumes are increasing immensely. In the meantime, the need for retrieval of focused information for decision making is increasing. Due to the particular nature of EO sensors, recording signals very differently than humans perceptual system, the challenges raised by the semantic and sensory gaps are immensely amplified in designing retrieval methods for EO images. This article introduces a method based on communication channel model to quantify and measure the semantic gap, used to assess various feature descriptors for semantic annotation purposes. The approach uses Latent Dirichlet Allocation (LDA), considering images as the source and the semantic topics as the receiver. The parameters of LDA are estimated for computing the Mutual Information to assess latent semantics of feature space. We further introduce a method to measure the distance between …\n",
      "Recent years have witnessed an increased interest towards compression-based methods and their applications to remote sensing, as these have a data-driven and parameter-free approach and can be thus succesfully employed in several applications, especially in image information mining. This paper expands the algorithmic information theory frame, on which these methods are based. On the one hand, algorithms originally defined in the pattern matching domain are reformulated, allowing a better understanding of the available compression-based tools for remote sensing applications. On the other hand, the use of existing compression algorithms is proposed to store satellite images with added semantic value.\n",
      "Many fawns and other wild animals are killed by mowing machines every year. To prevent them from being killed or injured, a sensor system is being developed to detect the fawns hidden in meadows under mowing. Beside a microwave radar system, two cameras (thermal infrared and RGB) take a picture at the mower's current location. This contribution focuses on the compression-based algorithm that will be adopted to detect the locations containing a fawn hiding in the grass: such approach, being parameter-free, allows performing a fully unsupervised clustering by exploiting the intrinsic properties of data compression to estimate the amount of shared information between two images.\n",
      "In this letter, our main objective is to demonstrate the capabilities of independent component analysis (ICA) for very high resolution satellite image characterization, particularly for geometrical structures contained in images from urban areas in comparison with natural landscapes. We propose a model based on ICA sources to index satellite images with a resolution of 0.6 m. An important part of this work is to study the effects of multiscaling and dimensionality behavior of ICA components. For evaluating the capabilities of our model, we design a classification method to distinguish images froma variety of natural and man-made scenes.\n",
      "This paper presents a system to integrate digital elevation model (DEM) enhancement and Earth Observation (EO) image analysis for realistic three-dimensional (3-D) rendering applications. There is an increasing interest in interferometric synthetic aperture radar (InSAR) data, principally due to the availability of the nearly global Shuttle Radar Topography Mission coverage. To remove artifacts and noise from an InSAR DEM, a nonstationary Bayesian filtering is applied that preserves structural information. Land-cover or man-made structures are easily recognized in an optical image. The corresponding geometry encapsulated in the DEM differs from our implicit perception and generally leads to unrealistic 3-D rendering. To improve this, DEM regularization is achieved using only the visualization dataset (optical image and DEM). It consists of extracting relevant information from the optical image and integrate them in the filtered DEM. To gather image information, an object-based description of large optical EO images is obtained in two stages 1) an image is segmented to create a partition of regions and 2) a novel dynamical algorithm is proposed to extract the regions and encode them in a tree structure. Regions are modeled by objects primitives stored in a database. Spatial relationships between regions are reflected by the presented tree of regions. Using the object-based description generation, structures to be integrated into the DEM are interactively selected and classified among a set of user-thematic. Each thematic is associated with a corresponding elevation modeling and enables to estimate the region's 3-D structure. The proposed object line processing provides more realistic 3-D visualizations.\n",
      "Several signal processing techniques are presented and evaluated to filter/enhance SAR digital elevation models (DEMs). The results are compared to a topographic digital terrain model (DTM) in the context of 3D visualization and real-time rendering. Through the DLR X-SRTM DEM, the interest of InSAR data for such applications is illustrated.\n",
      "The increased availability of high-resolution synthetic aperture radar (SAR) satellite images has led to new civil applications of these data. Among them is the systematic classification of land cover types based on the patterns of settlements or agriculture recorded by SAR imagers, in particular the identification and quantification of temporal changes. A systematic (re)classification shall allow the assignment of continuously updated semantic content labels to local image patches. This necessitates a careful selection of well-defined and discernible categories being contained in the image data that have to be trained and validated. These steps are well-established for optical images, while the peculiar imaging characteristics of SAR sensors often prevent a comparable approach. Especially, the vast range of SAR imaging parameters and the diversity of local targets impact the image product characteristics and need special care. In the following, we present guidelines and practical examples of how to obtain reliable image patch classification results for time series data with a limited number of given training data. We demonstrate that one can avoid the generation of simulated training data if we decompose the classification task into physically meaningful subsets of characteristic target properties and important imaging parameters. Then, the results obtained during training can serve as benchmarking figures for subsequent image classification. This holds for typical remote sensing examples such as coastal monitoring or the characterization of urban areas where we want to understand the transitions between individual land cover categories. For this purpose, a representative dataset can be obtained from the authors. A final proof of our concept is the comparison of classification results of selected target areas obtained by rather different SAR instruments. Despite the instrumental differences, the final results are surprisingly similar.\n",
      "In many applications, such as image retrieval and change detection, we need to assess the similarity of two statistical models. As a distance measure between two probability density functions, Kullback-Leibler divergence is widely used for comparing two statistical models. Unfortunately, for some models such as Gaussian Mixture Model (GMM), Kullback-Leibler divergence has no analytically tractable formula. We have to resort to approximation methods. In this paper, we compare seven methods, namely Monte Carlo method, matched bond approximation, product of Gaussian, variational method, unscented transformation, Gaussian approximation, and min-Gaussian approximation, for approximating the Kullback-Leibler divergence between two Gaussian mixture models for satellite image retrieval. Two image retrieval experiments based on two publicly available datasets have been performed. The comparison is carried out in terms of both retrieval performance and computational time.\n",
      "We present an accelerated probabilistic learning concept and its prototype implementation for mining heterogeneous Earth observation images, e.g., multispectral images, synthetic aperture radar (SAR) images, image time series, or geographical information systems (GIS) maps. The system prototype combines, at pixel level, the unsupervised clustering results of different features, extracted from heterogeneous satellite images and geographical information resources, with user-defined semantic annotations in order to calculate the posterior probabilities that allow the final probabilistic searches. The system is able to learn different semantic labels based on a newly developed Bayesian networks algorithm and allows different probabilistic retrieval methods of all semantically related images with only a few user interactions. The new algorithm reduces the computational cost, overperforming existing conventional systems, under certain conditions, by several orders of magnitude. The achieved speed-up allows the introduction of new feature models improving the learning capabilities of knowledge-driven image information mining systems and opening them to Big Data environments.\n",
      "Deep Learning techniques have lately received increased attention for achieving state-of-the-art results in many classification problems, including various vision tasks. In this work, we implement a Deep Learning technique for classifying above-ground objects within urban environments by using a Multilayer Perceptron model and VHSR DEM data. In this context, we propose a novel method called M-ramp which significantly improves the classifier’s estimations by neglecting artefacts, minimizing convergence time and improving overall accuracy. We support the importance of using the M-ramp model in DEM classification by conducting a set of experiments with both quantitative and qualitative results. Precisely, we initially train our algorithm with random DEM tiles and their respective point-labels, considering less than 0.1% over the test area, depicting the city center of Munich (25 km&lt;sup&gt;2&lt;/sup&gt;). Furthermore with no additional training, we classify two much larger unseen extents of the greater Munich area (424 km&lt;sup&gt;2&lt;/sup&gt;) and Dongying city, China (257 km&lt;sup&gt;2&lt;/sup&gt;) and evaluate their respective results for proving knowledge-transferability. Through the use of M-ramp, we were able to accelerate the convergence by a magnitude of 8 and achieve a decrease in above-ground relative error by 24.8% and 5.5% over the different datasets.\n",
      "The exponentially increasing amount of Earth Observation (EO) data requires novel approaches for data mining and exploration. Visual analytic systems have made valuable contribution in understanding the structure of data by providing humans with visual perception of data. However, these systems have limitations in dealing with large-scale high-dimensional data. For instance, the limitation in dimension of the display screen prevents visualizing high-dimensional data points. In this paper, we propose a virtual reality based visual analytic system, so called Immersive Information Mining, to enable knowledge discovery from the EO archive. In this system, Dimension Reduction (DR) techniques are applied to high-dimensional data to map into a lower-dimensional space to be visualized in an immersive 3D virtual environment. In such a system, users are able to navigate within the data volume to get visual …\n",
      "Several techniques have been proposed in the last few years for the compression of hyperspectral and multispectral images. All of them try to exploit, in various degrees, the particularities of these Images, especially of the intraband and interband redundancies they exhibit. In this paper, we consider the compression of multitemporal and multispectral images and we make a comparison between still image and video approaches for the compression of these images acquired by SPOT 1, 2 and 4. The still image compression is realised using the state-of-the-art JPEG2000 codec, while the video one uses an EZBC wavelet-based codec. Both spectral and temporal decorrelation approaches are discussed.\n",
      "Images are highly complex multidimensional signals, with rich and complicated information content. For this reason they are difficult to analyze with a specific automated approach. However, a hierarchical representation is helpful for understanding image content. In this paper, we describe an application of a scale-space clustering algorithm (melting) for exploration of image information content. Clustering by melting considers the feature space as a thermodynamical ensemble and groups the data by minimizing the free energy, having temperature as a scale parameter. We develop clustering by melting for multidimensional data, and propose and demonstrate a solution for the initialization of the algorithm. Due to the curse of dimensionality, for initialization of clusters we choose the initial clusters centers with an algorithm that performs fast cluster center estimation with low computation cost. We further analyze …\n",
      "In this paper we present an intuitive way of semantic labeling of image content suited for query by image content from remote sensing image databases. The space of image content understanding is separated into a syntactic and a semantic space. The syntactic space contains objective, signal-oriented classes of certain types of structures and the semantic space contains subjective, user-oriented content labels. We expand on the Bayesian inference between the two spaces and provide examples for semantic content labeling in both optical (Landsat TM) and synthetic aperture radar (XSAR) data.\n",
      "An approach for reconstruction of speckled SAR images is presented. This approach is based upon Bayes' rule obtaining the maximum a posteriori estimate of the underlying radar cross section. The prior used for the reconstruction is modelled by Gibbs random fields reflecting the existing texture characteristics, while the system transfer function of the SAR signal processing together with the speckle noise is accounted for by the likelihood distribution. The solution of this optimization problem is obtained by relaxation methods such as simulated annealing using the prior information as a constraint to limit the optimization space.\n",
      "In the literature, scene recognition from interferometric synthetic aperture radar (InSAR) images has been mainly focused on the joint use of the backscatter intensity and the coherence between interferometric image pairs. However, the terrain height information residing in the interferometric phase requires further exploration for classification purposes. In this letter, taking the interferometric phase information into account together with the backscatter intensity, the whole complex- valued InSAR image is exploited for feature extraction. In addition, a new complex-valued phase-gradient InSAR (PGInSAR) image is defined. A fractional-Fourier-transform-based feature ex traction, which was proposed for the classification of single-look complex (SLC) SAR images, is adopted for InSAR and PGInSAR images. For patch-based classification, an image database is generated from bistatic pairs acquired from the same terrain …\n",
      "Efficient management and exploration of high-volume scientific file repositories have become pivotal for advancement in science. We propose to demonstrate the Data Vault, an extension of the database system architecture that transparently opens scientific file repositories for efficient in-database processing and exploration.\n",
      "The Method of Log Cumulants (MoLC) has been recently proposed for analysis and parameter estimation of the probability density function (pdf) defined in R+. Here the Fourier transform as the characteristics function is replaced with Mellin transform for parameter estimation. Instead of focusing on pdf parameter estimation using MoLC, our objective in this article is to directly use log-moments (also called second-kind moments in second-kind statistics) of transformed synthetic aperture radar (SAR) images as the feature descriptor describing the image content. Gabor filters have been considered to transform the SAR image data. Comparison is presented with first and higher-order statistics and spectral feature descriptors. K-nearest neighborhood (K-NN) classification algorithm have been used as classifier.\n",
      "In this paper, mixed information similarity measure and a multidimensional density estimation method based on multivariate Edgeworth series expansion are proposed and assessed for the task of multi-temporal change detection. To unify mutual information and variational information, mixed information is proposed to quantify the degree of dependence between two random variables, which are intuitively appropriate for multi-temporal change detection. In the literature, Edgeworth series expansion is widely used in statistics and various engineering fields for one-dimensional density estimation. To compute the mixed information measure, multidimensional density estimation based on multivariate Edgeworth series expansion is proposed and evaluated. Two experiments on real SAR images and optical images are carried out to evaluate the performance of change detection. Experimental results confirm the promising capability of mixed information and the multivariate density estimation based on Edgeworth series expansion.\n",
      "Satellite images of medium resolution are often part of historical archives, which makes them ideally suited to study urban growth. Such archives enable creation of satellite image time series (SITS). SITS represent an amount of information greater far greater than individual images, but are complex and difficult to interpret. In this paper we develop Landsat TM SITS centered over Bucharest, we create temporal signatures based on spectral indices, and we show possible uses for change detection based on these temporal signatures.\n",
      "Audio data like speech and music can be analyzed and processed with Fourier methods, having as one constraint the constant product of time and frequency resolutions. This problem can be avoided applying the wavelet transform, ensuring good resolutions on both time and frequency supports. We propose in this paper to determine features of music in a combined framework using multi-resolution (wavelet) analysis and spectral analysis in order to realize the classification of musical pieces in genre classes. The proposed approach also uses a number of features commonly employed for speech recognition, such as Mel-cepstral coefficients, zero crossing rate or the signal energy. Moreover, the rhythm audio content is considered, the corresponding feature parameters being extracted from beat-histograms.\n",
      "The high complexity and the increased importance of geometry in growing resolution synthetic aperture radar (SAR) data in urban environments poses a limit on the usability of lattice-based scene models. Geometrical models based on marked point processes can be employed to provide better descriptions of the scene. A Gibbs potential based on a hierarchical Bayesian description of the direct model of the acquisition is defined on the process: an a-priori measure of plausibility for the scene takes into account interactions between scene objects, while a Bayesian likelihood term is based on the decomposition of scene objects into basic elements and on their mapping in the data space. Multiple reflections of the radar signals are considered and exploited. The resulting detectability measure is compared to a hypothesis in a likelihood ratio. The resulting posterior potential is optimized by Monte Carlo methods. The …\n",
      "<jats:p>Contrary to optical images, Synthetic Aperture Radar (SAR) images are in different electromagnetic spectrum where the human visual system is not accustomed to. Thus, with more and more SAR applications, the demand for enhanced high-quality SAR images has increased considerably. However, high-quality SAR images entail high costs due to the limitations of current SAR devices and their image processing resources. To improve the quality of SAR images and to reduce the costs of their generation, we propose a Dialectical Generative Adversarial Network (Dialectical GAN) to generate high-quality SAR images. This method is based on the analysis of hierarchical SAR information and the &amp;ldquo;dialectical&amp;rdquo; structure of GAN frameworks.&amp;nbsp; As a demonstration, a typical example will be shown where a low-resolution SAR image (e.g., a Sentinel-1 image) with large ground coverage is translated into a high-resolution SAR image (e.g., a TerraSAR-X image). Three traditional algorithms are compared, and a new algorithm is proposed based on a network framework by combining conditional WGAN-GP (Wasserstein Generative Adversarial Network - Gradient Penalty) loss functions and Spatial Gram matrices under the rule of dialectics. Experimental results show that the SAR image translation works very well when we compare the results of our proposed method with the selected traditional methods.</jats:p>\n",
      "We propose a multilevel semantics discovery approach for bridging the semantic gap when mining high-resolution polarimetric synthetic aperture radar (PolSAR) remote sensing images. First, an Entropy/Anisotropy/Alpha-Wishart classifier is employed to discover low-level semantics as classes representing the physical scattering properties of targets (e.g., low-entropy/surface scattering/high anisotropy). Then, the images are tiled into patches and each patch is modeled as a bag-of-words, a histogram of the class labels. Next, latent Dirichlet allocation is applied to discover their higher level semantics as a set of topics. Our results demonstrate that topic semantics are close to human semantics used for basic land-cover types (e.g., grassland). Therefore, using the topic description (bag-of-topics) of PolSAR images leads to a narrower semantic gap in image mining. In addition, a visual exploration of the topic descriptions helps to find semantic relationships, which can be used for defining new semantic categories (e.g., mixed land-cover types) and designing rule-based categorization schemes.\n",
      "Very-high resolution (VHR) synthetic aperture radar (SAR) images from the last generation satellites such as TerraSAR-X and TanDEM-X exhibits special characteristics, especially in the urban-areas. Consequently, attention is needed on special considerations while developing algorithms for SAR image processing and its applications for automated interpretation. With automatic interpretation we refer to the information extraction and characterization for image categorization, retrieval, segmentation, automated target recognition etc.. In this article we focus our attention to the problem of SAR image categorization. The interest in SAR image categorization in VHR SAR (on the contrary to the pixel-based classification in low-resolution SAR images) has increased with enhanced resolution providing opportunity to carry out a more detailed analysis of targets and objects. SAR image categorization requires generation of a compact feature descriptor which accurately define the image content. A feature descriptor can be generated using 'parametric' or 'non-parametric' approaches in 'image' or 'image within a transformation space'. The objective of this article is to review some selected techniques for this purpose in form of a methodological classification. Qualitative assessment of selected algorithms is presented.\n",
      "The main purpose of this study is to define for Synthetic Aperture Radar (SAR) data the primitive feature parameters, the incidence angle, and the orbit direction which can be used further for indexing and querying in the EO systems.The evaluation is done on the high resolution SAR data and the interpretation is realized automatically.In this paper, we propose to study and asses the behavior of the primitive feature extracted methods for images of the same scene with two look angles covering the min-max range of the sensor and with ascending/descending orbit looking. The tests are done on TerraSAR-X products Stripmap and high resolution Spotlight, specially and radiometrically enhanced covering the area of Berlin (Germany) and Ottawa (Canada). To identify the optimal primitive features, incident angle, and orbit direction the Support Vector Machine and as a measure of the classification accuracy the precision/recall were considered.\n",
      "In this paper, a patch based method for multi-temporal analysis of high resolution image is proposed. Conventionally, multi-temporal analysis performed at pixel level suffer from several restrictions, e.g., registration, bi-temporal analysis. To overcome these restrictions, two methods for multi-temporal analysis are proposed at patch level. One is for change detection in time series data by classifying all pairs of patches along time axis in the whole sequence into two classes. Features used for classification are similarity measures based on local statistical models and histogram of local patterns. The other aims at evolution analysis in long image time series. To characterize the evolution patterns, spatio-temporal local pattern features are extracted from time series data. ν-support vector machine (ν-SVM) is applied to classify different kinds of evolution at patch level. Performance is evaluated based on our database \n",
      "Actually the growing volume of data provided by different sources some times may present inconsistencies, the data could be incomplete with lack of values or containing aggregate data, noisy containing errors or outliers, etc. Then data cleaning consist in filling missing values, smooth noisy data, identify or remove outliers and resolve inconsistencies. In more general definition, data cleaning is a task to identify something that is unusual and try to correct it.\n",
      "This work presents a new approximation for the Kolmogorov complexity of strings based on compression with smallest Context Free Grammars (CFG). If, for a given string, a dictionary containing its relevant patterns may be regarded as a model, a Context-Free Grammar may represent a generative model, with all of its rules (and as a consequence its own size) being meaningful. Thus, we define a new complexity approximation which takes into account the size of the string model, in a representation similar to the Minimum Description Length. These considerations result in the definition of a new compression-based similarity measure: its novelty lies in the fact that the impact of complexity overestimations, due to the limits that a real compressor has, can be accounted for and decreased.\n",
      "The last two decades showed an important development of satellite imagery with past and present satellites acquiring enormous volumes of data. Meanwhile, the quality of the acquired images increased permitting the recording of high resolution images (0.6 divided by 2.5 meters/pixel) in multispectral bands. Thus, both the data volume and the information detail increase dramatically. Consequently, new methods and tools to access and interpret Earth Observation (EO) images are needed. The present paper presents a semantic search engine for High Resolution (HR) EO images based on a hierarchical information model of satellite image contents. To face the potentially ambiguos meaning of image structures depending on their contextual understanding, the search engine uses Bayesian inference to learn categories and a Support Vector Machine (SVM) classifier to assign semantics. The categories are grouping and memorising the semantics of image structures, facilitating their recognition in various contexts. Also the generation of categories helps learning from a small training data set (i.e. image examples); thus, the method is useful for the exploitation of very large data volumes. The concept has enhanced inferred power, therefore optimising the Human Machine Communication (HMC), which is enhanced with learning/unlearning functions.\n",
      "For automatic remote-sensing image interpretation it is important to give specific consideration to the resolution of the data. The performance of content-based retrieval systems can be enhanced significantly if the scale of spatial features is used explicitly as a meta feature. This allows to use low-dimensional feature vectors at each scale instead of a high-dimensional feature vector for all scales. The authors developed a system where the user can query for signal properties, like texture characteristics. He is encouraged to restrict the search space by indicating the scale he is interested in. The signal oriented search is done using indices that are computed completely unsupervised. These indices represent the characteristic signal classes of the data. The system does no interpretation of the classes. It is up to the user to name the contents according to his application interest.\n",
      "Forward modeling represents an emulation technique providing a numerical approximation of a physical process. Forward modeling is often applied to find a solution for problems where no direct inversion techniques are available. Typical examples are the determination of physical quantities that can only be found based on comparisons with successively refined models. Classical forward modeling often relies on learned guesses and practical experience. An overview will be given where this technique can be used profitably as a data analysis tool in remote sensing. We will show typical application areas such as imaging observations of land and water surfaces with optical and microwave instruments and compare the approaches with atmospheric retrieval techniques of a limb sounding instrument. Bridging the gap between practical experience and theoretical concepts, maximum likelihood calculations allow the …\n",
      "Semantic segmentation for synthetic aperture radar (SAR) imagery is a rarely touched area, due to the specific image characteristics of SAR images. In this research, we propose a dataset which consists of three data sources: TerraSAR-X images, Google Earth images and OpenStreetMap data, with the purpose of performing SAR and optical image semantic segmentation. By using fully convolutional networks and deep residual networks with pre-trained weights, we investigate the accuracy and mean IOU values of semantic segmentation for both SAR and optical image patches. The best Segmentation accuracy results for SAR and optical data are around 74% and 82%. Moreover, we study SAR models by combining multiple data sources: Google Earth images and OpenStreetMap data.\n",
      "In this paper, we propose to identify the number of categories that can be retrieved from a very high resolution SAR data. The evaluation is done on TerraSAR-X high resolution Spotlight data and the retrieved categories are semi-automatically annotated using as feature vector the Gabor filters; as a classifier the Support Vector Machine, and for ranking the suggested images the relevance feedback. The visualization of the tool was enhanced compared with our previous implementation in order to support the users in hislher approach to search the patches of interest in a large repository. Our dataset consist in 43 scenes that cover as much as possible all the regions over the world. A total of 352 categories are identified that contain urban and non-urban categories.\n",
      "Generally, the repository of a remote sensing system needs a capacity of hundreds of terabytes to archive original and processed data. There are several satellites whose downlink rates require ingesting over 100 GB into the archive each day. In order to process such a huge volume of data, to classify them, to index generated classes in the database, and to provide a quick access to stored information at real time, an image information mining system is developed. In this letter, we present the design of a system architecture for processing data from very large image archives.\n",
      "Recognizing scenes in a single look meter resolution Synthetic Aperture Radar (SAR) images, requires the capability to identify relevant signal signatures in condition of variable image acquisition geometry, arbitrary objects poses and configurations. Among the methods to detect relevant scatterers in SAR images, we can mention the internal coherence. The SAR spectrum splitted in azimuth generates a series of images which preserve high coherence only for particular object scattering. The detection of relevant scatterers can be done by correlation study or Independent Component Analysis (ICA) methods. The present article deals with the state of the art for SAR internal correlation analysis and proposes further extensions using elements of inference based on information theory applied to complex valued signals. The set of azimuth looks images is analyzed using mutual information measures and an equivalent …\n",
      "The analysis of discrimination, feature and model selection conduct to the discussion of the relationships between Support Vector Machine (SVM), Bayesian and Maximum Entropy (MaxEnt) formalisms. MaxEnt discrimination can be seen as a particularcase of Bayesian inference, which at its turn can be seen as a regularization approach applicable to SVM. Probability measures can be attached to each feature vector, thus feature selection can be described by a discriminative model over the feature space. Further the probabilistic SVM allows to define a posterior probability model for a classifier. In addition, the similarities with the kernels based on Kullback-Leibler divergence can be deduced, thus returning with MaxEnt similarity.\n",
      "Derived from Information Theory, the Information Bottleneck principle enables to quantify and qualify the information contained in a signal. This paper presents an algorithm based on the Information Bottleneck principle to analyze Satellite Image Time Series (SITS). The method is composed of a parameter estimation and a model selection. This method has been previously applied to textural and radiometric parametric models and we propose here to extend it to take into account the geometry information. Two approaches are presented. In the first approach, each image of the SITS is segmented and the obtained regions are described by textural models. The Information Bottleneck method is further used to characterize the image segments of the SITS a spatio‐temporal way. In the second method, the geometrical information is extracted from a temporal adjacency graph of the spatial regions, and the radiometric and …\n",
      "The new generation of high resolution imaging satellites acquires huge amounts of data which are stored in large archives. The state-of-the-art systems for data access allow only queries by geographical location, time of acquisition or type of sensor. This information is often less important than the content of the scene, ie structures, objects or scattering properties. Meanwhile, many new applications of remote sensing data are closer to computer vision and require the knowledge of complicated spatial and structural relationships among image objects. We are creating an intelligent satellite information mining system, a next generation architecture to help users to gather rapidly information during courses of actions, a tool to add value and to manage the huge amount of historical and newly acquired satellite data-sets by giving to experts access to relevant information in an understandable and directly usable form and to provide friendly interfaces for information query and browsing.\n",
      "The phase unwrapping is the key step in recovering the terrain elevations from Interferometric SAR (InSAR) data. The problem is to find an estimate of the phase values known the wrapped noisy phase observations. In this article the authors introduce a new Bayesian model based solution for the phase unwrapping using a multiscale stochastic process as a prior for the estimation of the terrain height.\n",
      "The constantly growing process of the Earth Observation (EO) data and their heterogeneity require new systems and tools for effectively querying and understanding the available data archives. In this paper, we present a tool for heterogeneous geospatial data analytics. The system implements different web technologies in a multilayer server-client architecture, allowing the user to visually analyze satellite images, maps, and in-situ information. Specifically, the information managed is composed of EO multispectral and synthetic aperture radar products along with the multitemporal in-situ LUCAS surveys. The integration of these data provides a very useful information during the EO scene interpretation process. The system also offers interactive tools for the detection of optimal datasets for EO multitemporal image change detection, providing at the same time ground-truth points for both human and machine analyses …\n",
      "This paper proposes a custom convolutional deep belief network for polarimetric synthetic aperture radar (PolSAR) data feature extraction. The proposed architecture stands out through the interesting features it shows, starting with the fact that it is adapted to fully polarimetric SAR data. Then, the multilayer approach allows the stepwise discovery of higher-level features. The convolutional approach allows the discovery of local, spatially invariant features and makes the architecture scalable to fully sized PolSAR images. The network is trained in an unsupervised manner, without using labeled data and then it succeeds to extract powerful features from PolSAR patches. This fact is demonstrated by applying supervised and unsupervised classification algorithms on features extracted from patches of a fully polarimetric multi-look F-SAR image over Kaufbeuren airfield, Germany.\n",
      "In this paper, we propose an Active Learning approach to query by example retrieval, using a retraining procedure that improves the understanding of the machine with respect to the human perception. The proposed method is based on Support Vector Machine (SVM) classifiers and requires a small number of training samples. The classifier is retrained several times in order to determine the optimal separating hyper-plane between the class of the query and the rest of the analysed image. The closest feature points to the SVM-learned hyper-plane are the points being able to produce the most relevant modification of the position of this hyper-plane. These points, that are both negative and positive examples, are then used to retrain the SVM classifier. In addition, the proposed approach shows the importance of normalization in a classification problem with heterogeneous objects. Several experiments were conducted on GeoEye-1 multispectral images, whilst the retrieval was performed for different patch-level descriptors, which furthermore increases the complexity of the semantic content of the query object.\n",
      "In this paper, we propose a semi-automated hierarchical clustering and classification framework for synthetic aperture radar (SAR) image annotation. Our implementation of the framework allows the classification and annotation of image data ranging from scenes up to large satellite data archives. Our framework comprises three stages: 1) each image is cut into patches and each patch is transformed into a texture feature vector; 2) similar feature vectors are grouped into clusters, where the number of clusters is determined by repeated cluster splitting to optimize their Gaussianity; and 3) the most appropriate class (i.e., a semantic label) is assigned to each image patch. This is accomplished by semi-supervised learning. For the testing and validation of our implemented framework, a concept for a two-level hierarchical semantic image content annotation was designed and applied to a manually annotated reference dataset consisting of various TerraSAR-X image patches with meter-scale resolution. Here, the upper level contains general classes, while the lower level provides more detailed subclasses for each parent class. For a quantitative and visual evaluation of the proposed framework, we compared the relationships among the clustering results, the semi-supervised classification results, and the two-level annotations. It turned out that our proposed method is able to obtain reliable results for the upper-level (i.e., general class) semantic classes; however, due to the too many detailed subclasses versus the few instances of each subclass, the proposed method generates inferior results for the lower level. The most important contributions of this paper are the integration of modified Gaussian-means and modified cluster-then-label algorithms, for the purpose of large-scale SAR image annotation, as well as the measurement of the clustering and classification performances of various distance metrics.\n",
      "Over the last two decades, dimension reduction for visualization has gained a high amount of attention in visual data mining where the data is represented by high-dimensional features. Basically, this approach leads to an unbalanced and occluded distribution of visual data in display space, giving rise to difficulties in browsing the data. In this paper we propose an approach for the visualization of image collections in such a way as (1) images are not occluded by each other, and the provided space is used as much as possible; (2) the similar images are positioned close together; (3) an overview of data is feasible. To fulfill these requirements, we propose to use regularized Nonnegative Matrix Factorization (NMF) controlled by parameters to reduce the dimensionality of data. Experiments performed on optical and radar images confirm the flexibility of proposed method in visualizing large-scale visual data. Finally, an …\n",
      "Feature learning algorithms aim to provide a compact and discriminative representation of complex datasets in order to increase the speed and accuracy of clustering or classification. In this paper, we propose a novel interactive feature learning approach which is mainly based on 3D interactive data visualization and Non-negative Matrix Factorization (NMF). Here, the data is visualized in a 3D interface to support human-data interaction. The user interactions are exploited in an NMF framework to learn a compact representation of the data. The conducted experiments on Synthetic Aperture Radar (SAR) images confirm the efficiency of the proposed approach.\n",
      "In this paper we present the LUCAS Visual Browser system, a tool for land cover visual analytics. The system implements different web technologies in a multilayer server-client architecture in order to allow the user to visually analyse land cover heterogeneous information. The information manage is composed of EO multispectral and SAR products along with the multitemporal in situ LUCAS surveys. The fusion of these data provides a very useful information during the EO scene interpretation process. Furthermore, the system offers interactive tools for the detection of optimal datasets for EO multitemporal image change detection, providing at the same time ground truth points for both, human and machine analysis.\n",
      "Modeling of synthetic aperture radar (SAR) images has been an important topic of research since the inception of SAR satellites. Many theoretical and empirical models have been presented in literature to accurately model the amplitude SAR images. The method of parameters estimation of the probability density function (PDF) for selected models is another topic of research associated with modeling. Earlier the maximum-likelihood (ML) methodology or the methods of moments (MoM) were used for the parameter estimation. The method of logarithmic-cumulants (MoLC), which has been proposed for the parameter estimation for the PDF defined in R + , is now a very popular tool for the efficient parameter estimation for amplitude SAR images. In this article, we present a survey of some of the well-known PDFs proposed for SAR amplitude images by carrying out the parameter estimation with the MoLC method. The …\n",
      "This paper presents an implementation of query by example in Earth Observation image archive using data compression-based approach. Data compression approach allows to exploit the compression properties of the objects and to estimate the shared information between them, this concept is extended to image retrieval for finding similar objects in the image archive. Our implementation is based on LZW algorithm for compressing the image content and extracting features of the images. The fast compression distance (FCD) is defined as a similarity metric in order to retrieve the most similar images. This tool is satisfactory implemented and tested using optical and SAR images.\n",
      "The artifacts detection is a step of data cleaning process. The classical approach is to predict or determine the existence of defects, to model it, and then design a method to detect and correct them. This classical approach is for specific artifacts. The approach presented in this work is using complexity distortion theory to implement a more generic method, thus, this work will aim at developing parameter free methods able to automatically detect artifacts in EO images. We use the Kolmogorov Structure Function as approximation to the Rate-distortion curve and examine how the artifacts can have the same structure.\n",
      "The dramatic increase in satellite images spatial resolution makes difficult to fully capture high-complexity structures in urban areas. We introduce a multiresolution approach employing a single image to characterize structures using Gibbs-Markov Random Fields. Texture parameters are also extracted from downsampled and oversampled versions of the image: while the former allows considering individual objects as part of more homogeneous textures, the latter moves the texture detection on the object, exploiting the smooth edge transitions to capture better the analyzed structures with the adopted texture model. Examples of analysis at multiple scales improving feature classification and object detection with optical data are presented.\n",
      "In this paper, we present a semi-supervised method for auto-annotating image collections and discovering unknown structures among them. The approach relies on the existence of only a small training database of annotated examples. First, a fully-supervised algorithm using annotated samples is presented. Next, we introduce a semi-supervised procedure which allows us to incorporate unannotated samples and to infer the existence of unknown structures, that is, the existence of new image classes which are not represented in the training database. Finally, we present experimental results from a database of satellite images and briefly mention the possibility of reusing the presented approach as a basis for more complex systems such as Content Based Image Retrieval (CBIR) systems.\n",
      "Earth observation optical images may contain blemishes or artificial structures that come from processing or directly from the sensors. These artifacts decrease the quality of the images and can lead to analysis and interpretation problems. We are interested in detecting these defects automatically. We develop an approach based on an information-theoretic analysis of the image formation process, which is inspired by methods already used in domains dealing with similar problematics like image quality or information hiding. In this letter, we propose a method based on a rate distortion analysis, exploiting the local regularity properties of the image.\n",
      "The properties of single look complex SAR satellite images have already been analyzed by many investigators. A common belief is that, apart from inverse SAR methods or polarimetric applications, no information can be gained from the phase of each pixel. This belief is based on the assumption that we obtain uniformly distributed random phases when a sufficient number of small-scale scatterers are mixed in each image pixel. However, the random phase assumption does no longer hold for typical high resolution urban remote sensing scenes, when a limited number of prominent human-made scatterers with near-regular shape and sub-meter size lead to correlated phase patterns. If the pixel size shrinks to a critical threshold of about 1 meter, the reflectance of built-up urban scenes becomes dominated by typical metal reflectors, corner-like structures, and multiple scattering. The resulting phases are hard to …\n",
      "Texture models are widely in use for image content description. In remote-sensing images textures occur at very different scales, requiring the application of multiple texture models. We present an algorithm based on a multi-scale random field model to detect the characteristic scales at which textures are present, so that texture models can be applied to a few selected scales only. The algorithm is compared to two other models based on Haralick and wavelet features. Such a scale selection scheme reduces computation time and minimizes the index size. Both are critical parameters in the design of large remote-sensing databases with content-based retrieval services.\n",
      "A new scheme for reconstructing scene topography using both interferometric phase and backscattering intensity is presented. We use the framework of Bayesian theory and look for the scene topography which best explains the observed data. We iteratively improve the estimation changing the topography and simulate, in the Lambertian approximation, a SAR image to be compared to the real one. The fidelity to the observed interferogram is expressed in terms of the phase-difference between the simulated and the observed phase. The regularity of the scene topography is expressed as a Gibbs Random Field. This allows us to obtain an energy to be minimized. The solution of this optimization problem is obtained by a relaxation method.\n",
      "5 Conclusions The present paper presents an automatic method for the detection of errors and artifacts in the generation of\n",
      "The qualified Earth Observation (EO) images sometimes may present unexpected artifacts. These perturbations and distortions can make more difficult the analysis of images and may decrease the efficiency of interpretation algorithms because the information is distorted. Thus is necessary to implement methods able to detect these artifacts regardless of the model which are formed, i.e. parameter free. In this article, we propose and present a method based on data compression, whether lossy compression or lossless compression for detecting aliasing, strips, saturation, etc.\n",
      "High resolution remote sensing SAR images - such as the image data acquired by the German TerraSAR-X mission - contain a variety of details that have to be extracted by automated processing in order to fully exploit and understand the image content. In particular, the interpretation of man-made structures that are typical of built-up or agricultural areas poses a number of challenges including parameterized image focusing during routine processing, careful despeckling, descriptor and feature extraction, and final classification including specific scattering and 3D effects. Therefore, we propose a set of general sequential as well as dedicated application-dependent processing steps that allow user-oriented classification of high resolution SAR images. We will also report on actual classification results and experiences.\n",
      "The paper presents two algorithms for texture primitive feature extraction on Single Look Complex (SLC) and Polarimetric Synthetic Aperture Radar (PolSAR) SLC data. We assume the data to be modeled by a Gauss-Markov Random Field (GMRF): a complex GMRF model for characterizing the spatial correlation in SLC data and an extension of the model for inter-band correlation characterization. The complex GMRF characterizes the spatial relationship of a two-dimensional complex signal, i.e. SLC SAR data. The extended model characterizes the spatial interaction and the inter-band pixels correlation between the polarimetric complex channels. The Bayesian approach permits to deal with model fitting and selection in a direct way. The results are presented on a polarimetric E-SAR L band scene of Mannheim, Germany.\n",
      "We present a complete processing line to generate an object based description of optical Remote Sensing (RS) images. A segmentation algorithm is used to generate a partition of regions and simplify the volume of data. Results are still at the pixel level. Based on topology analyses, a dynamical algorithm is proposed to retrieve, extract the segmented regions and encode them in a tree structure which describes their topological relations (adjacencies, inclusions). The overall collected information constitutes a consistent and independent database, generated efficiently on standard workstation. Many applications are possible, such as content based image retrieval, image description and compression, object classification or image-object fusion. A scenario is presented to emphasize interest of the method in the case of 3D visualization enhancement: Image-objects are integrated on elevation data (Digital Elevation Models, DEM) in order to generate more realistic rendering.\n",
      "The exploitation of meter resolution SAR data for the reconstruction of the structure of the observed scenes poses specific problems related both to the complexity of acquired scene details and to the peculiarities of the SAR acquisition system. On the one hand, much more complexity is transferred through the system from the scene into the data: new kinds of complex man-made scene objects are acquired. Layover and shadowing and responses from single scatterers tend to dominate the data. On the other hand, multiple signal reflections, sidelobe effects, radiometric pollution and many other effects related to the increased resolution of the system have to be taken into account. We show how, by properly modelling in stochastic terms the peculiarities of both the acquisition system and of the scene and by composing them in a Bayesian framework, new methods are developed that allow the reconstruction of the imaged structures from SAR data. Particular interest is devoted to the application of the developed algorithms in urban environments on data resolutions ranging from a few meters to fifty centimeters.\n",
      "We present a Bayesian segmentation algorithm which is part of a fully Bayesian approach for automatic information extraction from satellite images. It was shown that pyramidal image models based on multi-scale Markov random fields in combination with a texture model yield good classification and segmentation results. The texture model is used for an initial characterization and then an optimal segmentation is inferred using the multi-scale random field defined on a pyramid structure. Segment probabilities are calculated in a fine-to-rough analysis and segmentation is performed by a rough-to-fine decision algorithm that maximizes the a posteriori probability for the pyramid. The procedure is iterated until it converges to a stable solution. We improve the maximization procedure by optimizing the underlying pyramidal structure of the multi-scale Markov random field. Neighborhood dependencies are …\n",
      "An approach for texture reconstruction in noisy images is presented. The reconstruction is achieved by a denoising algorithm using Gauss Markov random fields as texture models and taking advantage of both the first and the second level of Bayesian inference to obtain a MAP estimate of the noise-free image and an estimate of the model parameters, respectively. For noise-free images exist several techniques for parameter estimation. In the noisy case, however, parameter estimation becomes much more difficult. In order to obtain the best possible texture reconstruction we propose an iterative algorithm to estimate the parameters that provide the highest evidence. This results in an optimization problem where we use the current MAP estimate of the noise-free image to calculate an approximated model evidence for a given set of parameters and adjust these parameters accordingly.\n",
      "In this letter, a velocity estimation method for moving ships in synthetic aperture radar (SAR) images is proposed based on a subaperture decomposition technique. In contrast to traditional methods, our method needs only a few SAR imaging parameters besides the SAR image itself. The behavior of moving ships in subaperture images is theoretically analyzed, and the ship motion parameters in azimuth direction are accurately estimated. The proposed approach was tested on real SAR stripmap images acquired by TanDEM-X, a twin satellite SAR constellation. The estimated azimuth velocities perfectly fit the data recorded by the international automatic identification system.\n",
      "An effective monitoring and analysis of ecosystems requires developing new tools and knowledge. In this paper, we propose an approach for detecting land-cover changes using satellite Image Time Series. This approach represents each image by spectral indices and then extracts local features of these representations. Next, a clustering technique (e.g., k-means) is applied to the extracted features, where the resulting clusters are assumed to refer to land-cover classes. The land-cover change is then obtained by counting the number of times an assigned class to each point changes along the time series. For our experiments, we use a collection of Landsat-5 images captured every second month from October 2009 to August 2010 over the protected area of the Doñana National Park in southwestern Spain, which is the largest sanctuary for migratory birds in western Europe. Results demonstrate that the proposed …\n",
      "In this paper, we apply and evaluate a modified Gaussian-test-based hierarchical clustering method for high-resolution satellite images. The purpose is to obtain homogeneous clusters within each hierarchy level which later allow the classification and annotation of image data ranging from single scenes up to large satellite data archives. After cutting a given image into small patches and feature extraction from each patch, k-means are used to split sets of extracted image feature vectors to create a hierarchical structure. As image feature vectors usually fall into a high-dimensional feature space, we test different distance metrics, to tackle the “curse of dimensionality” problem. By using three different synthetic aperture radar (SAR) and optical image datasets, Gabor texture and Bag-of-Words (BoW) features are extracted, and the clustering results are analyzed via visual and quantitative evaluations. We also compared …\n",
      "Earth observation (EO) images clustering is a challenging problem in data mining, where each image is represented by a high-dimensional feature vector. However, the feature vectors might not be appropriate to express the semantic content of images, which eventually lead to poor results in clustering and classification. To tackle this problem, we propose an interactive approach to generate compact and informative features from images content. To this end, we utilize a 3-D interactive application to support user-images interactions. These interactions are used in the context of two novel nonnegative matrix factorization (NMF) algorithms to generate new features. We assess the quality of new features by applying k-means clustering on the generated features and compare the obtained clustering results with those achieved by original features. We perform experiments on a synthetic aperture radar (SAR) image \n",
      "Automated recognition of SAR images requires feature extraction from complex-valued data. In this work, complex-valued interferometric SAR (InSAR) images, which are mainly used to construct elevation models, are proposed for feature extraction. Feature extraction based on the log-cumulants of fractional Fourier transform (FrFT) coefficients has already been proposed in the literature and found to be quite successful for the classification of single-look complex (SLC) SAR images. Here, this method is applied to the complex-valued InSAR and newly introduced complex-valued phase gradient InSAR (PGInSAR) images. In order to evaluate the classification performance for SLC, InSAR and PGInSAR images, a database of bistatic TanDEM-X interferometric pairs is constructed, and a supervised KNN classification is performed. The overall classification accuracies for a 4% training set size show that the use of …\n",
      "In this paper, we present an accelerated knowledge-driven content-based information mining system for Big Earth Observation data fusion. The tool combines, at pixel level, the unsupervised clustering results of different number of features. The features, extracted from different EO raster image types and from existing GIS vector maps, are combined, in form of a BoW, with a user given semantic concepts in order to calculate the posterior probability that allows the final search. The inclusion of GIS data during the active learning, based on Bayesian networks, accelerate the definition processes of semantic labels and retrieve the related images with only a few user interactions. The inclusion of GIS data in conjunction with the recently introduced search algorithm have as a result a system which greatly optimizes the computational costs and over performs existing similar systems in various orders of magnitude.\n",
      "The increasing amount of high resolution Earth Observation (EO) data during recent years, has brought the content analysis of the provided data into the spotlight. Most of the current content analysis is based on unsupervised methods (e.g., clustering). However, the structure discovered by these methods is not necessarily human understandable. Moreover, they require some prior knowledge of the structure of the data for initialization. In this paper, we propose an interactive method to discover the semantic structure behind SAR image collections. Thus, we use a modified version of k-means, namely weight-balanced k-means, to perform clustering on the given images. The interaction mechanism allows users to provide the clustering method with relevant knowledge about the structure of the data. Experimental results demonstrate that the structure discovered by the proposed interactive method is closer to human understanding of the data.\n",
      "The extraction of different parts of the spectrum from complex-valued synthetic aperture radar (SAR) images is equivalent to selecting a same number of low-resolution images, each of which is acquired using a sub-antenna. This subantenna can be viewed as a part of azimuth squint angle and a part of the range chirp bandwidth in the full synthetic aperture. Due to this process, which is also called sub-aperture extraction, it is not possible to apply traditional band-pass filters to complex-valued SAR images using modulated window-based multi-scale approaches (such as wavelet decomposition). Thus, in this paper we proposes the use of a chirplet-derived transform, that is, the fractional Fourier transform (FrFT), as an alternative scaling approach, where the scaling is carried out in phase. We also underline the physical significance of classical wavelet decomposition for complex-valued SAR images, demonstrating that this is equivalent to a modulated sub-aperture extraction or aspect angle filtering rather than shape filtering.\n",
      "Earth Observation satellites acquire huge volumes of high resolution images continuously increasing the size of the archives and the variety of EO products. However, only a small part of this data is exploited. In this paper, we present how we take advantage of the TerraSAR-X images of the German Aerospace Center in order to build applications on top of EO data.\n",
      "In this paper we propose to identify the number of urban categories that can be retrieved from very high resolution TerraSAR-X data. For this task a semi-automated procedure was built in order to search in large Earth Observation database for similar sub-images (i.e. patches) and group them in the same semantic category. The dataset consists of 39 scenes over the world: 18 scenes in Asia, 15 scenes in Europe, 5 scenes in North and South America, and 1 scene in Africa. These scenes are grouped in three different types of collections (a total of 16 collections are generated) and the semantic categories in each collection are retrieved. A total of 320 categories are identified and those that contain man-made structures in the urban area are kept and the rest of categories (e.g., agriculture, water, etc.) are discarded. These categories represent between 50\\% and 65\\% from the total number of retrieved categories in each collection.\n",
      "Satellite image time series (SITS) can be described in an unsupervised way by means of spatio-temporal localization maps. These maps are extracted using data mining techniques that spatially and temporally locate pixel evolutions affecting a minimum number of pixels with sufficiently high connectivity. Depending on the parameter settings and on the original data, large numbers of maps may be produced. In order to focus on the most interesting ones, we propose a method to rank them by computing the normalized mutual information between the spatio-temporal localization maps extracted from the SITS and the ones extracted from the same but randomized SITS. The latter is obtained using a swap-randomization technique. Experimental results on a Landsat 7 SITS covering New Caledonia are presented.\n",
      "In natural hazards management applications Earth Observation (EO) image processing methods are based on segmentation and classification. The result primary consists of thematic maps which are readily interpretable. We propose a complete EO image processing chain, which generates an end product with increased information content organized in thematic layers. The processing chain integrates four main components: image classification, identification of high anomaly areas relative to the entire scene context, spectral and texture change detection, and the integration of different information layers. The processing chain was tested in a fire management scenario, using a pair of Landsat5-TM images for the Pagami Creek forest fire which was active from August to October 2011.\n",
      "Aperture Radar images depends by the used parameters and incidence angle. The evaluation is done on the high resolution SAR data and the interpretation is realized automatically. In this paper, we propose to study and asses the behavior of the primitive feature extracted methods for images of the same scene with 2-3 look angles covering the min-max range of the sensor. The tests are done on TerraSAR-X products High Resolution Spotlight mode at 3 m resolution and two sites were found that are appropriate for this. To identify the best features and appropriate incidence angle for them the Support Vector Machine and as a measure of the classification accuracy the precision–recall were considered. The precision-recall was computed first for all investigated features and after that the best were taken into account for the incidence angle evaluation.\n",
      "This paper provide systematic results of the influence of the Synthetic Aperture Radar image structure descriptors with incidence angle and orbit direction. The evaluation is done on TerraSAR-X data and the interpretation is done semi-automatically. In the first part, we study and assess the behavior of the primitive feature extracted methods for images of the same scene with 2 look angles covering the min-max range of the sensor. After that the influence of the orbit looking is shortly discuss. The tests are done on TerraSAR-X products High Resolution Spotlight mode at 3 m resolution and two sites covering the Berlin and Ottawa area are found to be suitable for this investigation. To identify the best features and appropriate incidence angle for them the Support Vector Machine and as a measure of the classification accuracy the precisionrecall were considered. The recall shows that the optimal value of the incidence angle in order to have a higher classification is obtained for a value of the incidence angle closer to upper bound of the sensor range. In the second part of the paper a list of queries that can be asked by Earth Observation users are presented and proposed to be implemented in the next generation of our system. The first contribution of this paper is the evaluation of four primitive features that are very known (gray level cooccurrence matrix, Gabor filter, quadrature mirror filter, and non-linear short time Fourier transform) but not used and compared for SAR images. After the best primitive feature is identified the second contribution of this paper lies in the fact that the parameters of the data namely, incidence angle and orbit direction are \n",
      "Classical SAR image analysis methodologies face hard challenges with the advent of satellites capable of acquiring images up to 1 m resolution: the details observable in the image grow exponentially making the classification task very hard, although the resolution is not yet high enough to enable target recognition tasks. Furthermore, these applications are usually strongly dependant on the assumed models and estimated parameters, which could either underfit the data, failing to capture relevant information, or overfit them, introducing nuisance. The method proposed in this article aims at discovering common patterns within the data, without any a priori assumption, relying on data compression-based techniques: its main advantage lies in the fact that it is totally parameter-free and data-driven. Results obtained on TerraSAR-X data are presented.\n",
      "In this paper we compare parametric and non-parametric method for the analysis of complex valued high-resolution SAR data. Gauss-Markov Random Field (GMRF) model with a quadratic energy function as a parametric analysis parameterizes the spectogram of the signal, whereas nonlinear short time Fourier transform (STFT) method, the method based on time frequency analysis (TFA) as a non-parametric approach exploits the signal's non-stationarity in the time-frequency domain for information extraction. This comparative analysis helps to understand, characterize and analyze complex valued SAR data.\n",
      "SAR images are affected by speckle which is a coherent process modelled as a multiplicative noise. It makes the automatic image classification difficult. Thus, many methods have been developed to remove speckle from SAR images while preserving the useful information of the image such as texture. This paper presents an evaluation of texture extraction parameter estimation methods using Cramer-Rao lower bound (CRLB). The first evaluated method is model-based despeckling (MBD) algorithm, which uses Gauss-Markov random fields as prior. The second one is the maximum a posteriori auto-binomial method (MAP-ABM), which rather uses auto-binomial model as prior. The evaluation has been carried out using simulated SAR data. In here, data with increasing number of looks have been used in order to study 1) how the estimated parameters approach the real one, and 2) how their variances get closer to CRLB. The experimental results show the superiority of MBD parameter estimation. Both MBD and MAP-ABM provide the most robust texture parameters when the number of look is between 3 and 4.\n",
      "this paper proposes complexity based analysis as a valid alternative to classic image analysis methodologies for Earth Observation imagery, which are heavily dependant on the assumed data models. We will show the power of this totally model-free, data-driven methods by presenting three very different applications relying on complexity based analysis: image classification, artifact detection, and database compression which enables queries directly on the compressed content.\n",
      "With the increase of Synthetic Aperture Radar (SAR) sensor resolution, SAR images could include a large variety of interesting real man-made structures. Therefore, a more detailed analysis and a finer description of SAR images of urban areas are needed for a better understanding of the scene. Nevertheless, recognizing scenes using high resolution SAR images requires the capability to identify relevant signal signatures (called also descriptors), depending on variable image acquisition geometry, arbitrary objects poses and configurations. Among feature extraction methods, we propose to use Principal Components Analysis (PCA) and/or Independent Components Analysis (ICA), in order to exploit deeper the nature of SAR signatures. In this paper, both a description of our work and a presentation of our preliminary classification performance results will be provided.\n",
      "This paper presents a method which extracts information from Satellite Image Time Series which are new type of data set acquired with remote sensing technologies. The method is based on Multi-Information Bottleneck theory. The principle of inference for data clustering and clusters number selection is presented. Finally, the paper concludes showing examples presenting an information extraction from Satellite Image Time Series.\n",
      "The progress in information retrieval, computer vision and image analysis makes possible to establish very complete bases of algorithms and operators. A specialist in remote sensing or image processing has the tools now allowing him, at least in theory, to configure applications solving complex problems of image understanding. However, in reality, the Earth Observation data analysis is still performed in a very laborious way at the end of repeated cycles of trial and error. To this end we propose a novel advanced remote sensing information processing system, based on Human Centered Concepts, which implement new features and functions allowing improved feature extraction, search on a semantic level, the availability of collected knowledge, interactive knowledge discovery and new visual user interfaces.\n",
      "Due to the huge volume and high complexity of remote sensing data, the management of image archives demands high level representation of information. Augmentation of the data with meaning is a key issue for the success of query processes, and has to include the model of user's understanding. The information retrieval process is split up into two steps: objective information extraction and semantic representation. These concepts are applied for the design of a new generation of remote sensing ground segment systems.\n",
      "The paper describes a new model for the correction of topographic effects in satellite images of snow covered rough terrain. The model simulates a synthetic image of the scene using a computer graphics approach which combines ray-tracing techniques with radiosity methods to render accurately both diffuse and specular reflections. Computation is structured on three levels: a macro level in which the image is described by the Digital Elevation Model, the position and physical properties of the light source and global atmospheric effects, a meso-scale in which the model simulates the integration effect of the imaging sensor and a micro-scale which is characterized by the reflectance of the snow cover (specular and diffuse reflections). After setting up the model, its parameters are tuned with a gradient search to fit real images acquired from the Landsat-TM sensor. The results show a good coincidence between synthetic and real images and prove the validity of the suggested image formation model.\n",
      "A new model for the correction of topographic effects in satellite images of rough terrain is described. The model simulates a synthetic image of the scene using a computer graphics approach which combines ray-tracing techniques with radiosity methods. Computation is structured on three levels: a macro level in which the image is described by the Digital Elevation Model and the light source, a meso-scale in which the model simulates the integration effect of the imaging sensor and a micro-scale which is characterized by the reflectance of the snow cover (specular and diffuse). The parameters of the model are tuned with a gradient search to fit real images acquired by the Landsat-TM sensor. The results show a better accuracy than the classical cosine of incidence and Minnaert models. Additionally a new technique based on maximum entropy estimation is used to determine the reflectance function of snow and compare it with the one predicted by our model.\n",
      "Unmanned Aerial Vehicles (UAVs) have been involved in a wide range of remote sensing applications. In particular, recent developments in robotics, computer vision, and geomatics technologies have made it possible to capture a huge amount of visual data with low-cost UAVs. As a kind of rapid, flexible and low-cost data acquisition system, UAVs have shown great potential to perform numerous surveying, mapping, and remote sensing tasks with extremely high-resolution data in low altitude flying and imaging conditions. However, such developments have also brought a plenty of challenges to the data processing for aerial remote sensing, photogrammetry, and geo-spatial information. Recently substantial research has been devoted to the analysis of UAV data, eg understanding and modeling the urban environment with visual information from multiple sensors. The aim of this special issue of Geo-spatial \n",
      "Satellite Image Time Series (SITS) are widely used in monitoring the Earth's changes for various applications such as land-cover evolution analysis. In this paper, we propose an approach based on Latent Dirichlet Allocation (LDA) which considers spatial and spectral information to measure the land-cover changes in multispectral SITS. For our experiments, we focus on the vegetation dynamics of the Donana National Park (in southwestern Spain) using a Landsat and a Sentinel-2 SITS dataset. The proposed approach represents each image by Normalized Difference Vegetation Index (NDVI) and tiles it into smaller patches. The patches are then modeled as Bag-of-Words (BoW) and LDA is applied to them in order to discover the latent structure of the image. The divergence between the latent structures of any two consecutive images is then considered as the measure of change. Results show that the changes measured by the proposed approach can represent the vegetation dynamics of the region of interest. Moreover, comparing the results obtained from the two datasets demonstrates that using high-level information allows the proposed approach to measure the changes independent of the sensor. This will support long-term monitoring through combining various available data.\n",
      "When we perform image content classification by appending semantic labels to regularly cut image patches, we have to be sure that the selected patch size is a good choice for the images at hand. In the following, we look at SAR (Synthetic Aperture Radar) satellite images, and analyse the impact of the selected patch size on the attainable classification accuracy. For test images with precisely known ground truth, one can determine the true precision / recall performance of the applied classification method. In our case, we interactively trained a classifier system via active learning, and compared the resulting classification accuracy for high and medium resolution SAR images of different space borne instruments taken over urban areas, characterized by a high diversity of target categories. At a first glance, it turns out that the selected patch size does have a significant impact leading to a varying number of identified \n",
      "In this paper we present the Earth Observation Image Librarian (called EOLib) as a new generation of Image Information Mining Systems. EOLib is operated in the Payload Ground Segment of TerraSAR-X. The main goal of EOLib is to provide semantic annotations of satellite image content and offer to the end user a semantic catalogue via a web user interface. Moreover, EOLib has more functionality such as searches based on image metadata and semantics, visual exploration of the image archives, metadata extraction, etc. The system consists of components such as a query engine, knowledge discovery in databases, visual data mining, epitome generation, and user services. EOLib is able to ingest a TerraSAR-X scene with 8000×8000 pixels in about three minutes. The EOLib workflow starts with the ingestion of a scene, it continues with the semantic annotation of the image content based on machine learning methods, and it ends with publishing the semantic catalogue and enabling the search by metadata and semantic image descriptions.\n",
      "In this paper, we consider the problem of satellite image classification, in which feature extraction is a critical step. One of the most prevalent methods is the Bag-of-Words (BoW) feature representation, which attains state-of-the-art performance in many applications. It has five steps: feature detection, local feature extraction, dictionary learning, feature coding, and feature pooling. In this paper, we focus on the second and third step. We propose a simple yet efficient feature extraction method within the BoW framework. It has two main advantages. Firstly, this method does not need any complex local feature extraction; instead, it uses directly the pixel values from small windows as low level features. Secondly, instead of using a time-consuming clustering algorithm for dictionary learning, a random dictionary is built and applied to feature space quantization. An extensive experimental evaluation has been performed and …\n",
      "Several algorithms for polarimetric synthetic aperture radar (PolSAR) data indexing and classification were proposed in the state of the art literature. In particular, one of them computes powerful, compact feature descriptors composed of the first three logarithmic cumulants of the BiQuaternion Fractional Fourier Transform (BiQFrFT) coefficients of PolSAR patches. Since the BiQFrFT of each patch is computed at three different angles, the algorithm's result consists in nine complex-valued features (18 real-valued features) for single polarization images and in nine biquaternion-valued features (72 real-valued features) for fully polarimetric images. In this paper feature selection based on mutual information (MI) is employed to optimally select a subset of features, in order to improve the indexing performances and to minimize the classification error. The improved results are shown on two polarimetric images: a L-band PALSAR image over Danube's Delta, Romania and a C-band RadarSAT2 image over Br??ila, Romania. ?? 2015 IEEE.\n",
      "In the context of earth observation, different sensors have been used to acquire satellite images and it becomes a research topic about how to analyse and use multi-sensor images. In this paper, we carry out a study of multi-sensor satellite image indexing. The goal is to study which kind of satellite image provides more information for classification. To this end, we prepared four datasets covering four typical cities. Each dataset consists of three kinds of images: multispectral and panchromatic images from WoldView-2, Synthetic Aperture Radar (SAR) images from TerraSAR-X satellite. Image indexing is performed at patch level with the same feature extraction method. The indexing is carried out using an active learning system we developed before. A series of independent and joint indexing by combining the features have been performed. Through this study, we found that the indexing accuracy on SAR images is the worst. By contrast, the joint indexing by concatenating the features computed from each kind of image could provide best accuracy. Thus, we conclude that combing information from multi-sensor images could achieve better results than using each kind of image independently.\n",
      "The multitude of sensors used to acquire Earth Observation (EO) images have led to the creation of an extremely various collection of data. Along with appropriate methods able to work with great amount of data, informat ion retrieval process requires algorithms to cope with a range of input imagery. Even if the geometry and the manner of creating Synthetic Aperture Radar (SAR) images are totally different than multispectral data, there are attempts of finding a common ground such that optical image indexing algorithms can be applied for SAR data and vice versa. Moreover, new concepts must be defined in order to obtain satisfying results, enabling measurements and comparisons between the extracted features [4]. Regarding this idea, the goal is to develop an application capable to join feature extraction algorithms and classification algorithms . Its success will sustain the integration of a reliable EO data search engine. This paper presents a framework for feature extraction and classification aiming to support EO image annotation. Weber Local Descriptors (WLD), Gabor filter and Support Vector Machine (SVM) are combined in order to define an application to be tested on both SAR and optical data.\n",
      "Content-Based Image Retrieval (CBIR) systems are powerful search tools in image databases that have been little applied to hyperspectral images. Relevance feedback (RF) is an iterative process that uses machine learning techniques and user's feedback to improve the CBIR systems performance. We pursued to expand previous research in hyperspectral CBIR systems built on dissimilarity functions defined either on spectral and spatial features extracted by spectral unmixing techniques, or on dictionaries extracted by dictionary-based compressors. These dissimilarity functions were not suitable for direct application in common machine learning techniques. We propose to use a RF general approach based on dissimilarity spaces which is more appropriate for the application of machine learning algorithms to the hyperspectral RF-CBIR. We validate the proposed RF method for hyperspectral CBIR systems over a real hyperspectral dataset. (C) 2013 Elsevier B.V. All rights reserved.\n",
      "In this paper, a cascade active learning approach relying on a coarse-to-fine strategy for evolution pattern indexing is developed, which allows fast indexing and hidden spatial and temporal pattern discovery in multi-temporal SAR images. In this approach, a hierarchical multi-level image representation is adopted and each level is associated with a specific patch size. SVM active learning is applied at each level to obtain reliable samples and reduce the manual effort in labeling the images. When moving to a new level, all the negative patches are neglected and the learning at the new level focuses only on the positive patches. In this way, the computation burden in annotating large data set could be remarkably reduced while keeping the accuracy. Through temporal pattern retrieval, the cascade active learning has been compared with a baseline SVM active learning operating only at the last level in terms of both accuracy and time complexity. We have demonstrated that cascade active learning can not only achieves better accuracy but also reduce remarkably the computation time.\n",
      "Urban areas around the world are rapidly changing in an unregulated manner and remote sensing is the most effective option for their monitoring and planning. Good modeling of urban areas means reliable translation of the scene semantics into an algorithmic language. The compression based image retrieval techniques are data driven. The intention of employing compression based image retrieval techniques is to exploit the compression properties of the objects and estimate the shared information between them. Fast compression distance (FCD) is the similarity metric used in a compression based image retrieval technique that can be applied on large datasets. FCD between any two objects can be computed using the sizes of their dictionaries (sequence of recurring patterns) extracted through compression with LZW algorithm and the intersection of their dictionaries. In this paper, it is proposed to assess high \n",
      "In the context of image search and classification, we describe an active learning strategy that relies on the intrinsic data distribution modeled as a mixture of Gaussians to speed up the learning of the target class using an interactive relevance feedback process. The contributions of our work are twofold: First, we introduce a new form of a semi-supervised C-SVM algorithm that exploits the intrinsic data distribution by working directly on equiprobable envelopes of Gaussian mixture components. Second, we introduce an active learning strategy which allows to interactively adjust the equiprobable envelopes in a small number of feedback steps. The proposed method allows the exploitation of the information contained in the unlabeled data and does not suffer from the drawbacks inherent to semi-supervised methods, e.g. computation time and memory requirements. Tests performed on a database of high-resolution satellite images and on a database of color images show that our system compares favorably, in terms of learning speed and ability to manage large volumes of data, to the classic approach using SVM active learning.\n",
      "The increasing number and resolution of earth observation (EO) imaging sensors has had a significant impact on both the acquired image data volume and the information content in images. There is consequently a strong need for highly efficient search tools for EO image databases and for search methods to automatically identify and recognize structures within EO images. Content Based Image Retrieval (CBIR) and automatic image annotation systems have been designed to tackle the problem of image retrieval in large image databases. These two systems achieve a common goal which is to learn the mapping function between low-level visual features and high-level image semantics. In this paper, we present an overview of two approaches that address the problem of learning this mapping function from a few training examples in the case of auto-annotation and CBIR systems respectively.\n",
      "Dans cet article, nous proposons une nouvelle méthode d’apprentissage actif sur des bases d’images satellites permettant d’incorporer l’information a priori contenue dans les données ( donnée fait référence ici aux paramètres de texture, couleur, forme... extraits des images). Plus précisément, nous utilisons la connaissance d’une distribution a priori sur les données, dans notre cas un mélange de Gaussiennes, pour guider l’apprentissage d’un classifieur SVM. Un algorithme d’apprentissage actif qui reprend cette idée est d’abord décrit. Les performances de l’algorithme ainsi obtenu sont ensuite comparées en terme de vitesse d’apprentissage et de capacité à gérer de gros volumes de données à une approche classique utilisant un classifieur SVM qui n’exploite pas la structure a priori des données. Les tests sont réalisés sur une base d’images satellites haute résolution QuickBird.\n",
      "The 19 papers in this special issue focus on automation of geospatial intelligence for the environment and security in which image information mining (IIM) concepts are a central component.\n",
      "Recognizing scenes using high resolution Synthetic Aperture Radar (SAR) images requires the capability to identify relevant signal signatures, depending on variable image acquisition geometry, arbitrary objects poses and configurations. This paper addresses a target recognition problem in high resolution SAR images using Principal Components Analysis (PCA), Independent Components Analysis (ICA), as well as a combination of both, for feature extraction; and Support Vector Machine (SVM) for classification. The performance of these techniques were analyzed and tested on a four-class database collected from the same TerraSAR-X High Resolution spotlight Mode (HS), Multi Look Ground Range Detected (MGD) image, over the Pyramids of Gizeh in Egypt.\n",
      "High Resolution (HR) Synthetic Aperture Radar (SAR) Single Look Complex (SLC) observations, mainly of strong scattering scenes or objects show phase patterns. Phase patterns may occur due to the system behavior or they may be signatures of the imaged objects. Since state of the art stochastic models of SAR SLC data describe mainly the pixel information. Now studies are needed to elaborate better models for the full information content. Thus, new statistical models of HR SAR SLC are proposed, they aim at the characterization of the spatial phase feature of Polarimetric SAR (PolSAR) SLC data, i.e. they describe multi-band, complex valued textures. The definition of texture must be changed because it is not anymore characterizing the optical features but the electromagnetic properties of the illuminated targets. The content of the SAR image is a stochastic process characterized from its own structure and \n",
      "With the increase of the Synthetic Aperture Radar (SAR) sensor resolution, a more detailed analysis and a finer description of SAR images are needed. Nevertheless, when dealing with urban areas, the high diversity of manmade structures combined with the complexity of the scattering processes makes the analysis and information extraction, from high resolution SAR images over such areas, not easily reachable. In general, an automatic full understanding of the scene requires the capability to identify both relevant and reliable signatures (called also features), depending on variable image acquisition geometry, arbitrary objects poses and configurations. Then, since SAR images are formed, by coherently adding the scattered radiations from the components of the illuminated scene objects, we can make the assumption that, the SAR image is a superposition of different sources. Following this approach, one \n",
      "A visual information mining concept is proposed for spatio-temporal patterns discovery in remotely sensed image time-series (ITS). An information theory framework is adopted to first model information content. It results in the inference of a relevant directed graph characterizing ITS. Then the user conjecture is modeled via visual information representations : similarity measures between sub-graphs, which represents spatio-temporal events are derived and included in an interactive learning and probabilistic retrieval procedure of user-specific event-types. The present concept for ITS mining is demonstrated on multitemporal SPOT data.\n",
      "In this paper, a dynamic scene understanding concept is proposed and applied on multispectral image time-series. Information mining enables the exploration and discovery of spatio temporal patterns localized in given spatio temporal windows. With this in mind, a hierarchical information representation which comprises several processing steps is developed. The features are extracted locally in a time window. Several classifications are then performed for each time window according to a Gaussian mixture model constrained by a minimum description length criterion. The non-parametric clustering algorithm is presented and evaluated. Then, the cluster dynamic is investigated in order to enable a graph representation displaying flow of feature points. The analysis is also performed in the space of the image time-series. Lastly, the concept is applied on remotely sensed data and a couple of pattern behaviors are presented.\n",
      "the complexity of the observed images. New methods are needed for their interpretation, both for 2and 3-dimensional analysis. The present work proposes methods of 2—dimensional information extraction from SAR and InSAR metric resolution observations.\n",
      "• The generic image labeling is searched for specific region types based on ancillary information from the area of interest. The regions searched based on spectral, textural and shape information.• The regions classified based on trained models. Regions that can not be labeled into specified categories may indicate problems with the data (haze, clouds, etc.).\n",
      "Forward modeling represents an emulation technique providing a numerical approximation of a physical process. Forward modeling is often applied to find a solution for problems where no direct inversion techniques are available. Typical examples are the determination of physical quantities that can only be found based on comparisons with successively refined models.Classical forward modeling often relies on learned guesses and practical experience. An overview will be given where this technique can be used profitably as a data analysis tool in remote sensing. We will show typical application areas such as imaging observations of land and water surfaces with optical and microwave instruments and compare the approaches with atmospheric retrieval techniques of a limb sounding instrument.Bridging the gap between practical experience and theoretical concepts, maximum likelihood calculations allow the assessment of forward modeling with respect to the accuracy of information extraction. Information theoretical bounds can be derived from the Cramer-Rao bound and the Kullbach-Liebler divergence. As a result, a maximum likelihood estimation can be defined and be interpreted as fitting the observed likelihood to its true value. This allows a determination of the attainable accuracy of the process to be modelled.\n",
      "273 The multiresolution approach in SAR interferometry Mihai Datcu Deutsche Forschungsanstalt für Luft und RaUIIIIaIIrt eV, Deutsches Ferrierkundungsdatenzenirurn, D-82234 Wesslmg, Germany datcu~Jdfd.d1r.de http://www.dfd.dlr.de/ Abstract The high interest to derive digital elevation models from interferometric SAR data stimulated the research to optimally and numerically efficient solve the phase unwrapping problem. Several solutions have been proposed. We address the solution of the phase unwrapping stated as a least squares problem and its multiresolution solutions. The multiresolution algorithms are computationaly efficient implementations of the phase unwrapping solution, the wavelet implementation is systematic and allows to deal with the noise in the datL Keywords: SAR Interferomet,y, multiresolution analysis, partial differential equations Introduction The paper is a thort presentation and theoretical comparison ofmultigrid, finite element …\n",
      "Summary form only given, substantially as follows. Transform coded images suffer from specific image degradations. In the case of standard JPEG compression/decompression the image quality losses are known to be blocking effects resulting from mean value discontinuities along the 8*8 pixel block boundaries as well as ringing artifacts due to the limited precision of the reconstruction from linear combinations of quantized or discarded basis functions. The most evident consequence of JPEG compression is the fragmentation of image histograms mainly caused by blocking in low activity image subareas. The histogram of the image shows spikes that contain most of the signal amplitudes, the other values are distributed on the remaining permissible levels. As a measure of the blocking effect, the blocking factor is defined as the ratio of the spikes area to the total area of image histogram. This method represents a …\n",
      "The Coastal Thematic Exploitation Platform (CTEP) is an on-going ESA project to develop a platform dedicated to the observation of the coastal environment to support management and monitoring; this paper explains how the innovations of the CTEP will provide new means to handle the technical challenges of observation of coastal areas and contribute to improved understanding and decision-making with respect to coastal resources and environments.\n",
      "The main advantage of Synthetic Aperture Radar (SAR) Tomography over classical interferometry consists in capacity to detect the presence of multiple scatterers within the same resolution cell. In this paper we present an algorithm for detection of Persistent Scatterers (PS) based on the variation of reflectivity function in elevation direction reconstructed with Beam-Forming technique. Then, we extract the contribution of dominant scatterers from each resolution cell and reapply the detection algorithm to identify the presence of secondary PSs in scene's pixels. The methods were implemented on a dataset of high-resolution Single Look Complex (SLC) images acquired by TerraSAR-X sensor, on which the residual component of interferometric phase was estimated and compensated locally.\n",
      "In this paper, we present the visualization of image databases based on their primitive features. Our approach is to have a visual navigation tool for allowing the exploration and exploitation of large image archives. The tool is able to project the content of a given image database based on the primitive feature space and to provide interaction between the final user and the huge amount of data. Land Use/Land Cover area frame statistical Survey in-situ data are used as test dataset. Bag-of-Words and Weber Local Descriptors are used as primitive features.\n",
      "As the data acquisition capabilities of Earth observation (EO) satellites have been improved substantially in the past few years, large amount of high-resolution satellite images are downlinked continuously to ground stations. Such amount of data increases rapidly beyond the users' capability to access the images' content in reasonable time. Hence, automatic and fast interpretation of a large data volume is a computationally intensive task. Recently, approximate nearest neighbour search has been used for content-based image retrieval in sub-linear time. Kernelized locality sensitive hashing (KLSH) is a well-known approximate method, which has recently shown promising results for fast remote sensing image retrieval. This paper proposes a novel parallelization of KLSH using Graphical Processing Units (GPU), in order to perform fast parallel image retrieval. The proposed method was tested on high-dimensional feature vectors from two satellite-based image datasets, where an average speedup of 20 times was achieved.\n",
      "Satellite image time series are a valuable resource for enhancing land exploitation by respecting the natural cycles, analyzing urban expansion and its positive and negative effects, limiting the unhealthy rhythm of deforestation, understanding natural hazards and so on. In this context, understanding only the changes in multitemporal images is not sufficient. This paper aims to correlate multi-level change detection techniques with image semantic segmentation methods in order to build an hierarchy of changes for each semantic class. In this way, we are able to provide statistics regarding the levels of change suffered by a certain area. The methods are demonstrated with examples involving bi-temporal Land-sat images.\n",
      "Recently, two improved methods have shown their advantages in browsing Earth Observation (EO) dataset. The first method is the Bag-of-Words (BoW) feature extraction method and the second is the Normalized Compression Distance (NCD) for assessing image similarity. However, they have not been compared so far for satellite image retrieval, which motivates this paper. Two retrieval experiments have been performed on a freely available optical image dataset and a SAR image dataset. Through these two experiments, we conclude that the BoW method performs generally better than NCD. Although it is a parameter-free solution for data mining, NCD only performs well for images with repetitive patterns like some homogeneous classes. In contrast, BoW method performs much far beyond that of NCD. In addition, NCD is computationally very expensive, which makes it infeasible to be applied in real applications. In contrast, BoW method is more realistic in practical applications in terms of both accuracy and computation.\n",
      "The continuous increase in the size of the archives and in the variety and complexity of Earth-Observation (EO) sensors require new methodologies and tools that allow the end-user to access a large image repository, to extract and to infer knowledge about the patterns hidden in the images, to retrieve dynamically a collection of relevant images, and to support the creation of emerging applications (e.g.: change detection, global monitoring, disaster and risk management, image time series, etc.). In this context, we are concerned with providing a platform for data mining and knowledge discovery content from EO archives. The platform’s goal is to implement a communication channel between Payload Ground Segments and the end-user who receives the content of the data coded in an understandable format associated with semantics that is ready for immediate exploitation. It will provide the user with automated tools to explore and understand the content of highly complex images archives. The challenge lies in the extraction of meaningful information and understanding observations of large extended areas, over long periods of time, with a broad variety of EO imaging sensors in synergy with other related measurements and data. The platform is composed of several components such as 1.) ingestion of EO images and related data providing basic features for image analysis, 2.) query engine based on metadata, semantics and image content, 3.) data mining and knowledge discovery tools for supporting the interpretation and understanding of image content, 4.) semantic definition of the image content via machine learning methods. All these components are integrated and supported by a relational database management system, ensuring the integrity and consistency of Terabytes of Earth Observation data.\n",
      "As we have entered the era of big data, the capability of Earth observations has been dramatically increased and reached an unprecedented level by widely accessible remotely sensed big data. The current remote sensing systems collect several terabytes of Earth observation data per day and enable the measurement of objects at the submeter level. Moreover, with the rapid development of imaging and earth observation technologies, the collected data volumes are predicted to be amplified quickly. Efficient management and analytics for such remotely sensed data are critical in the applications of Earth observations, but present great challenges due to data complexity, diversity, and volume. Actually, there exists great imbalance between the capacity of data management and analytics and the capacity of data acquisition in remote sensing. Thus, it is an urgent demand to develop effective data management tools and advanced analytical techniques for the best use of remotely sensed big data. Meanwhile, streaming and online real-time algorithms are required for quick and intelligent decision making.\n",
      "This paper presents a study of content based image retrieval using compression based methods with original and despeckled TerraSAR-X images. This study aims at analysing the behaviour of our method regarding speckle noise. Our method is based on Lempel-Ziv-Welch compression algorithm for feature extraction and fast compression distance as similarity metric. From the experimental results can be observed that the method is independent of the speckle noise.\n",
      "In the last few years, thanks to projects like TELEIOS, the linked open data cloud has been rapidly populated with geospatial data some of it describing Earth Observation products (eg, CORINE Land Cover, Urban Atlas). The abundance of this data can prove very useful to the new missions (eg, Sentinels) as a means to increase the usability of the millions of images and EO products that are expected to be produced by these missions. In this paper, we explain the relevant opportunities by demonstrating how the process of knowledge discovery from TerraSAR-X images can be improved using linked open data and Sextant, a tool for browsing and exploration of linked geospatial data, as well as the creation of thematic maps.\n",
      "Clustering of Earth Observation (EO) images has gained a high amount of attention in remote sensing and data mining. Here, each image is represented by a high-dimensional feature vector which could be computed as the results of coding algorithms of extracted local descriptors or raw pixel values. In this work, we propose to learn the features using discriminative Nonnegative Matrix factorization (DNMF) to represent each image. Here, we use the label of some images to produce new representation of images with more discriminative property. To validate our algorithm, we apply the proposed algorithm on a dataset of Synthetic Aperture Radar (SAR) and compare the results with the results of state-of-the-art techniques for image representation. The results confirm the capability of the proposed method in learning discriminative features leading to higher accuracy in clustering.\n",
      "The TerraSAR-X satellite has been fully operational since nearly 6 years and has delivered a very large quantity of high resolution SAR images. Among these images one can find a number of repeated acquisitions of selected target areas taken with nearly identical imaging parameters. These image time series data often cover the full seasonal cycle of a target area and lend themselves well to small-scale change detection; however, in the case of urban areas, we have to be aware of the quantitative impact of rain, frost and wind on high resolution SAR images. In particular, images of Western European cities are characterized by construction work concentrating on single buildings within a fully built-up city and by public green space changes. A quantitative analysis of urban time series data has to discriminate between definite changes of the urban landscape and the transient impacts of rain, frost and wind. The critical issue is how to identify and characterize these transient phenomena.\n",
      "In this paper, a novel active learning approach and system incorporating multiple instance learning for SAR image mining and annotation is introduced. Based on a multiscale and hierarchial patch based image representation, a cascade classifier is learned at different levels. At each level of the hierarchy, a SVM classifier is trained based on active learning and the training sample propagation between different levels is achieved through Multiple Instance SVM (MI-SVM). Classification at the higher level is applied only to the positive patches obtained at the previous level, which can significantly reduce the burden of computation in the case of large data set. Performance has been evaluated through a large data set, which shows promising gain not only in accuracy but also in computation.\n",
      "Advances in remote sensing technologies have allowed us to send an ever-increasing number of satellites in orbit around Earth. As a result, Earth Observation data archives have been constantly increasing in size in the last few years (now reaching petabyte sizes), and have become a valuable source of information for many scientific and application domains (environment, oceanography, geology, archaeology, security, etc.). TELEIOS is a recent European project that addresses the need for scalable access to petabytes of Earth Observation data and the discovery of knowledge that can be used in applications. To achieve this, TELEIOS builds on scientific database technologies (array databases, SciQL, data vaults) and Semantic Web technologies (stRDF and stSPARQL) implemented on top of a state-of-the-art column-store database system (MonetDB). In this paper we outline the vision of TELEIOS (now in its second year), present its software architecture and give a detailed example of a fire monitoring application that we have completed.\n",
      "This paper presents a methodology for feature extraction from high resolution SAR image classification, using descriptors constructed from the complex SAR signal. The proposed data mining scheme aims at determining regions in the imaged scene which have similar content. Two complementary approaches are proposed, one making use of the single look complex data for feature extraction and the other based on the interferometric information available about the imaged scene. The features are derived from the estimated signal spectrum, in two stages. For the second stage, the model order is given by minimum number of components needed for classification and is estimated through the Akaike information criterion. Tests show that the proposed features allow for a robust recognition of 25 scene classes.\n",
      "Huge quantities of medium resolution satellite images are available from various Earth observation sites. These archives enable the creation of long-term, medium resolution Satellite Image Time Series (SITS). Such SITS are large, complex data sets, embedding spatial, spectral and temporal information. The development of effective methodologies for analysis of SITS is a challenging issue. In this paper we propose a new method to analyze medium spatial resolution SITS at pixel level by means of multi-sensor spectro-temporal signatures. The temporal resolution of SITS is improved by combining scenes captured with different remote sensing sensors. The proposed method is applied to a series of 40 Landsat TM and ETM+ scenes covering the area of Bucharest, Romania. Spectro-temporal signatures are extracted by means of the first two tasseled cap features and a multiclass SVM classification was used to create maps that show land use and transitions in land use over time.\n",
      "In this article we propose a parameter-free method for Remote Sensing (RS) image databases Data Mining (DM). DM of RS images requires methodologies robust to the diversity of context found in such large datasets, as well as methodologies with low computational costs and low memory requirements. The methodology that we propose is based on the Normalized Compression Distance (NCD) over lossless compressed data. Normalized Compression Distance is a measure of similarity between two data files using the compression factor as an approximation to the Kolmogorov complexity. This approach allows to directly compare information from two images using the lossless compressed original files, and avoiding the feature extraction/selection process commonly used in pattern recognition techniques. This shortcut makes the proposed methodology suitable for DM applications in RS. We provided a classification experiment with hyperspectral data exemplarizing our methodology and comparing it with common methodologies found on the literature.\n",
      "This paper presents a non-parametric modeling scheme for high resolution SAR data, based on Short Time Fourier Transform which is able to integrate the radiometrical and morphological properties of the data, for object recognition, scene and target indexing, addressing the problem of large data base queries and information retrieval.. The method is assessed by using a Bayesian Support Vector Machine image search engine based on a hierarchical learning model. The method allowed for the recognition of over 30 different classes, both homogeneous and heterogeneous urban objects with high levels of details. Qualitative and quantitative measures for evaluation are presented and discussed.\n",
      "This paper discusses the basic paradigm of how image information mining methods work in the field of remote sensing. To this end, we compare our approaches to the approaches being used in the world of multimedia; then we discuss the annotation specifics of remote sensing data and describe the different types of remote sensing data that we are faced with today. We conclude with a description of algorithmic alternatives and compare several competing systems that are currently in use. Finally, we provide an outlook of what we expect in the near future.\n",
      "In this paper we discuss Gauss-Markov Random Field (GMRF) based on multiple sub-aperture decomposition method for the analysis of targets in complex-valued high-resolution SAR data. Gauss-Markov Random Field (GMRF) model with a quadratic energy function as a parametric analysis parameterizes the spectogram of the signal, whereas sub-aperture decomposition method exploits the holographic property of the spectrum at the cost of reducing resolution. This analysis helps to understand, characterize and analyze complex-valued SAR data and provides temptation to use complex-valued SAR data over detected data.\n",
      "Construction works in the city of Valencia are changing continuously the appearance of the city: new metro lines, the construction of the high speed railway lines, for the train between Madrid and Valencia, the renewal of the districts of El Grao, Cabanyal and Campanar, and some other works for the extension of the harbor area including commercial docks, the facilities for the Americas Cup and the Formula 1 circuit. All these changes could affect the city of Valencia, for example with subsidence, landslides, uplift, since it is located over a quaternary alluvial plane with a complex hydro-geological system. Due to its proximity to the sea, the phreatic surface is at only seven meters depth. Construction works are always affected by this fact and the special characteristics of an unstable but very fertile soil. Interferometric studies have been done in order to estimate possible cases of subsidence over the city and its surroundings. Our work covers a period of 7 years, from 2003 to the present, and it is focused mainly over the port area, where we could detect the most significant results. Our dataset includes ENVISAT ASAR and TerraSAR-x, the German radar satellite, Stripmap images. The collaboration with the Port of Valencia allowed us to have access to the study area and documents that helped us to explain our results.\n",
      "The progress in information retrieval, computer vision, and image analysis makes it possible to establish very complete bases of algorithms and operators. An specialist in remote sensing or image processing now has the tools that allow him to configure applications solving complex problems of image understanding. However, in reality, Earth Observation (EO) data analysis is still performed in a very laborious way at the end of repeated cycles of trial and error. To overcome this, novel advanced concepts for remote sensing information processing based on human-centred concepts (HCCs) are proposed. New features and functions allowing improved feature extraction, search on a semantic level, the availability of collected knowledge, interactive knowledge discovery, and new visual user interfaces are implemented.\n",
      "Compared to conventional optical images, the classification of remote sensing SAR images represents a rather difficult task. As a rule, the various SAR imaging and product options, the high dynamic range of SAR images, and the presence of speckle noise prevent us from obtaining robust classification results. In the following, we try to circumvent these difficulties by proper pre-processing and despeckling of high resolution SAR images. Our approach aims at adapting the radiometry and the resolution of the scenes to the optimal target recognition capabilities of a classification algorithm. To this end, we have to apply systematic adaptations that provide optimized multilooking of our input data. Then these adapted data can be fed into a scene classification system.\n",
      "The Satellite Image Time Series (STIS) consists in sequences of image acquisition of a single zone, taken with varying temporal intervals. The ADAM SITS is composed of 20 m spatial resolution images acquired by three different satellites SPOT 1, 2, and 5. The observed scene contains regions that might conserve properties over time (or at least for a certain time interval): for example, during winter, the different plots join, whereas during spring, they split according to the type of cultures or vegetation. One would like, in that case, to obtain segmentations differentiating the different plots in spring and summer images, and the grownable areas in the winter images. Moreover, the sequence contains occultations by clouds, and annual periodicity, and one would like to find the same region before and after an occultation as well as after one or more years of evolution. The radiometrical discontinuities dues to the bad or absent calibration of the sensors, and to the atmospheric conditions changes superimposed on the scene prevent us from using 3D segmentation methods which suppose a continuity in the third dimension. And finally, the image dynamic changes prevent us from segmenting these images completely independantly because it would not enable us to enhance regions of the same scale, and it would then be difficult to follow a region through time. We propose here an extention of the image segmentation method by Minimum Description Length (MDL) to image series. The advantages of this approach is that it can cope with both deterministic and probabilistic descriptions, and that it is unsupervised: the optimal number of regions is estimated …\n",
      "One of the basic components of image information mining (IIM) systems is feature extraction. Feature extraction delivers a low level “building block” decomposition of the input data. In principle, feature extraction results may depend on the characteristics of the images to be analyzed. In order to avoid a critical dependence on a specific concept, we advocate a general feature finder toolbox approach that handles typical remote sensing images with diverse geometrical and texture characteristics. Our concept considers high resolution optical as well as synthetic aperture radar (SAR) images.\n",
      "Modern imaging sensors, especially those aboard satellites, continuously deliver enormous amounts of data. The widespread of meter resolution images, is not only exploding the volumes of acquired data but also brings a new dimension in the image detail, thus growing the information content. These represent typical cases, where users need automated tools to discover, explore and explain the contents of large image databases. There is a strong need to build up applications that help the user in image interpretation task, applications that permit to query the archives in content based mode, without having to know all the information contained in the images at signal level. We propose in this article, a synergy between stochastic modelling, knowledge discovery, and semantic representation. To do that, we associate semantic labels to a combination of primitive image features. The user-defined semantic image content interpretation is linked with Bayesian networks to a completely unsupervised classification. This new paradigm for the interaction with EO archives can provide several applications for users coming from different domains, as change detection, agricultural field classification, environment monitoring, atmosphere effects or urbanization.\n",
      "Large EO repositories and Information Mining Systems (IMS) usually are based on different system architecture and are operated as stand alone systems. The communication of these systems for the exchange of image and metadata files poses new challenges to the developer due to the systems heterogeneity, the enormous volume of archived data and communication limitations. Maintain data integrity in different data driven as well as user interactive transfer and learning scenarios, is an important issue. We propose a theoretical framework to maintain data integrity in communicating systems and illustrate it on the example communication of DIMS (German Aerospace Center – Data information management system) with KES (Knowledge enabled services) system, the recently developed Information Mining System.\n",
      "In the framework of 3D visualization and real-time rendering of large remote sensing image databases, several signal processing techniques are presented and evaluated to filter/enhance SAR Digital Elevation Models (DEMs). Through the SRTM DEM, the interest of InSAR data for such applications is illustrated. A non stationary bayesian filter is presented to remove noise and small artefacts which pervade the SAR DEM while preserving structures and information content. Results obtained are very good, nevertheless large artefacts cannot be filtered and some artefacts remain. Therefore, image information have to be inserted to produce more realistic views. This second step is done by using a segmentation algorithm on the image data. By a topology analysis, the extracted objects are classified/stored in a tree structure to describe the topologic relations between the objects and reflect their interdependencies. An interactive learning procedure is done through a Graphical User Interface to link the signal classes to the semantic ones, ie to include human knowledge in the system. The selected information in form of objets are merged/fused in the DEM by assigning regularisation constraints.\n",
      "In this paper, a dynamic scene understanding concept is proposed and applied on multispectral image time series. Information mining enables the explorations and discovery of spatio temporal patterns localized in given spatio temporal windows.With this in mind, a hierarchical information representation is developed. It comprises different levels in which the data is modeled so that the relevant information is transmitted through the architecture, according to a query and to several assumptions made on the models employed. There are mainly four components : feature extraction, reduction of dimensionality, clustering and interactive exploration.\n",
      "We present an intelligent satellite information mining system, a next generation architecture to help a user to rapidly gather information about courses of action, a tool to add value and to manage the huge amounts of historical and newly acquired satellite data-sets by giving to experts access to relevant information in an understandable and directly usable form and to provide friendly interfaces for information query and browsing. In a remote sensing image archive the data access by geographical position, time of acquisition or type of sensor is often less important than what is the content of the scene, ie structures, objects, scattering properties. Interesting applications involve complicated spatial and structural relationships among image objects.\n",
      "Content-based retrieval from remote-sensing data requires the linkage of features describing signal properties with terms expressing image content in a user-friendly language. On the one hand we need general and powerful features that describe precisely the data properties. These must be signal-oriented free of any interpretation, so that the system can respond in an unbiased manner to a wide range of queries. On the other hand we have to provide the user of the retrieval system with a suitable query tool where he can express his needs in terms he is familiar with. To this end the authors use search terms that origin in the application domain of the user and a graphical tool where the user can give training regions in remote-sensing data. The difference to existing systems is that we explicitly use the scale as a query element. The user has the possibility to indicate the typical size of objects and structures he is …\n",
      "Textural information can efficiently describe the content of a remote sensing image. In this paper we present the characterization of textures via a conditional probability model for the magnitudes of the wavelet coefficients. We select the optimal model complexity using the Bayesian formalism. The order of the model and the associated model parameters can be used for texture segmentation and classification, or as an index in an image database for content-based retrieval.\n",
      "In this paper we present a multi-level scheme for stochastic description of image content. The different levels are derived from the different degrees of abstraction. On the level of the image data, we use stochastic data models and Bayesian parameter estimation to derive low-level image features. On the next level, we derive meta features that provide both the fit of these models and the actual complexity of the data. The low-level and meta features are combined in an un-supervised clustering scheme to obtain an objective description of the image content. To obtain this objective description we use clustering by melting. The descriptions by several models are then linked to application-oriented, semantic labels using another process of Bayesian inference. We sketch in detail the various processes of inference and give an example for this kind of information on each level of abstraction using satellite images …\n",
      "An approach to unsupervised segmentation of SAR images and texture modelling is presented. This approach is based upon a Bayesian estimation in order to obtain the maximum a posteriori segmentation of an image. The segmentation is performed by using prior information describing the features according to which an image is to be segmented and, where mathematically tractable, takes into account the likelihood function of the SAR specific speckle statistics. The solution of this optimization problem is obtained by a relaxation method combined with a region growing approach.\n",
      "Presents a model based technique for an efficient correction to topographically induced radiometric influences on remotely sensed imagery. In a first step, relief-induced geometric distortions are removed from optical imagery, taking terrain elevation into account. In a second step the radiometry is considered. Synthetic images are generated based on the digital elevation model, and Sun and satellite position at the time of acquisition of the image. The synthetically derived images model the image formation process for the directly lighted and shadow areas. Using direct, indirect and diffuse illumination. The resemblance of the synthesized image to reality is evaluated for a mountainous alpine region covered by snow. In a last step the derived image is used for the snow cover segmentation.<>\n",
      "The objective of WP6 is to build a Virtual Earth Observatory for TerraSAR-X data and demonstrate its functionality by developing use scenarios such as rapid mapping, semantic cataloguing, etc. This deliverable is the second part of Deliverable 6.2 (Ontologies for the VO for TerraSAR-X data) of the TELEIOS project. The present document continues the work started with Deliverable 6.2. 1 where the first version of DLR ontology for TerraSAR-X data was developed.\n",
      "The classification of large-scale high-resolution SAR land cover images acquired by satellites is a challenging task, facing several difficulties such as semantic annotation with expertise, changing data characteristics due to varying imaging parameters or regional target area differences, and complex scattering mechanisms being different from optical imaging. Given a large-scale SAR land cover dataset collected from TerraSAR-X images with a hierarchical three-level annotation of 150 categories and comprising more than 100,000 patches, three main challenges in automatically interpreting SAR images of highly imbalanced classes, geographic diversity, and label noise are addressed. In this letter, a deep transfer learning method is proposed based on a similarly annotated optical land cover dataset (NWPU-RESISC45). Besides, a top-2 smooth loss function with cost-sensitive parameters was introduced to tackle the label noise and imbalanced classes' problems. The proposed method shows high efficiency in transferring information from a similarly annotated remote sensing dataset, a robust performance on highly imbalanced classes, and is alleviating the over-fitting problem caused by label noise. What's more, the learned deep model has a good generalization for other SAR-specific tasks, such as MSTAR target recognition with a state-of-the-art classification accuracy of 99.46%.\n",
      "Dear editor, The concept of geosynchronous synthetic aperture radar (GEO SAR) system was conceived in an effort to realize a quick observation of emergency disasters (eg, landslides and earthquakes)[1]. The novel GEO SAR system has the significant advantages of short-revisit time and large coverage and facilitates the nearly continuous observation of target regions, unlike the currently operating low earth orbit (LEO) SARs [2]. However, the systems integration time requirement of minutes to even hours in obtaining a satisfactory azimuth resolution produces some difficulties in imaging. A long integration time introduces highly curved trajectories, which makes conventional imaging algorithms face lots of challenges [3]. Moreover, the impacts of the varied atmosphere, the unstable clutter, and the complex radio frequency interference during the lengthy duration of the integration are likely to seriously jeopardize the image quality [36]. The aforementioned problems may be prevented by a reduction of the integration time; however, low azimuth resolution and the invisibility of many fine structures in the scene, such as roads and building silhouettes, are the corresponding disadvantages.\n",
      "In this paper, we propose a Bayesian inference method for the generalized Gamma mixture model (GΓMM) based on variational expectation-maximization algorithm. Specifically, the shape parameters, the inverse scale parameters, and the mixing coefficients in the GΓMM are treated as random variables, while the power parameters are left as parameters without assigning prior distributions. The help function is designed to approximate the lower bound of the variational objective function, which facilitates the assignment of the conjugate prior distributions and leads to the closed-form update equations. On this basis, the variational E-step and the variational M-step are alternatively implemented to infer the posteriors of the variables and estimate the parameters. The computational demand is reduced by the proposed method. More importantly, the effective number of components of the GΓMM can be determined …\n",
      "Satellite Image Time Series (SITS) are large datasets containing spatiotemporal information about the surface of the Earth. In order to exploit the potential of such series, SITS analysis techniques have been designed for various applications such as earthquake monitoring, urban expansion assessment or glacier dynamic analysis. In this paper, we present an unsupervised technique for browsing SITS in preliminary explorations, before deciding whether to start deeper and more time consuming analyses. Such methods are lacking in todays analyst toolbox, especially when it comes to stimulating the reuse of the ever growing list of available SITS. The method presented in this paper builds a summary of a SITS in the form of a set of maps depicting spatiotemporal phenomena. These maps are selected using an entropy-based ranking and a swap randomization technique. The approach is general and can \n",
      "This paper describes CANDELA - Copernicus Access Platform Intermediate Layers Small Scale Demonstrator - a general platform for the handling, analysis, and interpretation of Earth observation satellite images, mainly exploiting big data of the European Copernicus Programme. Its workflow allows the selection of satellite images, the generation of local image patch descriptors, the ingestion of image and descriptor data into a common database, the assignment of semantic content labels to image patches, and the search and retrieval of similar content-related image patches.\n",
      "Object detection in aerial images plays a significant role in intelligent interpretation of aerial images. Hence many effective methods, especially the new-generation data-driven methods, have been developed for this task. Here, we hold the ODAI, a new contest that focused on object detection in aerial images, based on a new large-scale aerial image dataset called DOTA [1]. This contest contains over 3000 large-size images (4k x 4k pixels), which cover 211,581 instances divided into 15 categories. Each instance is labeled by an arbitrary (8 d.o.f.) quadrilateral. Besides, we propose two tasks for this contest, named object detection with the horizontal bounding box (OD-HBB) and object detection with the oriented bounding box (OD-OBB). The contest was opened on February 7, 2018, and ended on April 30, 2018. A website is open to the public, which provides links to download data and evaluation server. We have totally received 60 registrations. There are 8 teams that have successfully submitted results on the OD-HBB task with the top mAP as 0:719, and 9 teams that have successfully submitted results on the OD-OBB task with the top mAP as 0.705. Through the contest, we hope to draw extensive attention from a wide range of communities and call for more future research and efforts for the task of object detection in aerial images.\n",
      "Current satellite images provide us with detailed information about the state of our planet, as well as about our technical infrastructure and human activities. A range of already existing commercial and scientific applications try to analyze the physical content and meaning of satellite images by exploiting the data of individual, multiple or temporal sequences of images. However, what we still need today are advanced tools to automatically analyze the image data in order to extract and understand their full content. In this paper, we propose a highly automated approach for application-adapted image content exploration, targeting coastal environmental monitoring. For the selected coastal areas, different use cases can be considered such as: detection of wind turbines vs. boats, differences between beaches, tidal flats, and dams, and identification of fish cages/aquaculture. The average accuracy is ranging from 80% to 95% depending on the satellite images.\n",
      "In this work we propose an end-to-end trainable supervised Deep Convolutional Neural Network (DCNN) targeting the task of semantic-segmentation with the addition of class-aware boundary detection. Through this explicit modeling of the class-boundaries, we enforce the network to extract coherent and complete objects, suppressing the uncertainty influencing these regions. Importantly, we show that class-boundary networks in conjunction with DCNN performs optimally, achieving over 90% overall accuracy (OA) on the challenging ISPRS Vaihingen Semantic Segmentation benchmark.\n",
      "We present a data mining methodology to filter and validate land cover change detections obtained from multitemporal in situ surveys. As in situ data we use the measurements from the European land use and coverage area frame survey (LUCAS), which provides images with standardized metadata about land cover and land use within the whole territory of the European Union. Multitemporal LUCAS surveys present an anomaly in the amount of land cover changes that disagree with the estimated by experts. Therefore, our methodology analyses the available data in order to explain the existing irregularities in them. The initial step of our methodology is based on database query refinements. The data mining methodology continues with an image analysis process. This analysis calculates similarity measures of the multitemporal images that are used to identify the potential misclassifications. The final step involves …\n",
      "We demonstrate how to achieve a semi-automated and rapid semantic annotation of high resolution SAR image patches in the case of big image archives. To this end, we start with an already existing annotated satellite image data set and a validated multi-level annotation scheme aimed at semi-automated land cover and urban scene labelling. Our goals are mainly achieved by pre-defined patch cutting, feature extraction from image patches, and a cascaded active learning approach where unnecessary processing steps are skipped. This concept allows us to adapt the classification/annotation quality of a knowledge discovery in databases system to the actual user requirements. In addition, an easily understandable visualization of the retrieved results can be obtained by interactive graphical data mining, by the generation of map products, or by data analytics tools providing mainly statistical results and graphics.\n",
      "This work introduces a well-accepted image representation model in image analysis, namely the Bag-of-Visual-Words (BoVW), to interferometric SAR (InSAR) images. As the low-level local features, Gabor- and fractional Fourier transform (FrFT)-based feature descriptors are used. The supervised classification results with BoVW-Gabor and BoVW-FrFT features are compared to those with global Gabor and global FrFT features. Although the global Gabor features are better than the global FrFT features, by the implementation of BoVW model, FrFT outperforms Gabor features. Also, the classification performances of different baseline acquisitions for the same scenes are compared. For each baseline, the mean and individual class accuracies are improved by using BoVW- FrFT features.\n",
      "Synthetic Aperture Radar (SAR) tomography can reconstruct the elevation profile of each pixel based on a set of co-registered complex images of a scene. Its main advantage over classical interferometric methods consists in the capability to improve the detection of single persistent scatterers as well as to enable the detection of multiple scatterers interfering within the same pixel. In this paper, three tomographic algorithms are compared and applied to a dataset of 32 images to generate the elevation map of dominant scatterers from a scene. Targets which present stable proprieties over time - Persistent Scatterers (PS) are then detected based on reflectivity functions reconstructed with Capon filtering.\n",
      "The increasing number of satellite missions for Earth exploration provides huge amounts of data. These data are of wide diversity regarding the images characteristics, thus new techniques and tools need to be developed to accommodate the extraction of meaningful information. This paper presents An Earth Observation Spatio-Temporal Data Mining System (HyperMINE), which integrates fast and complex query methods in order to generate SITS (Satellite Image Time Series) regarded as a data hypercube. The multidimensional data, considering geographical space, time, band, and satellite/sensor are used as input for information mining algorithms. The system is built on a modular multilayer architecture that allows effective processing of various sources of data.\n",
      "In the context of fast growing data archives, with continuous changes in volume and diversity, information mining has proven to be a difficult, yet highly recommended task. The first and perhaps the most important part of the process is data representation for efficient and reliable image classification. This paper is presenting a new approach for describing the content of Earth Observation Very High Resolution images, by comparison with traditional representations based on specific features. The benefit of data compression is exploited in order to express the scene content in terms of dictionaries. The image is represented as a distribution of recurrent patterns, removing redundant information, but keeping all the explicit features, like spectral, texture and context. Further, a data domain analysis is performed using Support Vector Machine aiming to compare the influence of data representation to semantic scene annotation. WorldView2 data and a reference map are used for algorithm evaluation.\n",
      "This paper makes a comparative assessment of the observable landcover classes visible in the data provided by the newly launched SENTINEL-1 (S-1) satellite. The analysis focuses on two feature extraction methods previously reported in the literature to be able to distinguish between a relatively large number of classes in high and very high resolution SAR data. The analysis of the S-1 medium resolution data makes use of the Gabor filtering and Fourier spectral coefficients. Moreover, we consider the opportunity of speckle reduction before feature extraction, considering that the texture analysis is sensitive to correlated speckle. Furthermore, the comparison takes into account the adaptation of the window size to the resolution and pixel spacing of the data. In order to make a quantitative assessment of the results, we perform a joint evaluation of the detection probability at pixel and patch level, with respect to an expert annotated dataset. ?? 2015 IEEE.\n",
      "In this paper, we present a Gaussian test-based hierarchical clustering method for high-resolution TerraSAR-X images. The purpose is to obtain homogeneous clusters. k-means is used to split image features to create a hierarchical structure. As image feature vectors usually fall into high dimensional feature space, we test different distance metrics, in order to try to tackle the curse of dimensionality problem. With prepared datasets, we evaluate the clustering results by defining a homogeneity percentage. The results show that by using Gabor texture feature, the Gaussian test-based hierarchical patch clustering method is able to obtain homogeneous clusters. Meanwhile, fractional distance or Minkowski distance performs better than Euclidean or Manhatten distance.\n",
      "Last years have witnessed an increased interest in the analysis of evolution of spatio-temporal structures in large data volumes. The current satellite remote sensing missions allow the recording of long Satellite Image Time Series (SITS) with passive and active sensors. However, the spatio-temporal characteristics of SITS imply different approaches. This paper aims at presenting an overview of these issues, and also some recent results based on Gibbs Markov Random Fields models that are used to describe the spatio-temporal patterns. In addition, in order to obtain an automatic analysis of these patterns, the problem of determining the optimal number of spatio-temporal clusters is also discussed. The experiments are carried on Landsat 7 multi-temporal and multi-spectral images and on Envisat ASAR images, both at 30 meters spatial resolution.\n",
      "The latest generation of synthetic aperture radar (SAR) instruments operating in X-band, that is, COSMO-SkyMed (CSK) and TerraSAR-X (TSX), are capable of providing images from coarse resolution to very high resolution. A lot of research effort has been invested in the study and understanding of images obtained from these satellites. However, there is still a huge scope of statistical understanding and comparison of data from both satellites. In this study, we demonstrate some striking similarities between medium resolution data obtained from CSK and TSX Stripmap mode images. Land-cover unsupervised clustering using k-means is discussed to further justify our findings. Clustering is carried out using a feature descriptor based on log-cumulants of Gabor coefficients, which was recently proposed by us in earlier studies.\n",
      "Traditionally, images are understood based on their primitive features such as color, texture, and shape. The proposed feature extraction methods usually cover a range of primitive features. SIFT, for example, in addition to the shape-based information, extracts texture and color information to some extent. Thus, different descriptors may cover a common range of primitive features which we call information overlap. Selecting a set of feature descriptors with low information overlap allows more comprehensive understanding of the data by providing a broader range of new features. This article introduces a new method based on information theory for comparing various descriptors. The idea is to code each description of an image by Huffman coding. The distance between the coded descriptions are then measured using Levenshtein distance as the information overlap. Results show that the computed information overlap clearly describes the differences between the learning from different descriptions of Earth Observation images.\n",
      "Representing images with their descriptive features is the fundamental problem in CBIR. Feature coding as a key-step in feature description has attracted the attentions in recent years. Among the proposed coding strategies, Bag-of-Words (BoW) is the most widely used model. Recently saliency has been mentioned as the fundamental characteristic of BoW. Base on this idea, Salient Coding (SaC) has been introduced. Empirical studies show that SaC is not able to represent the global structure of data with small number of codewords. In this paper, we remedy this limitation by introducing Locally Linear Salient Coding (LLSaC). This method discovers the global structure of the data by exploiting the local linear reconstructions of the data points. This knowledge in addition to the salient responses, provided by SaC, helps to describe the structure of the data even with a few codewords. Experimental results show that …\n",
      "In this paper, complex-valued Markov random field (CMRF) parameters, namely the interaction strength and variance, which have been previously used for noise reduction in interferograms, are proposed for feature extraction from interferometric SAR (InSAR) images. A comparative performance evaluation has been carried out for feature extraction from InSAR and single-look complex (SLC) SAR images. A patch-based classification is performed for a small database of 3 forest classes. Also, a single image is tiled into small patches and unsupervised clustering is performed. The results are compared to that of another MRF-based complex-valued feature vector which consists of complex-mean and covariances.\n",
      "Visual attributes are high-level semantic description of visual data that are close to the language of human. They have been intensively used in various applications such as image classification [1, 2], active learning [3, 4], and interactive search [5]. However, the usage of attributes in dimensionality reduction has not been considered yet. In this work, we propose to utilize relative attributes as semantic cues in dimensionality reduction. To this end, we employ Non-negative Matrix Factorization (NMF)[6] constrained by embedded relative attributes to come up with a new algorithm for dimensionality reduction, namely attribute regularized NMF (ANMF).\n",
      "New trends in exploration and visualization are highly demanded in dealing with the massive amount of collected Earth Observation (EO) data. In this work, we propose an immersive visual analytic of EO data utilizing Virtual Reality technology. Precisely, we introduce the visualization of large scale SAR images in an immersive 3D environment and also introduce an interactive learning algorithm for the data clustering using Nonnegative Matrix Factorization framework. We conduct our experiments on a dataset of SAR images represented by different features and show that the proposed interactive clustering outperforms the others.\n",
      "Active learning aims to label the most informative data points in order to minimize the cost of labeling [1]. In this work, we introduce a human based approach, namely First Certain Wrong Labeled (FCWL) to select points for labeling. It is based on a ranked list of predictions ordered by confidence, from which the user selects the highest ranking incorrect prediction. The experimental results show the improvement in performance of this method compared to others.\n",
      "In high-resolution (HR) and very-high resolution (VHR) synthetic aperture radar (SAR) images, focus is now on the patch-oriented image categorization in contrast to the pixelbased classification in low-resolution SAR images. SAR image categorization requires the generation of a compact feature descriptor that accurately defines the content of the image patch under consideration.In this paper we propose a parametric feature descriptor generated on the complex-valued SAR image within a transformation space. The fractional Fourier transform (FrFT), has been considered to transform the image pixels of the singlelook complex (SLC) SAR images in order to obtain a simpler statistical response. The real and imaginary components of the complex-valued FrFT coefficients have been modelled with generalized Gaussian distribution (GGD).The proposed feature descriptor is compared with a Wavelet-decomposition-based parametric feature descriptor; and with the FrFT-based and Gabor-filter-bank-based non-parametric feature descriptors. Categorization accuracy enhancement is demonstrated over several categories comprising of natural topologies. The experimental database consists of 2000 image patches (of size 200 x 200 pixels) extracted from SLC HR TerraSAR-X scenes.\n",
      "Recent development in the design of modern satellite ground segments include systems and tools for automated content analysis allowing users to conduct systematic semantic searches within satellite image data archives. The need for such tools becomes more and more pressing as future space-borne imaging sensors will deliver enormous quantities of data that cannot be studied manually. For instance, typical examples from a European perspective are described in [1] and [2]. Within this framework, the European Space Agency (ESA) has started to fund the Earth Observation Librarian (EOLib) project to set up the next generation of image information mining systems [3]. Here we report on the preparation of scenarios that are needed for training and to verify and optimize the performance of such systems.\n",
      "The increasing number of Earth Observation image acquisitions provides huge volume of information, which requires new techniques, methods and tools to explore and exploit the abundant volume of information contained in the image archives. This paper presents an architecture concept for data mining systems using Earth Observation images. The architecture concept is defined as a modular system composed of five modules allowing functions such as primitive feature extraction, image content and context analyses, finding scenes of interest by content, enriched metadata, and semantics, the interpretation and understanding of the image content, semantic definition of the image content, and visualization of the image database via human machine interfaces. All these functionalities are integrated and supported by a database management system.\n",
      "In this paper, we present a comparative evaluation of two content-based image retrieval systems, the first one based on texture feature extraction methods and machine learning algorithms and the second one based on compression methods and similarity metrics. The evaluation is carried out using high resolution optical and SAR data. The test data set is composed of 4000 tiles, with 64×64 pixel size. Those tiles were classified into 7 land use/land cover classes in the case of optical and 10 classes in the case of SAR. The experimental results show a good performance of both methods in retrieving built-up and natural scenes. However, the advantage of the last method is mainly the facility of its operation since it does not need to set input parameters and the image retrieval is full automatic.\n",
      "Dimensionality reduction is the most widely used approach for extracting the most informative low-dimensional features from highdimensional ones. During the last two decades, different techniques (linear and nonlinear) have been proposed by researchers in various fields. However, the main question is now how well a specific technique does this job. In this paper, we introduce a qualitative method to assess the quality of dimensionality reduction. In contrast to numerical assessment, we focus here on visual assessment. We visualize the Minimum Spanning Tree (MST) of neighborhood graphs of data before and after dimensionality reduction in an immersive 3D virtual environment. We employe a mixture of linear and nonlinear dimension reduction techniques to apply to both synthetic and real datasets. The visualization depicts the quality of each technique in term of preserving distances and neighborhoods. The results show that a specific dimension reduction technique exhibits different performance in dealing with different datasets.\n",
      "During the 1990’s, most work in Earth Observation (EO) data management focused on the design of catalogues and single mission (ie, sensor) data repositories for enabling geospatial (ie, bounding boxes) and temporal queries. The developed techniques and systems were mainly based on the ‘traditional’data base management system and simple query languages. At the beginning of 2000 there was a marked awareness of the growing need for longterm preservation of the data to facilitate climate change research and multi-mission EO data access. Efforts have been directed and are presently directed in pursuit of reaching a consensus for the architecture of software systems in order to enable robust operation, maintainability, and adaptability.\n",
      "This paper advocates an interactive technique to discover the optimum combination of three spectral features of a multispectral satellite image that enhances visualization of target classes/objects. The method is an application-free, single-click user effort, spectrally and spatially balanced, fast-response, low-cost, informationbased feature selector that comes to optimize a very important problem in the computer assisted work of the human operator: visualization of target areas. The new tools developed to assist image experts in their work need to be tailored to the new products offered by the sub-meter spatial resolution multispectral imaging sensors. The spectral bands of the satellite image are ranked using measures of mutual information-the minimumredundancy-maximum-relevance mRMR criterion-and the top three are automatically displayed on screen. The evaluation of results is performed in terms of both …\n",
      "It is envisaged that the Global Earth Observation System of Systems (GEOSS) will provide data streams to decision-support tools for a wide variety of users and applications. As with the Internet, GEOSS will be a global and flexible network of content providers facilitating decision makers' access to an extraordinary range of information products at their desk. However, the challenge for the global users community is to have access to fast and reliable tools to process the data streams into actionable information. On August 31 - September 2, 2009 a workshop was held in Sinaia, Romania to discuss the current state-of-the-art in data mining tools and technologies for Earth Observation (EO) data by a group of international experts. The intent of the workshop was to lead to an understanding of and an objective assessment of the world's practice in extracting information from Earth Observation data and in developing a …\n",
      "This paper is an assessment of two feature extraction methods based on Gibbs random field models using a Cramer-Rao Lower Bound and a Fisher Information Matrix. The evaluated methods are the model-based despeckling (MBD) method and the maximum a posteriori autobinomial method (MAP-ABM). The assessment has been carried out using TerraSAR-X and simulated SAR data. In here, data with an increasing number of looks have been used in order to study 1) how the estimated parameters approach the real ones, 2) how their variances get closer to the CRLB, and 3) how to make a comparison between both model parameters\n",
      "In this paper a new Bayesian algorithm for interferometric phase restoration is presented. Based on a non-linear anisotropic extension of Orientation Diffusions, the inherent directionality of the fringe structure is introduced into its prior model. It also accounts for the periodicity of the phase representation. A fidelity term derived from the anisotropic metrics and the InSAR phase statistics deviates diffusion towards the acquired phase value. It acts as an adapted likelihood of the diffused phase. Hence, phase restoration is a trade-off between directionality and reconstruction fidelity, prior and likelihood. Results are provided on a High Resolution Spotlight scene acquired by TerraSAR-X.\n",
      "This paper presents despeckling and information extraction using non-quadratic regularization. The novelty of this paper is that instead of the Gaussian prior model a Gauss-Markov random field model is chosen, because it can efficiently model textures in the images. The iterative procedure consists of noise-free image and texture parameter. The experimental results show that the proposed method satisfactorily removes noise form synthetic and real SAR images and is comparable with the state of the art methods using objective measurements on synthetic SAR images.\n",
      "With the launch of the German TerraSAR-X system in June 2007, a new generation of high-resolution spaceborne synthetic aperture radar (SAR) data is available; which should facilitate the interpretation of urban environments. This article proposes a new automatic tool for geometric and topological urban areas characterization. Our approach is divided into three main steps. First, a bright linear structures detector is applied to extract the geometrical information. Then, a graph-based spatial characterization is used to model the topological relationships between the different detected bright pixels (nodes). Next, a classification by examining the profile of the distributions of the angles between neighboring nodes, is performed in order to label the linked structures. Evaluations of the proposed approach in characterizing the geometry and topology of urban areas were carried out using TerraSAR-X data over three …\n",
      "The paper aims at applying the evidence maximization algorithm in order to extract the primitive texture feature and to de-speckle the detected image. Following the classical speckle analysis, the speckle noise can be modeled as a multiplicative noise. The improvement of the algorithm comes from the bayesian approach which incorporates the model parameter estimation and model selection in an automatic.\n",
      "Nowadays huge volumes of Earth Observation data are available and increasing every day. Users are faced with the problem of having to extract and interpret information in large volumes of data, with the additional problem of images being annotated only by simple descriptors. Therefore, in this paper we present the Knowledge-centered Earth Observation system which offers interactive probabilistic information mining, among other functionalities, and two Support Vector Machine based Feature Extraction services integrated in the system.\n",
      "With the growing importance of model‐based signal analysis methods, the dependence of their performance on the choice of the models needs to be addressed. Bayesian theory incorporates model selection in a natural and direct way: we apply it to the space‐variant choice of the best model in a given reference class in the framework of parameter estimation from complex data. In particular, we introduce an algorithm for image information extraction that is based on a two‐level model, it estimates local texture Gauss‐Markov Random Field (GMRF) parameters and local GMRF model order for incomplete data. Model selection is based on an approximate numerical computation of the evidence integral. Results are presented on Synthetic Aperture Radar (SAR) images.\n",
      "The Bayesian approach is a promising method for modelbased signal analysis. It was previously used on detected radar images for model based despeckling and feature extraction. We propose an extension on Single Look Complex (SLC) High Resolution (HR) Synthetic Aperture Radar (SAR) images. The information contained in the phase is reflected in the second order statistics and it is important for texture characterization. The SLC data, generally modeled as circular complex Gaussian, is assumed to be modeled by a complex Gauss-Markov Random Fields (GMRF). An efficient parameter extraction for texture characterization is important in order to create an alphabet of plausible primitive feature for image labeling. The affectation of the phase correlation on parameter estimation is explored. The results are demonstrated on E-SAR SLC HR images.\n",
      "Rate distortion theory is one of the areas of information transmission theory with important applications in multimodal signal processing, as for example image processing, information bottleneck and steganalysis. This article present an image characterization method based on rate distortion analysis in the feature space. This space is coded using clustering as vector quantization (k-means). Since image information usually cannot be coded by single clusters, because there are image regions corresponding to groups of clusters, the rate and distortion are specifically defined. The rate distortion curve is analyzed, extracting specific features for implementing a database image classification system.\n",
      "The interpretation of EO data requires not only data and/or information fusion for better understanding of Earth cover structures, but, at a higher level, needs the aggregation with existing bodies of knowledge specific to the application fields.\n",
      "In this article, we present tools for the evaluation of a knowledge-drivencontent-based image information mining system. In order to provide users fast access to the content of large remote sensing image archives, the system is composed of two main modules. The first includes computationally intensive algorithms for off-line data ingestion in the database, feature extraction and indexing. The second module consists of a graphical human-machine interface that manages the interactive learning and image information mining functions. According to the system architecture, the implemented evaluation tools determine the objective technical quality of the system and include subjective human factors, too. Since the query performance of the mining system mainly depends on the data sets stored in the archive, we first analyze the complexityof image data. Based on the stochastic nature of user-defined semantic cover-type …\n",
      "The generation of the objective information catalogue that enables further image mining functions needs the application of a similarity measure to group the points in the feature space. The generated clusters shall contain robust information on image-signal classes, and preserves an image and a spatial index. Due to the large volumes of data and to the incremental nature of the catalogue generation, classical clustering algorithms are limited in their use. For a new dataset we need to process all data set, the new and the old too. For these reasons we need a new algorithm compatible with the imposed conditions. We propose an algorithm for incremental clustering using grouping based on similarity of the local fractal dimension. By embedding the data set in an n-dimensional grid, we can compute the frequency with which data point fall into cell, and compute the fractal dimension. The fractal dimension is computed by box counting algorithm. The main concept of the algorithm is to add points incrementally to existing clusters, based on how they affect the fractal dimension of the cluster. The algorithm has two steps: initialization and cluster update. In the initialization step it is better if we have a sample of the dataset that is significant overall the feature space as that we can get a significant clustering (number and form), but we can work as well with a normal dataset. If the dataset used for initialization step does not reflect the true clusters structure, it is needed to do additional operations to optimize the groups of existing clusters, like splitting and merging. The algorithm requires one scan of the data, can cope with large dataset, needs only small …\n",
      "Digital Elevation Models (DEM) have become important tools in many remote sensing applications, such as classification, defense, Geographic Information Systems, etc. But they are complex products to generate and they are still pervaded with errors and artifacts due to the generation techniques themselves or atmospheric problems. Thus their qualification for a specified application is not guaranteed. It is well known nowadays that the evaluation of the quality of a DEM is a challenging task, due to the variety of requirements depending on the applications and on the end-user. It remains a major field of investigation, where scientists always look for new tools for the analysis of DEM. The use of multiresolution techniques is one possible answer to this research. In the past decades it has been shown that natural landscapes exhibit fractal behaviors. Consequently it seems rather obvious and relevant to use techniques …\n",
      "The wavelet transform developed during the last years into a mature and very pragmatic formalism for the analysis of the scale behaviour of signals. However, it also remains a tool to serve its very initial goal: the time-frequency analysis. In this article we summarize the basics of time-frequency-scale formalism for signal representation and analysis, and we overview several applications with promising results for the Synthetic Aperture Radar (SAR) signal processing.\n",
      "The purpose of this paper is to present a hierarchic processor architecture for the tracking of moving objects. Two goals are envisaged: the definition of a moving window for the target tracking, and multiresolution segmentation needed for scale independent target recognition. Memory windows in single processor systems obtained by software methods are limited in speed for high complexity images. In a multiprocessor system the limitation arises in bus or memory bottleneck. Highly concurrent system architectures have been studied and implemented as crossbar bus systems, multiple buses systems, or hypercube structures. Because of the complexity of these architectures and considering the particularities of image signals we suggest a hierarchic architecture that reduces the number of connections preserving the flexibility and which is well adapted for multiresolution algorithm implementations. The hierarchy is a quadtree. The solution is in using switched bus and block memory partition (granular image memory organization). To organize such an architecture in the first stage, the moving objects are identified in the camera field and the adequate windows are defined. The system is reorganized such as the computing power is concentrated in these windows. Image segmentation and motion prediction are accomplished. Motion parameters are interpreted to adapt the windows and to dynamically reorganize the system. The estimation of the motion parameters is done over low resolution images (top of the pyramid). Multiresolution image representation has been introduced for picture transmission and for scene analysis. The pyramidal implementation was elaborated for the evaluation of the image details at various scales. The multiresolution pyramid is obtained by low pass filtering and subsampling the intermediate result. The technique is applied over a limited range of scale. The multiresolution representations, as a consequence, are close to scale invariance. In the mean time image representation by wavelets allow scale to be implicit, that is why the wavelet transform is well adapted to evaluate the self similarity of the signals. The self similarity is the common point of wavelets and fractal signals. It is assumed that an image (signal) has fractal behavior if at several scales its `features' show deterministic or statistical self-similarity or self-affinity. Texture analysis can be accomplished by fractal transform: each pixel of the original image is substituted by the value of the fractal dimension in its neighborhood. To evaluate the fractal dimension several techniques have been developed. It is necessary to compute the dimension of the set of points in the neighborhood of interest for a given range of resolutions. The slope of the approximated straight line in log/log plot of these values versus the unit of each scale is in linear dependence to the fractal dimension. It has been proven that fractal dimension can be evaluated from the ratio of the energies of the detail images in a multiresolution pyramid obtained by wavelet transform.\n",
      "This paper introduces a novel Synthetic Aperture Radar (SAR) specific deep learning framework for complex-valued SAR images. The conventional deep convolutional neural networks based methods usually take the amplitude information of single-polarization SAR images as the input to learn hierarchical spatial features automatically, which may have difficulties in discriminating objects with similar texture but discriminative scattering patterns. Our novel deep learning framework, Deep SAR-Net, takes complex-valued SAR images into consideration to learn both spatial texture information and backscattering patterns of objects on the ground. On the one hand, we transfer the detected SAR images pre-trained layers to extract spatial features from intensity images. On the other hand, we dig into the Fourier domain to learn physical properties of the objects by joint time-frequency analysis on complex-valued SAR …\n",
      "We describe two alternative approaches of how to extract knowledge from high- and medium-resolution Synthetic Aperture Radar (SAR) images of the European Sentinel-1 satellites. To this end, we selected two basic types of images, namely images depicting arctic shipping routes with icebergs, and - in contrast - coastal areas with various types of land use and human-made facilities. In both cases, the extracted knowledge is delivered as (semantic) categories (i.e., local content labels) of adjacent image patches from big SAR images. Then, machine learning strategies helped us design and validate two automated knowledge extraction systems that can be extended for the understanding of multispectral satellite images.\n",
      "In the following, we describe highly-automated image analysis approaches that help us classify satellite images, and allow us to monitor dynamical changes in image time series. We concentrated on flooding events within the Danube Delta as seen by the European Sentinel-1 and Sentinel-2 satellites, and describe systematic processing approaches to extract pre-defined categories from the image data (being either Synthetic Aperture Radar or multispectral images). One basic tool to monitor dynamical changes is to analyze and compare the compressibility of image patches using their Normalized Compression Distances. These distances can be converted into similarity matrices providing reliable maps of surface changes. The accuracy of these change maps was quantified for several typical test cases. In addition, we analyzed the performance of an alternative active learning approach, where Gabor filters and \n",
      "&lt;p&gt;&lt;strong&gt;Abstract.&lt;/strong&gt; Today, radar imaging from space allows continuous and wide-area sea ice monitoring under nearly all weather conditions. To this end, we applied modern machine learning techniques to produce ice-describing semantic maps of the polar regions of the Earth. Time series of these maps can then be exploited for local and regional change maps of selected areas. What we expect, however, are fully-automated unsupervised routine classifications of sea ice regions that are needed for the rapid and reliable monitoring of shipping routes, drifting and disintegrating icebergs, snowfall and melting on ice, and other dynamic climate change indicators. Therefore, we designed and implemented an automated processing chain that analyses and interprets the specific ice-related content of high-resolution synthetic aperture radar (SAR) images. We trained this system with selected images covering various use cases allowing us to interpret these images with modern machine learning approaches. In the following, we describe a system comprising representation learning, variational inference, and auto-encoders. Test runs have already demonstrated its usefulness and stability that can pave the way towards future artificial intelligence systems extending, for instance, the current capabilities of traditional image analysis by including content-related image understanding.&lt;/p&gt;                    \n",
      "Monitoring large built structures, landslides, volcanoes, or glaciers implies relative height measurements and line-of-sight (LOS) displacement measurements, which are typically performed with monostatic spaceborne synthetic aperture radar (SAR) sensors. In this case, for each satellite that illuminates a given location, we can usually exploit only the information available from one ascending/descending orbit, and if the satellite uses multiple subswaths, the information is obtained only from one subswath per orbit. A bistatic configuration with spaceborne transmitter and fixed ground-based (GB) receiver opens the possibility to exploit the information available from more than one orbit and one subswath per orbit. Additionally, such a configuration offers new perspectives for target tracking and characterization (e.g., multiple LOSs and bistatic scattering signatures). This article presents an opportunistic C-band bistatic SAR differential interferometry architecture that uses a multichannel GB stationary receiver and a separate transmitter, which can be either the Sentinel-1A/B satellite, used opportunistically, or a specially designed GB sliding transmitter. The combination of the operation modes based on spaceborne and GB transmitter allows monitoring a small critical area of interest with many acquisitions triggered by the GB transmitter and surveying of the whole surrounding area with a small number of acquisitions corresponding to the satellites passes. The hardware platforms are presented along with the bistatic interferometric processing flow, and the potential of the proposed architecture is assessed in the context of monitoring large built structures.\n",
      "This chapter describes a Copernicus Access Platform Intermediate Layers Small-Scale Demonstrator, which is a general platform for the handling, analysis, and interpretation of Earth observation satellite images, mainly exploiting big data of the European Copernicus Programme by artificial intelligence (AI) methods. From 2020, the platform will be applied at a regional and national level to various use cases such as urban expansion, forest health, and natural disasters. Its workflows allow the selection of satellite images from data archives, the extraction of useful information from the metadata, the generation of descriptors for each individual image, the ingestion of image and descriptor data into a common database, the assignment of semantic content labels to image patches, and the possibility to search and to retrieve similar content-related image patches. The main two components, namely, data mining and data fusion, are detailed and validated. The most important contributions of this chapter are the integration of these two components with a Copernicus platform on top of the European DIAS system, for the purpose of large-scale Earth observation image annotation, and the measurement of the clustering and classification performances of various Copernicus Sentinel and third-party mission data. The average classification accuracy is ranging from 80 to 95% depending on the type of images.\n",
      "Single- and dual-polarimetric synthetic aperture radar (SAR) images provide very limited capabilities to interpret physical radar signatures. For generality and simplicity, we call single-polarimetric, dual-polarimetric, and fully polarimetric SAR (PolSAR) images flexible PolSAR images. In order to sufficiently extract physical scattering signatures from this kind of data and explore the potentials of different polarization modes on this task, this paper proposes a contrastive-regulated convolutional neural network (CNN) in the complex domain, attempting to learn a physically interpretable deep learning model directly from the original backscattered data. To achieve a better deep model containing physically interpretable parameters, the objective cost is compared to and selected from several commonly used loss functions in the complex form. The required ground-truth labels are generated automatically according to …\n",
      "Throughout the years, a wide range of satellite mission enabled the creation of a huge amount of Earth Observation (EO) data carrying complex information, whose exploitation is left behind due to the lack of handling capabilities. Computational resources are hardly keeping up with content analysis and information retrieval. In order to increase the search speed through data warehouses for knowledge discovery, new indexing methods are required to handle both the size and the informational complexity of EO data. Feature extraction algorithms are able to describe the image content, yet, they require a very complex database. In this paper, we propose a methodology that combines feature extraction, hashing methods and optimized indexing to convert the images characteristics into hash codes in an effort to speed up the search process. For our experiments, we run our procedure on a data-set composed of several Sentinel-2 acquisitions form across Europe and we assess the query times.\n",
      "Sentinel 2 (S2) satellite provides a systematic global coverage of land surfaces, measuring physical properties within 13 spectral intervals at a temporal resolution of 5 days. Computer-based data analysis is highly required to extract similarity by processing and assist human understanding and semantic annotation in support of Earth surface mapping. This paper proposes an exploratory search methodology for S2 data underpinning both visual and latent characteristics by means of data visualization and content representation. For optimized results, the authors focus on a detailed assessment of top relevant state-of-the-art algorithms for features extraction and classification to determine which one could handle best the characteristics of S2 data.\n",
      "Deep learning algorithms are widely used in remote sensing image scene understanding. Generally, a large-scale annotated dataset is essential to train a deep neural network for classification. In practical terms, however, a large amount of unknown remote sensing images obtained from different sensors need to be understood which may vary from resolution, geolocation and imaging conditions compared with annotated datasets. In this paper, an unsupervised domain adaptation framework based on ResNet-18 is presented to transfer the knowledge of an existing annotated land cover dataset to other remote sensing data, decreasing the discrepancy among images across sensors. The results show a significant improvement in scene understanding of new remote sensing images.\n",
      "The increased number of free and open satellite images has led to new applications of these data. Among them is the systematic classification of land cover/use types based on patterns of settlements or agriculture recorded by satellite imagers, in particular, the identification and quantification of temporal changes. In this paper, we will present guidelines and practical examples of how to obtain reliable image patch classification results based on data mining techniques for detecting possible changes that can appear within a data set. Here, we will focus on a scenario, namely forest monitoring using Earth observation Synthetic Aperture Radar data acquired by Sentinel-1, and multispectral data acquired by Sentinel-2.\n",
      "This paper addresses the feasibility of exploiting a radargrammetric procedure for the retrieval of height estimates using stereo images acquired in a space-surface (spaceborne transmitter-stationary receiver) bistatic geometry. Currently, the research interest concerning this particular direction is still in its infancy, as there are very few papers partially covering the subject. The method proposed in this study is applied to a set of SAR images (displaying an urban area of the Bucharest city) in order to assess the elevation of a group of selected targets within the remotely sensed zone.\n",
      "We address the problem of cross-modal information retrieval in the domain of remote sensing. In particular, we are interested in two application scenarios: i) cross-modal retrieval between panchromatic (PAN) and multispectral imagery, and ii) multi-label image retrieval between very high resolution (VHR) images and speech-based label annotations. These multi-modal retrieval scenarios are more challenging than the traditional uni-modal retrieval approaches given the inherent differences in distributions between the modalities. However, with the increasing availability of multi-source remote sensing data and the scarcity of enough semantic annotations, the task of multi-modal retrieval has recently become extremely important. In this regard, we propose a novel deep neural network-based architecture that is considered to learn a discriminative shared feature space for all the input modalities, suitable for \n",
      "When understanding the single polarization SAR images with deep learning, the texture features are usually learned automatically from the intensity. As an active microwave imaging, however, the complex Synthetic Aperture Radar (SAR) images not only contain the amplitude, but also the phase information, which is important and useful for interpretation. The time-frequency analysis (TFA) provides a physical understanding of the backscattering properties for each pixel in complex SAR images. As a consequence, a novel end-to-end deep learning framework to make the best use of both the physical properties of the objects and the spatial texture of the images is proposed. We start with a convolutional auto-encoder to learn the frequency features from each sub-spectrogram obtained by TFA, and then align them spatially. Next, the spatially aligned features in frequency domain and the low-level texture features obtained from a pre-trained SAR specific network in spatial domain are concatenated as the input of a post-processing residual network to learn spatial-frequency joint knowledge. The experiments were done on a large number of TerraSAR-X images. The proposed framework keeps the full information of complex-value SAR images, making a significant improvement compared with other spatial based deep learning methods in SAR image interpretation. In order to learn the latent space that governs the backscatter values in SAR-imagery we explored the dimensionality reduction properties of variational auto-encoders (VAE). By taking both channels of the SAR data as input and mapping them to a compact, lower-dimensional \n",
      "Currently, what exists in the field of data fusion is a collection of routines/algorithms that can be linked and embedded for various applications. A very well-known open-source toolbox is Orfeo which provides a large number of state-of-the-art algorithms to process SAR and multispectral images for different applications. Another one is Google Engine that includes a large image database and a number of algorithms (or you can add your algorithms) that can be used for image processing. An innovative system is CANDELA, an H2020 research and innovation project under grant agreement No. 776193, which has as one of its objectives the fusion of radar and multispectral images at semantic level but also at feature/descriptor level. The first results will be presented during the Living Planet Symposium. For this case, we propose to recognize different target area details in overlapping SAR and multispectral images complementing each other with rapid succession. For doing this, we already selected Sentinel-1 and Sentinel-2 images that can be rectified and co-aligned by publicly available toolbox routines offered by ESA allowing a straightforward image comparison. In addition, we propose data fusion, and interpretation. The most important aspects to be considered are: • The Sentinel-1 C-band constellation consisting of two radar satellites following each other along the same orbit delivers Earth surface images from their side-looking radar instruments taken during day or night. The images have a spatial resolution of typically 20x20 m. One can easily discriminate bright reflectors (e.g., edges of buildings) from dark surfaces (e.g., windless water …\n",
      "Similarity matrix shows the similarity degree between each data pairs, it actually plays a core role in a number of dimensionality reduction methods, since the objective function builds upon this matrix. While compression-based similarity measures are effectively employed in applications on diverse data types as basically parameter free approach, a fast compression distance (FCD) metric has been proved to be able to achieve similar classification performance comparing with the Normalized Compression Distance (NCD) method, regarding small- to medium- size datasets [1]. The FCD is claimed as combining a fast speed without skipping the joint compression step which obtains better performance compared with NCD [2]. The idea behind is: the LZW algorithm extracts a dictionary D(x) from each image patch, and encode into a string x, in ascending order. The definition of FCD is defined as an operation which mainly takes account of the joint number of patterns within two dictionaries D(x) and D(y). In this research, we use FCD together with t-SNE to visualize a large semantic annotated TerraSAR-X dataset as a study case. The dataset contain image patches from 288 TerraSAR-X images with a total number of over 60,000 individual image patches. The visualizations represent the annotated semantic labels in such an intuitive way which helps us to better understand the relationships between their annotated semantics and how their actual similarities are in manifold space. Our obtained results show that the FCD based similarity matrix effectively provides us a fast yet performance preserved insights in high-dimensional datasets with a non …\n",
      "During the last decade, much progress was made in the fields of artificial intelligence and machine learning. Typical applications range from production control in industrial environments to the automated analysis of scientific data. This development is a result of theoretical and practical advances mainly reached by innovative data representation, feature extraction, clustering, classification, modelling, analysis of time series, prediction techniques, machine learning, querying of relationships within data sets stored in big archives, distributed processing on the web, etc. In the overall geophysical domain, one can see numerous artificial intelligence examples presented in conferences and journal publications; however, new weather prediction and climate research techniques are less frequent than general technical image processing approaches as, for instance, developments for autonomous driving under realistic conditions. When we try to compare and categorize the main scientific and technical artificial intelligence approaches, one can already recognize some established techniques and their future potential that could also be exploited more routinely in weather prediction and climate research. We will present some typical state-of-the-art artificial intelligence techniques and their potential application in geophysics, in particular, for weather prediction and climate research. These techniques have to support the reliable extraction of geophysical quantities, together with their estimated error bars. Another important point is the required implementation effort and risk. We will demonstrate some characteristic cases where artificial intelligence software …\n",
      "Since the very beginning of satellite remote sensing the methods and applications the Satellite Image Time Series (SITS) are the main nature of Earth Observation. Presently, with the regular observations and free and open access of the Copernicus data the impact of SITS is largely amplified. The challenges of the EO Big Data are critically accentuated due to joint volume explosion, high acquisition velocity and sensor variety. The presentation emphases on novel Artificial Intelligence (AI) paradigms focuses to convert the SITS in valuable EO products with impact in new applications for understanding of the Erath cover spatio-temporal processes over long periods of time. AI for EO is largely an interdisciplinary field and involves the convergence of very different methods. The lecture overviews and discuss specific topics for SITS regarding the orbit, mission, sensor constellations, intelligent agents, machine learning, deep learning, data indexing, data bases, and DNN.\n",
      "The Earth is facing unprecedented climatic, geomorphologic, environmental and anthropogenic changes, which require global scale observation and monitoring. Thus a multitude of new orbital and suborbital Earth Observation (EO) sensors and mission are in operation or will be soon launched. The interest is in a global understanding involving observation of large extended areas, and long periods of time, with a broad variety of EO sensors. The collected EO data volumes are thus increasing immensely with a rate of many Terabytes of data a day. With the current EO technologies these figure will be soon amplified, the horizons are beyond Zettabytes of data. The challenge is the exploration of these data and the timely delivery of focused information and knowledge in a simple understandable format. Therefore, search engines, and Data Mining are new fields of study that have arisen to seek solutions to automating the extraction of information from EO observations and other related sources that can lead to Knowledge Discovery and the creation of an actionable intelligence. Knowledge Discovery is among the most interesting research trends, however, the real challenge is to combine Artificial Intelligence with the power and potential of human intelligence, this being a primary objective in the field of Human Machine Communication (HMC). The goal is to go beyond the today methods of information retrieval and develop new concepts and methods to support end users of EO data to interactively analyze the information content, extract relevant parameters, associate various sources of information, learn and/or apply knowledge and to visualize the …\n",
      "We propose a novel SAR-specific deep learning framework Deep SAR-Net (DSN) for complex-valued SAR images based on transfer learning and joint time-frequency analysis. Conventional methods for deep convolutional neural networks usually take the amplitude information of single-polarization SAR images as input to learn hierarchical spatial features automatically, which may have difficulties in discriminating objects with similar texture but with discriminative scattering patterns. As a result, we analyzed complex-valued SAR images to learn both spatial texture information and the backscattering patterns of objects on the ground. Firstly, we experimented on a large-scale SAR land cover dataset collected from TerraSAR-X images, with a hierarchical three-level annotation of 150 categories and comprising more than 100,000 image patches. With three main challenges of highly imbalanced classes, geographic diversity, and label noise, in automatically interpreting the dataset, a deep transfer learning method based on a similarly annotated optical land cover dataset (NWPU-RESISC45) was used to learn a deep Residual convolutional neural network, optimizing a combined top-2 smooth loss function with cost-sensitive parameters. Rather than applying the ImageNet pre-trained model of ResNet-18 to SAR images directly, the optical remote sensing land cover dataset narrows the gap between SAR and natural images which results in a significant improvement in feature transferability, and the proposed combined loss function is successful in accelerating the training process, and is reducing the model bias to noisy labels. The trained deep …\n",
      "During the last decades, natural and human-made disasters had a strong impact on their surrounding areas, and also the development of cities changed the land cover of the affected areas. To detect these changes in a satellite image time series, a parameter-free unsupervised approach using Normalized Compression Distance (NCD) was used to calculate a binary change map. NCD is a distance measure where an extraction of features is not required; instead, this method can calculate the distance between two objects with respect to the context within an image using patches. This approach was used to detect changes in different regions of interest (e.g., the Danube Delta in Romania or Belgica Bank in Greenland) independently of a special scenario or a specific SAR satellite, which enables the use of parameter-free unsupervised change detection for different scenarios.\n",
      "To improve the quality of SAR images, we proposed to train a deep neural network with TerraSAR-X. This is done by using a Dialectical Generative Adversarial Network (Dialectical GAN) to generate high-quality SAR images. This method is based on the analysis of hierarchical SAR information and the “Dialectical” structure of GAN frameworks. As a demonstration, a typical example will be shown where a low-resolution SAR image (e.g., a Sentinel-1 image) with large ground coverage is translated into a high-resolution SAR image (e.g., a TerraSAR-X image). Three traditional algorithms are compared and a new algorithm is proposed based on a network framework by combining conditional WGAN-GP (Wasserstein Generative Adversarial Network - Gradient Penalty) loss functions and spatial gamma matrices under the rule of dialectics. Experimental results show that the SAR image translation works very well when we visually compare the results of our proposed method with the selected traditional methods. Translation of Sentinel-1 data to TerraSAR-X image resolution has attracted great interest within the remote sensing community. First, the high resolution of TerraSAR-X generates SAR images rich in information that allow new innovative applications. Second, the wide area coverage of Sentinel-1 images reduces the need for multiple acquisitions, and decreases the demand for high-cost data. Third, it is much easier for researchers to access Sentinel-1 images than TerraSAR-X images because the Sentinel-1 images are freely available, while the TerraSAR-X images are usually commercial. For validation, we used images of urban areas, so …\n",
      "During the last years, we saw a growing interest in satellite image analysis including semantic and quantitative content description of images, physics-related classification of image segments, the quest for the causes and effects of changes over short and long time periods, and disaster relief support tools. These remote sensing applications are most often using optical datasets; fewer users employ SAR (Synthetic Aperture Radar) datasets. However, both cases call for the identification of land cover / land use details within the full image area. As modern imaging sensors are characterized by high spatial resolution and a wide field of view, we face a high diversity of target types, target objects, as well as temporal changes and their spatial interrelationships. Therefore, we need reliable benchmarking tools to ascertain the actual quality of our image analysis and retrieval results. Primary benchmarking tools for automated benchmarking are collections of selected reference images with known semantic content and characteristics that can be employed for quantitative and comparative image analyses. For optical sensors there exist several well-known and publicly available datasets comprising typical remote sensing image patches, while comparable SAR datasets are very scarce. For our user-oriented application cases no well-known high-resolution and publicly available SAR reference datasets exist. In our case, we collected from all over the world 1,000 urban and industrial areas together with their infrastructure TerraSAR-X images and 75 Sentinel-1 images [1, 2], and assigned them to typical cases of acquisition parameters and target areas. Then …\n",
      "Semantic segmentation or classification for satellite image time series (SITS) is a rarely touched topic, partly due to the difficulty in having the data, but more due to the unreachable task. In this research, we propose a dataset which consists of the Landsat image time series, with the purpose of performing multi-spectral semantic segmentation. As there is no ground truth information, we used unsupervised clustering to group time series into clusters, then Long short term memory (LSTM) unit based Recurrent neural networks (RNN) has been trained. We investigate the accuracy values for our test image patches, around 40% accuracy has been achieved for the sequence classification.\n",
      "Advanced interpretation of satellite images calls for automated content analysis as well as interactive content search. A typical example of such systems is EOLib, an ESA funded project that already demonstrated the application potential of TerraSAR-X data within a satellite payload ground segment. In this paper, we analyze the validation results of image content classification using a large set of selected TerraSAR-X images. The classification was done with a cascaded learning method. The main advantage of this method is a coarse-to-fine approach for semantically annotating pixel patches with decreasing size. Once a reliable label is found for a given pixel patch, no further subdivision into still smaller patch sizes is necessary. This leads to a considerable reduction of the computational effort during classification of large-size satellite images.\n",
      "Persistent Scatterers interferometry represented a breakthrough in synthetic aperture radar processing, its initial approach covering the linear deformation rates estimation step. Most advanced differential interferometric methods prefer the use of an external digital elevation model, because of the difficulties of unwrapping an interferometric phase which contains also the topographic component. In this work, the persistent scatterers approach is extended also for digital elevation model estimation, by applying the minimum cost flow phase unwrapping algorithm solely on the detected PS network. A detailed presentation of the proposed processing chain is conducted, along with the results of the described algorithm's implementation on a test region from Bucharest city, using a dataset of 12 Sentinel-1 acquisitions.\n",
      "This paper proposed a new method to estimate the ship azimuth velocity in TerraSAR-X data based on the minimum-entropy criterion. The moving targets in synthetic aperture radar images are blurred because of the mismatch of the desired signal of stationary targets. Applying the image entropy, a simple parameter to evaluate the extent of the defocusing, the azimuth velocity can be recovered through searching the minima of the entropy curves. The signal models of moving targets are analyzed and their behaviors in SAR images are deduced in this paper. Experiment results show that our method for estimating ship azimuthal velocities in TerraSAR-X data has high precision and is robust.\n",
      "Current satellite images provide us with detailed information about the state of our planet, as well as about our technical infrastructure and human activities. A range of already existing commercial and scientific applications try to analyze the physical content and meaning of satellite images by exploiting the data of individual, multiple or temporal sequences of images. However, what we still need today are advanced tools to automatically analyze satellite images in order to extract and understand their full content and meaning. To remedy this exploration problem, we outline a highly automated and application-adapted data-mining and content interpretation system consisting of five main components, namely Data Sources (selection and storage of relevant images), Data Model Generation (patch cutting and generation of feature vectors), Database Management System (systematic data storage), Knowledge Discovery in Databases (clustering and content labeling), and Statistical Analytics (generation of classification maps). As test sites, we selected UNESCO-protected areas in Europe that include coastal areas for monitoring and an area known in the Mediterranean Sea that contains fish cages. The analyzed areas are: the Curonian Lagoon in Lithuania and Russia, the Danube Delta in Romania, the Hardangervidda in Norway, and the Wadden Sea in the Netherlands. For these areas, we are providing the results of our image content classification system consisting of image classification maps and additional statistical analytics based on three different use cases. The first use case is the detection of wind turbines vs. boats in the Wadden Sea. The …\n",
      "The deluge of Erath Observation (EO) images counting hundreds of Terabytes per day needs to be converted into meaningful information, largely impacting the socio-economic-environmental triangle. Multispectral and microwave EO sensors are unceasingly streaming millions of samples per second, which must be analysed to extract semantics or physical parameters for understanding Earth spatio-temporal patterns and phenomena. Typical EO multispectral sensors acquires images in several spectral channels, covering the visible and infrared spectra, or the Synthetic Aperture Radar (SAR) images are represented as complex values representing modulations in amplitude, frequency, phase or polarization of the collected radar echoes. An important particularity of EO images should be considered, is their instrument nature, i.e. in addition to the spatial information, they are sensing physical parameters, and they are mainly sensing outside of the visual spectrum. Machine and deep learning methods are mainly used for image classification or objects segmentation, usually applied to one single image at a time and associated to the visual perception. The tutorial presents specific solutions for the EO sensory and semantic gap. Therefore, aiming to enlarge the concepts of image processing introducing models and methods for physically meaningful features extraction to enable high accuracy characterization of any structure in large volumes of EO images. The tutorial presents the advancement of the paradigms for stochastic and Bayesian inference, evolving to the methods of deep learning and generative adversarial networks. Since the data sets …\n",
      "Clouds and cloud-shadow are a persistent problem in all optical satellite imagery. Plenty of methods have been suggested in the literature to address this problem, and reconstruct the missing part of the optical signal. In this work, three methods representative of different approaches to the cloud removal problem were compared. The first method is temporal fitting using Fourier series, which benefits from the temporal continuity of the signal. The second method uses sparse spectral unmixing to fill in the missing areas. The third method employs radiometric consistency as a tool to determine the missing part of the signal. These three methods were first presented and their theoretical background described, followed by a discussion of their implied assumptions and general performance. A set of experiments using Landsat 8 time series with diverse land cover types were conducted. The quantitative results of the three methods using simulated clouds are presented. Finally, some concluding remarks about the relative advantages of the three approaches are listed, in addition to some recommendations about their use.\n",
      "Many works dealing with the problem of urban detection at large scale have been published, but very little attention has been paid to the investigation of the features’ relative importance. Feature selection is known to be an NP-hard problem, which means it can not be solved in polynomial time, but there are many heuristics suggested to approximate the solution. In this paper, a survey of the features used for large scale urban detection is presented, then the question of finding the best subset of features is investigated. Using Landsat scenes of five urban areas, most common features were extracted to represent the full feature set. Employing mutual information based ranking methods, Support Vector Machine (SVM) and Random Forest feature ranking, an importance score was assigned to each feature by each method. To aggregate the individual rankings of features, a two stage voting scheme was implemented to choose a subset of size N as the most relevant features. The most important features for all five cities taken together were listed.\n",
      "The general problem of multiple signal sources detection using an array of sensors, with the particular case of Synthetic Aperture Radar (SAR) Tomography is approached in this paper. A detection algorithm which generates accurate results but it's computationally demanding, sup-GLRT (Generalized Likelihood Ratio Test with support estimation), is discussed. Main objective consists in applying matrix algebra for optimization of 2D Non-Linear Least Squares (NLLS) search implementation, the most demanding part of the detector. Results of the detection algorithm on a dataset of high resolution SAR images are presented. Performance of the proposed optimization method is assessed by comparison of algorithm implementation times.\n",
      "Synthetic Aperture Radar (SAR) Tomography is a multi-temporal technique which can reconstruct the 3D profile of a scene. One of its main features consists in the ability to detect the presence of multiple Persistent Scatterers (PS) within the same resolution cell. This paper aims to investigate the super-resolution capabilities of SAR Tomography, by detecting targets situated at a distance which is close to Rayleigh resolution. Elevation positions of scatterers are determined with Capon estimation, which is characterized by higher side-lobs reduction. An adapted form of multi-looking is proposed for extraction of targets contribution from reconstructed reflectivity functions and for estimation of reflectivity power textures. An algorithm for detection of dominant and secondary PSs will be conducted based on the derived reflectivity estimates, trying to preserve the advantages of Capon filtering used for reflectivity reconstruction.\n",
      "This paper presents results obtained by applying the maximum entropy method to image reconstruction of C-band ground-based synthetic aperture radar images. In GB-SARs, azimuth resolution is dependent on the range to target. Hence, a range dependent point spread function is synthesized. Experimental results show that through the maximum entropy method target detection is enhanced resulting in both side lobes reduction and range resolution improvement.\n",
      "Some of the first Earth Observation (EO) missions date back to the 1970s. Over the time, large datasets of Satellite Image Time Series (SITS) have been used to identify and monitor land cover evolutions. The processing complexity increases proportionally to the time span of the Earth Observation (EO) series. Because of the SITS dataset complexity and variety of contained evolution patterns, most unsupervised classification methods fail to detect and isolate the user's evolution pattern of interest. This is usually caused by the discrepancy between automatically extracted low-level features and high-level meaning assigned by the user who searches for a specific evolution. In an effort to find a solution for this difficult task, this paper presents a SVM based active learning method for the extraction of specific evolution classes from SITS. Several experiments were conducted on a dataset composed of Landsat 4 TM (Thematic Mapper) and Landsat 5 TM acquisitions over Bucharest, Romania, in the time interval of 1984-1993.\n",
      "Current satellite images and image time series provide us with detailed information about the state of our planet as well as about our technical infrastructure and human activities. These images allow us to learn more about local, regional, and global phenomena and events, including - if interpreted properly - their causes and effects. In particular, image time series provide specific information about the dynamics of many processes implicitly contained in our images that need to be unearthed and investigated in detail. A traditional approach towards this aim is to start with pixel-level or patch-level data analysis for pixel-based image analysis, followed, if necessary, by subsequent feature extraction, clustering, classification and semantic labelling in order to generate various types of change maps on different representation levels. The classification step can be supported by interactive human intervention, or by automated machine learning strategies to identify higher level objects and their spatial and temporal relationships. The detected relationships can then be formulated as parameterized rule sets that create higher-level descriptor sets of the content of the selected images, and of additional external data such as thematic maps or typical dynamics descriptions. As an innovative extension of this traditional concept, we propose a highly automated approach for application-adapted image content exploration and knowledge extraction. The reason for this strategy is the additional amount and the precision of semantic relationships and details that we can assign to an image time series once we know the final application field and how to embed and access image content within knowledge graphs.\n",
      "In the era of constantly increasing Earth Observation (EO) data collections, information extraction and data analysis should be enhanced with a multi-temporal component enabled by the temporal resolution of satellite missions and create handy, yet powerful tools for those applications involving monitoring of land cover. The image time series, as results of the satellite revisiting period, gives you insights not only on a certain area, but also on its representation at different moments of time. In order to limit the issues that might arise due to irregular time sampling of multispectral data, the authors propose a Synthetic Aperture Radar (SAR) image time series for analysis. To this point, the main goal is to mine the satellite image time series (SITS) for understanding the temporal behaviour of an area in terms of evolution and persistency. The paper introduces an analytical approach, combining coherent and no coherent …\n",
      "The Coastal Thematic Exploitation Platform (C-TEP) is an on-going European Space Agency (ESA) funded project to develop a web service dedicated to the observation of the coastal environment and to support coastal management and monitoring. For over 20 years ESA satellites have provided a wealth of environmental data. The availability of an ever increasing volume of environmental data from satellite remote sensing provides a unique opportunity for exploratory science and the development of coastal applications. However, the diversity and complexity of EO data available, the need for efficient data access, information extraction, data management and high spec processing tools pose major challenges to achieving its full potential in terms of Big Data exploitation. C-TEP will provide a new means to handle the technical challenges of the observation of coastal areas and contribute to improved …\n",
      "The EU-funded ECOPOTENTIAL project shall demonstrate, among others, the application potential of satellite images for detailed ecological studies of environmental and ecological protected areas within pre-defined bio-geographical regions of Europe. These studies aim at the corroboration of essential variables for the monitoring of protected areas in Europe. The innovative character of our project is a systematic assessment of how to exploit SAR satellite images in combination with multispectral optical satellite images and/or local in-situ measurements. The results of the project shall demonstrate the scientific gain when combining SAR image data with optical instrument data. While standard products of Sentinel-2 and WorldView-2 provide a sound basis for multispectral analysis and interpretation of vegetated areas, any additional information contained in SAR images (of TerraSAR-X and Sentinel-1) can improve the classification results and the analysis of time series data. We estimate that about 10 essential protected area variables (out of 93 envisaged variables) can be extracted from these images.\n",
      "The Earth is facing unprecedented climatic, geomorphologic, environmental and anthropogenic changes, which require global scale observation and monitoring. Thus resulting in a multitude of new orbital and suborbital Earth Observation (EO) sensors. Particularly the Very High Resolution Satellite images, are providing a wealth of information, spatial, multi-temporal, physical parameters. However, due to their inherent complexity and also very large volumes, their automatic analysis and information extraction needs to be further evolved. Since their instrument nature, image processing or computer vision methods are not always suitable, new methods need to be developed. The presentation aims to enlarge the preoccupation of the image processing/computer vision towards the particular challenges of VHR EO information extraction, particularly to image understanding and information mining.\n",
      "The abundance of available satellite images calls for their automated analysis and interpretation, including the semantic annotation of discovered objects as well as the monitoring of changes within image time series. A common approach is to cut large satellite image into contiguous patches and to classify each patch separately by attaching a semantic patch content label to it. In this context, the selected patch size is a critical parameter, as patches being too large may contain multiple objects and patches being too small may not be understandable due to missing contextual information. This approach has been embedded into an interactive active learning and exploitation environment within the ESA-funded EOLib project. The software of EOLib allows automated image data ingestion, feature extraction, and semantic image content annotation supported by interactive visualization tools. We report about our experiences with medium and high resolution Synthetic Aperture Radar (SAR) and optical multispectral image classification when using such an active learning approach. The most important phenomenon is the impact of image resolution. The higher the resolution, the higher the number of discernible land cover categories, in particular for built-up areas and industrial sites where we can see and interpret the impact of distinct human-made activities. Here, the discernible land cover categories depend on the actual image resolution. This becomes apparent when we compare the same target areas acquired by different space-borne SAR sensors (e.g., Sentinel-1A versus TerraSAR-X). In addition, it turns out that several country-specific regional \n",
      "In an era where the satellite image collections are in a continuous growth, Earth Observation (EO) image annotation and classification is becoming an important component of data exploitation. In this paper we present how feature extraction methods such as Gabor (G) and Weber Local Descriptor (WLD) are performing in a patch-based approach in the frame of Sentinel-1 and Sentinel-2 image data analysis. Having the goal to develop an application capable to join feature extraction and classification algorithms, in our assessment, we performed supervised support vector machines (SVM) and k-Nearest Neighbors (k-NN) classifications to extract a few generic classes from synthetic aperture radar (SAR), multispectral (MSI) and data fusion (DFI) images. The result of this study is intended to establish the optimum number of classes that can be found in the Sentinel-1 and Sentinel-2 images when using patch based …\n",
      "The lack of a comprehensive solution for image information mining has often brought confusion and misunderstanding when Earth Observation data based application scenarios were addressed. Considering the variety of dedicated sensors available nowadays, the particularities of the recorded data raises serious issues when explored. Most of the proposed methodologies for data analysis integrate algorithms able to cope with single cases. In order to overcome this limitation, the present paper introduce a compound, configurable framework containing two processing levels, for feature extraction and image classification, that allows different settings depending on the application being handled. The design was proposed such that it facilitates the integration of several methods and algorithm for each level, including a module to serve for validation when reference data is available. The approach is not complete without the interaction with the user, therefore, a human-machine communication strategy was also developed. The validation was performed through a prototype system meeting all the criteria of the defined framework.\n",
      "Satellite images clustering is a challenging problem in remote sensing and machine vision, where each image content is represented by a high-dimensional feature vector. However, the feature vectors might not be appropriate to express the semantic content of images, which eventually leads to poor results in clustering and classification. To tackle this problem, we propose a novel approach to generate compact and informative features from image content. To this end, we utilize geometrical information (as meta data accompanied with images) in the context of Non-negative Matrix Factorization (NMF) to generate new features. We assess the quality of new features by applying k-means clustering on the generated features and compare the obtained clustering results with those achieved by original features. We perform experiments on several satellite image data sets represented by different state-of-the-art features and demonstrate the effectiveness of the proposed method.\n",
      "With the continuous image product acquisition of satellite missions, the size of the image archives is considerably increasing every day as well as the variety and complexity of their content, surpassing the end-user capacity to analyse and exploit them. Advances in the image retrieval field have contributed to the development of tools for interactive exploration and extraction of the images from huge archives using different parameters like metadata, key-words, and basic image descriptors. Even though we count on more powerful tools for automated image retrieval and data analysis, we still face the problem of understanding and analyzing the results. Thus, a systematic computational analysis of these results is required in order to provide to the end-user a summary of the archive content in comprehensible terms. In this context, visual analytics combines automated analysis with interactive visualizations analysis techniques for an effective understanding, reasoning and decision making on the basis of very large and complex datasets. Moreover, currently several researches are focused on associating the content of the images with semantic definitions for describing the data in a format to be easily understood by the end-user. In this paper, we present our approach for computing visual analytics and semantically querying the TerraSAR-X archive. Our approach is mainly composed of four steps: 1) the generation of a data model that explains the information contained in a TerraSAR-X product. The model is formed by primitive descriptors and metadata entries, 2) the storage of this model in a database system, 3) the semantic definition of the image content based on machine learning algorithms and relevance feedback, and 4) querying the image archive using semantic descriptors as query parameters and computing the statistical analysis of the query results. The experimental results shows that with the help of visual analytics and semantic definitions we are able to explain the image content using semantic terms and the relations between them answering questions such as what is the percentage of urban area in a region? or what is the distribution of water bodies in a city?.\n",
      "Simple color, intensity representations of polarimetric synthetic aperture radar (PolSAR) images fail to show the physical characteristics of the recorded ground objects, so several coherent and incoherent decomposition theorems have been proposed in the state-of-the-art literature. All these decompositions assume the fact that any scattering mechanism can be represented as the sum of some simpler, canonical scattering mechanisms. Following the same assumption, in this paper we employ the independent component analysis (ICA) for PolSAR images representation. Since ICA is a method used for blind sources separation, we expect that the derived ICA channels represent as well as possible certain types of scattering mechanisms present in the image. ICA decomposition is validated against the coherent Pauli and the incoherent H/a/α decompositions. The normalized compression distance (NCD) is used as a measure of quality of decompositions. Experiments are made on a SLC L-band F-SAR image over Kaufbeuren airfield, Germany.\n",
      "The majority of learning algorithms work based on a training dataset. However, labeling the collected data is costly and time consuming. Active learning has gained high attention due to its ability to label a vast amount of unlabeled collected data. However, the performance of the current state-of-the-art methods declines when the number of training data is increasing. In this paper, we propose and study a variant of Support Vector Machine (SVM), namely low-rank classifier, which is regularized by the trace-norm of learning parameters in active learning scenario. We compare this algorithm with the standard SVM algorithms in depth and analyze its computational complexity and optimization solution. Our experimental results confirm, that the proposed method outperforms the other methods for an increasing amount of training data.\n",
      "This paper presents the semantic indexing of TerraSAR-X images and in situ data. Image processing together with machine learning methods, relevance feedback techniques, and human expertise are used to annotate the image content into a land use land cover catalogue. All the generated information is stored into a geo-database supporting the link between different types of information and the computation of queries and analytics. We used 11 TerraSAR-X scenes over Germany and LUCAS as in situ data. The semantic index is composed of about 73 land use land cover categories found in TerraSAR-X test dataset and 84 categories found in LUCAS dataset.\n",
      "The amount of data available on the internet provides massive additional information for the Earth Observation (EO) imagery. Periodical news, various reports and measurements, pictures or online encyclopedias are just few examples of the existent information. Occasionally, this data offers new perspectives for EO image understanding and interpretation. However, current image analysis do not benefit from the advantage given by external sources. To overcome these drawbacks, the present paper proposes an approach that goes beyond traditional information mining by using a joint image and text analysis. Fast Compression Distance (FCD) is computed to measure the similarities inside a collection of very high resolution images and text files. The main purpose is to discover common patterns within the data, without any a priori assumption, parameter-free, relying on data compression-based techniques. A hierarchical clustering is performed in order to learn about the dependencies between different types of data.\n",
      "In this paper, we present a quantitative analysis for a rapid mapping scenario that performs a damage assessment of the 2013 floods in Germany. The scenario is created using pre-disaster and post-disaster TerraSAR-X images and an automated annotation system. Our data set is tiled into patches and Gabor filters are used as a primitive feature method applied to each patch separately. An active learning system based on support vector machine is implemented in order to group the features into categories. Once all categories are identified, these are semantically annotated using reference data as ground truth. In our evaluation 7 categories were retrieved with their specific taxonomies defined using our previous hierarchical annotation scheme. We show that the system supports rapid mapping scenarios (e.g., floods, tsunami, earthquake, etc.) and interactive mapping generation. In addition, with the help of this …\n",
      "In the context of Earth Observation (EO), image information retrieval systems have gained importance as a way to explore terabytes of archive data. Concurrently, evaluation of these systems becomes a topic. Evaluation has typically been conducted in the form of metrics such as Precision Recall measures, with more recent approaches attempting to include the user in the evaluation process. This paper presents a more user centered evaluation of a CBIR tool in an EO context. The evaluation methodology involved open ended user feedback, which was then inductively categorized, and its distribution and content were analyzed. Results are presented, with conclusions indicating certain aspects of the user experience cannot be obtained from metrics alone, but can be complementary to metrics.\n",
      "Dimensionality reduction for visualization is widely used in visual data mining where the data is represented by high dimensional features. However, this leads to have an unbalanced and occluded distribution of visual data in display space giving rise to difficulties in browsing images. In this paper, we propose an approach to the visualization of images in a 3D display space in such a way that:(1) images are not occluded and the provided space is used efficiently;(2) similar images are positioned close together. An immersive virtual environment is employed as a 3D display space. Experiments are performed on an optical image dataset represented by color features. A library of dimensionality reduction is employed to reduce the dimensionality to 3D. The results confirm that the proposed technique can be used in immersive visual data mining for exploring and browsing large-scale datasets.\n",
      "The continuous progress in the acquisition of high-dimensional information (e.g., satellite image time series, or medical screening) im-plies an efficient characterization of changes that occur in a temporal series of data. A pseudo-encoding technique can be designed to represent the changes between two consecutive moments of time, based on the min-imization of a convex error function which has an analytical solution. The domain transformed feature vectors are grouped into clusters using K-Means. The proposed approach results in a better separation between classes and, thus, in an enhanced characterization of temporal changes. The experiments are done on 5 Landsat multispectral images at 30 me-ters spatial resolution, covering an area of approximately 59 X 51 km2 around Bucharest, Romania.\n",
      "Interactive visual data mining, where the user plays a key role in learning process, has gained high attention in data mining and human-machine communication. However, this approach needs Dimensionality Reduction (DR) techniques to visualize image collections. Although the main focus of DR techniques lays on preserving the structure of the data, the occlusion of images and inefficient usage of display space are their two main drawbacks. In this work, we propose to use Non-negative Matrix Factorization (NMF) to reduce the dimensionality of images for immersive visualization. The proposed method aims to preserve the structure of data and at the same time reduce the occlusion between images by defining regularization terms for NMF. Experimental validations performed on two sets of image collections show the efficiency of the proposed method in respect to controlling the trade-off between structure preserving and less occluded visualization.\n",
      "No abstract.\n",
      "In this work, a Markov random field based phase locked loop is proposed for phase unwrapping. The neighboring pixels are used to update the phase estimate of the centering pixel. The performance of the proposed method is evaluated for both synthetic and real interferometric phase. For terrains with relatively low slopes, the phase unwrapping is done successfully. However, in case of high fringe frequency, the method fails to unwrap the whole phase gradient. Nevertheless, the noise suppression capability of phase locked loop is remarkable.\n",
      "This paper describes a human-centered interactive technique that discovers the optimum combination of three spectral bands optimizing visualization of learned classes and objects in large satellite scenes. The method implements the minimum-redundancy-maximum-relevance mRMR information-based feature selector. The algorithm automatically ranks the ESA Sentinel-2 spectral bands according to the amount of information contained about a learned class or object. The top three features with maximum information are automatically fed to the R-G-B channels of the display. The tool presents the capability to optimize in real time maybe the most important problem in the computer-assisted work of the human operator: visualization of areas of interest. The evaluation of results is performed in terms of both quality (expert-driven visual analysis) and quantity (color metrics) and concludes that this approach can become an important tool in support of image information mining operations. Results of experiments performed on ESA Sentinel-2 will be presented.\n",
      "Since the development of remote sensing satellites in the latter half of the 20th century huge quantities of remotely sensed data have been gathered in the archives. Such amount of data poses a difficult challenge in extracting valuable information from the data, being estimated that only a small percentage of the data is currently analyzed. Furthermore, the current approach of assuring the long-term preservation of the archived data only emphasizes the problem of data analysis in order to extract useful information. In this paper we focus on a different approach, that of long-term data exploitation, by defining a framework for characterization and extraction of long-term satellite image time series (SITS), allowing us to fully exploit the informational content of data archives. The proposed framework aims towards creating automated methods for SITS extraction, allowing us to overcome the issues related to working with historical imagery, such as the co registration of images with missing or erroneous metadata, and by proposing methods that automate the evaluation of data quality, in support of enhancing the informational content of the extracted SITS. Considering the future remote sensing missions such as the Landsat 8 and the Sentinel programme, we focus on developing methods that allow us to enhance the temporal resolution of the extracted SITS by adding new data, enabling us to combine older and new information for a better understanding of the spatio-temporal evolution patterns. Considering the vast amount of spatial, spectral and temporal information embedded within SITS, we aim to identify possible applications of SITS analysis. In …\n",
      "Current earth observation data repositories enable us to extract observations of the same geographical area over the course of time and to create satellite image time series (SITS). Such SITS are data sets of high complexity, embedding spatial, spectral and temporal information. The rich content of SITS has generated a great interest in the recent years, many SITS analysis methods being developed. Many of these methods are focused towards improving the precision of land use/land cover detection by exploiting the inherent redundancy of SITS data. Some other methods focus on the evolution of a specific land use/land cover type. Often these methods are applied on SITS that span over a short period of time, typical one or several years. In this paper we focus on a different use scenario of SITS analysis by extracting classes of dynamic evolutions from long-term satellite image time series. As such we create a SITS of over 100 Landsat datasets, spanning from 1984 to 2011, covering the metropolitan area of Bucharest, Romania – perhaps the longest SITS ever being used. The analysis of this SITS aims to evaluate the spatio-temporal evolutions, focusing on finding classes of temporal dynamics of the main land use/land cover classes of the studied area, such as urban areas, agricultural land, forestry and water bodies, identifying interesting evolutions in the studied area. Furthermore, the extracted dynamic classes are used to establish relationships with known ancillary data such as CORINE Land Cover vector data sets or statistical datasets for demographics of the studied area.\n",
      "In this article, we propose a new methodology used for annotating TerraSAR-X products in the data base of the PDGS. Because manual annotation is very difficult and inefficient, we propose a semi-automated procedure in order to annotate TerraSAR-X datasets. Since for high resolution images, pixel-based methods do not capture the contextual information (complex structures are usually a mixture of regions and cover many pixels; different distributions of the same object can have different semantic meanings), and the global features describing the overall properties of images are not accurate enough. Therefore, the general approach adopted is to tile TerraSAR-X images into a number of no-overlapping sub-images (called patches) and to perform the feature extraction associated with these patches. In order to annotate the test dataset the following steps shall be applied to each product: 1) Group the scenes (products) in collections. 2) Select the optimal SAR image descriptors for given resolution, pixel spacing, optimal patch size, incidence angle, and orbit direction that corresponds to the basic detected TerraSAR-X products. 3) Tile the product-image into patches. 4) Generate a quick-look (in “jpg” format without rescaling the data) of each patch and also a quick-look of the full image needed for visualization. 5) Compute the descriptors (primitive features) associated with each patch. Gabor filters are used as primitive features generators computing 4 scale and 6 orientations that gives us feature vectors of 48 components (computing the mean and variance of each scale and orientation). 6) Use a classifier in order to group the features into …\n",
      "The volume of Earth Observation data is increasing immensely in order of several Terabytes a day. Therefore, to explore and investigate the content of this huge amount of data, developing more sophisticated Content-Based Information Retrieval (CBIR) systems are highly demanded. These systems should be able to not only discover unknown structures behind the data, but also provide relevant results to the users’ queries. Since in any retrieval system the images are processed based on a discrete set of their features (ie, feature descriptors), study and assessment of the structure of feature space, build by different feature descriptors, is of high importance. In this paper, we introduce a clustering-based approach to study the content of image collections. In our approach, we claim that using both internal and external evaluation of clusters for different feature descriptors, helps to understand the structure of feature space. Moreover, the semantic understanding of users about the images also can be assessed. To validate the performance of our approach, we used an annotated Synthetic Aperture Radar (SAR) image collection. Quantitative results besides the visualization of feature space demonstrate the applicability of our approach.\n",
      "In recent years the ability to store large quantities of Earth Observation (EO) satellite images has greatly surpassed the ability to access and meaningfully extract information from it. The state-of-the-art of operational systems for Remote Sensing data access (in particular for images) allows queries by geographical location, time of acquisition or type of sensor. Nevertheless, this information is often less relevant than the content of the scene (e.g. specific scattering properties, structures, objects, etc.). Moreover, the continuous increase in the size of the archives and in the variety and complexity of EO sensors require new methodologies and tools - based on a shared knowledge - for information mining and management, in support of emerging applications (e.g.: change detection, global monitoring, disaster and risk management, image time series, etc.). In addition, the current Payload Ground Segments (PGS) are mainly designed for Long Term Data Preservation (LTDP), in this article we propose an alternative solution for enhancing the access to the data content. Our solution presents a knowledge discovery architecture concept, whose intention is to implement a communication channel between the PGS (EO data sources) and the end-user who receives the content of the data sources coded in an understandable format associated with semantics and ready for the exploitation. This architecture concept encapsulates several techniques such as image content exploration based on signal processing analysis, knowledge discovery based on information modeling, and queries of the image archive based on data mining methods. Our new concept is …\n",
      "• C. Chen-An Information-Theoretic View of Visual Analytics, IEEE Comp. Graph. Appl. 28, issue 1, 18, 2008.• M. Chen, H. Jäenicke-An Information-theoretic Framework for Visualization, IEEE Trans. Viz. Comp. Graph. 16, 1206, 2010.• M. Datcu, H. Daschiel, A. Pelizzari, M. Quartulli, A. Galoppo, A. Colapicchioni, M. Pastori, K. Seidel, PG Marchetti, S. D'Elia-Information mining in remote sensing image archives-system concepts, IEEE Trans. Geo. Rem. Sens. 41, 2923, 2003.\n",
      "In recent years the ability to store large quantities of Earth Observation (EO) satellite images has greatly surpassed the ability to access and meaningfully extract information from it. The state-of-the-art of operational systems for Remote Sensing data access (in particular for images) allows queries by geographical location, time of acquisition or type of sensor. Nevertheless, this information is often less relevant than the content of the scene (e.g. specific scattering properties, structures, objects, etc.). Moreover, the continuous increase in the size of the archives and in the variety and complexity of EO sensors require new methodologies and tools - based on a shared knowledge - for information mining and management, in support of emerging applications (e.g.: change detection, global monitoring, disaster and risk management, image time series, etc.). In addition, the current Payload Ground Segments (PGS) are mainly designed for Long Term Data Preservation (LTDP), in this article we propose an alternative solution for enhancing the access to the data content. Our solution presents a knowledge discovery concept, whose intention is to implement a communication channel between the PGS (EO data sources) and the end-user who receives the content of the data sources coded in an understandable format associated with semantics and ready for the exploitation. The first implemented concepts were presented in Knowledge driven content based Image Information Mining (KIM) and Geospatial Information Retrieval and Indexing (GeoIRIS) system as examples of data mining systems. Our new concept is developed in a modular system composed of …\n",
      "The problem of phase unwrapping of two-dimensional phase signals has gained a considerable interest in recent years. The areas of applications include speckle imaging, magnetic resonance imaging and Synthetic Aperture Radar (SAR) interferometry. Phase unwrapping deals with the problem of estimating an absolute phase f from the observation of its noisy principal (wrapped) values g. This is an ill-posed problem since many possible solutions correspond to a given observation. We give an overview of several phase unwrapping algorithms and analyze them in the Bayesian framework, discussing the quality of models used to encapsulate the a priori knowledge.\n",
      "The recognition and analysis of moving targets in SAR images is a well-known topic in remote sensing. The public availability of high resolution SAR satellite images opened new perspectives for space-based small object recognition: traffic monitoring from space has matured into an established technique where the motion characteristics of ships and cars can be extracted routinely.A particular case of traffic monitoring is the search for moving trains in SAR images; here one can locate moving trains, determine their velocity, and identify the type and number of wagons. In the following, we concentrate on features to be extracted from TerraSAR-X images containing commuter trains in the area of Munich, Germany.\n",
      "Traditional approaches for Synthetic Aperture Radar image mining aim at finding accurate representations and models for specific categories of targets. Usually the task of achieving classifications with large number of classes is left for high resolution multispectral images or polarimetric SAR images, although for the latter the number of discoverable classes is significantly lower. This paper discusses the opportunity to use high-resolution SAR image spectra to obtain an increase in information content that can be extracted from the data, in order to identify a large number of classes directly from SLC images. The discussion features three spectrum processing algorithms, incorporating an information theory method, an approach for spectrum description and a spectrum estimation method. The results show that high-resolution SAR images can be used to obtain a statistical description of high accuracy for urban areas.\n",
      "The emergence of consumer sovereignty has its direct impact on the collection of qualitative and quantitative data for various business purposes. Some of the data set contains comprehensive data relating to household and national level. Identification of useful dimensions underlying the data is therefore crucial. Traditionally clustering is one of the most widely used techniques for data reduction to detect common characteristics for marketing decisions. However this is only one of its uses. What is little known is its application in compressing data to save limited server space. Clustering method can also be efficiently used to encrypt and decrypt the behavioural, categorical and ratio data on some common attributes. This study contributes to the usage of cluster centroid based compression and indicates its use of centroid based dictionary coding for future decompression.\n",
      "Achard, F. Ainsworth, T. Atwood, D. Bagan, H. Bamler, R. Bartsch, A. Benedetto, F. Blaschke, T. Bolvin, D. Bovolo, F. Buck, C. Budge, S. Chapman, B. Clemente-Colon, P. Closson, D. Cong, X. Datcu, M. Dell'Acqua, F. Di Matteo, A. Ding, K.-H. Du, Q. Durden, S. Eldhuset, K. Fabry, P. Farid, A. Firoozabadi, R. Fornaro, G. Galdi, V. Garcia-Pineda, O … Gutiérrez Barceló, Á. D. Hong, Y. Hornbuckle, B. Huffman, G. Hwang, P. Jia, X. Johnson, J. Jonckheere, I. Jones, L. Kergomard, C. Kerle , N. Kerr, Y. Lauknes, TR Lee, J.-S. Li, L. Licciardi, G. Loeb, N. Long, D. Mallorqui, J. Marpu, P. Moghaddam, M. Monaldo, F. Nilson, T. Ni-Meister, W. O'Neill, P. Venkatachalam, P. Pagano, T. Persico, R … Piepmeier, J. Plant, W. Plaza, A. Pottier, E. Radius, A. Raucoules, D. Reale, D. Ribas, F. Sansosti, E. Simard, M. Siqueira, P. Smits, P. Sobrino, JA Soldovieri, F. Sri Sumantyo, JT Stiles, B. Takahashi, K …\n",
      "Due to the short revisit time of high resolution satellites, huge amount of high resolution satellite images can be acquired every few days even few hours. It promotes the construction of Satellite Image Time Series (SITS), which contain valuable spatio-temporal information. Therefore, it is strongly needed to develop methods to explore such huge data to provide useful information in the context of earth observation. To address this issue, a patch based method for mining satellite image time series is proposed, consisting of statistical modeling and evolution analysis. Many statistical models has been proposed for Synthetic Aperture Radar (SAR) image modeling. Among them, G distribution has been proved efficient in modeling extremely heterogenous area especially for urban areas. In this paper, it is used to estimate the marginal distribution of SAR images by second-kind statistics. For the purpose of joint distribution …\n",
      "Automatic target characterization tools for satellite imagery are the need of the hour, but a large community of users still relies on visual exploration of targets and objects in SAR images. While considering the complex-valued SAR images, just looking at the image may provide incomplete and misleading information, as sometimes two entirely different behaving objects looks quite similar in SAR image. Thus a need was felt to develop tools, to support visual target recognition and analysis. In this paper we present the implementation concerns of multiple subaperture decomposition (MSAD) approach as a software tool for analysis of complex-valued SAR images. MSAD approach exploits the holographic property of complexvalued SAR images at the cost of reduced resolution to understand the scattering behavior of targets on ground. Foremost, this tool is an attempt in direction to generate a temptation to use complex-valued SAR data over detected data for target analysis. This tool has been developed in ENVI-IDL environment.\n",
      "The scientific community is challenged today by more and more complex requirements coming from the users in a very attractive EO context created by GMES. Recent debates show that there is no common understanding or standardization of, for example, the land use land cover products and the way of presenting them to the user, although de-facto standards like CORINE (CLC) are already in use. CLC is the European standard for extracting and presenting land cover and land use information for monitoring and protecting the environment. All mapping methodologies are mostly manually assessed because there still are important difficulties in creating thematic maps of land cover using automatic classification methods. When coming to land use, the final products based on satellite image of classification methods do not contain exclusive mapping units but mixtures of heterogeneous land cover classes, as …\n",
      "TerraSAR-X is the Synthetic Aperture Radar (SAR) German satellite which provides a high diversity of information due to its high-resolution. TerraSAR-X acquires daily a volume of up to 100 GB of high complexity, multi-mode SAR images, i.e. SpotLight, StripMap, and ScanSAR data, with dual or quad-polarization, and with different look angles. The high and multiple resolutions of the instrument (1m, 3m or 10m) open perspectives for new applications, that were not possible with past lower resolution sensors (20-30m). Mainly the 1m and 3m modes we expect to support a broad range of new applications related to human activities with relevant structures and objects at the 1m scale. Thus, among the most interesting scenes are: urban, industrial, and rural data. In addition, the global coverage and the relatively frequent repeat pass will definitely help to acquire extremely relevant data sets. To analyze the available …\n",
      "This paper discusses methods and parameter settings that help to estimate texture in SAR images. In general, this is a difficult task for SAR images that are characterized by speckle noise and which span a wide range of pixel magnitudes. We applied Gauss Markov Random Field (GMRF) models and Enhanced Model Based Despeckling (EMBD) to 1 meter resolution amplitude images of the German TerraSAR-X mission. The results demonstrate that one can find appropriate parameter combinations that allow robust texture estimation even for different types of target areas.\n",
      "Image satellite sensors acquire huge volumes of imagery to be processed and stored in big archives. An example of such an archive is the German Remote Sensing Data Center (DFD) at Oberpfaffenhofen, Germany, that receives about hundreds of GigaBytes of data per day entailing 104 GigaBytes in the repository. To provide access to this data, web applications have been developed, eg the DLR EOWEB1, to retrieve images according to meta information such as date, geographical location or sensor. Alexandria Digital Library2 is another example of accessing remote sensed imagery through its meta information providing a distributed searching mechanism for retrieving geospatial referenced data collections. It is able to search different types of databases placed at different locations. The software enables to implement web clients as Globetrotter3 or Gazetteer4. These systems based on meta information retrieval allow only constrained queries giving no information about the content, and consequently, no content based retrieval is offered. At the conference on database techniques for pictorial applications that took place in 1979 in Florence, Italy, the pursued aim was the integration of databases with image processing. This idea evolved, in 1990, promoting a new field, called Content Based Image Retrieval (CBIR). In 1998, CBIR got married with Data Mining and Knowledge Database Discovery (KDD) emerging, in 2000, the Image Information Mining (IIM) field. This new domain requires expertise in image processing, database organization, pattern recognition, contentbased retrieval and data mining: image processing indicates the …\n",
      "In this paper, we present a model to define an analogy between text and image data using ICA basis functions and we apply it to index Very High Resolution (VHR) satellite images. We introduce our text-image analogy by defining visual documents, visual words, visual vocabulary and labeling each word of document using vocabulary words. Further, we propose a classification using a simple Bayesian method to evaluate our model for VHR satellite image characterization. The results for two types of vocabularies, one based on visual words clustering and other based on obtaining ICA components for each class, is compared for a variety of natural and man-made scenes.\n",
      "In this paper a new algorithm for interferometric phase restoration is presented. Firstly, a continuous framework for anisotropic phase diffusion is stated. A tensorial based metric allows directional control. The periodic continuous structure of the phase representation is accounted for. Secondly, this framework is adapted for interferometric phase filtering. Progressive re-estimation of directionality avoids directional bias. Isotropy and anisotropy are adaptively combined with a constant overall diffusion rhythm, so that the degree of regularization is the same regardless of the underlying topography. Robust estimation minimizes the spread of outliers. Results on both synthetic and TerraSAR-X data are provided.\n",
      "While typical remote sensing imaging instruments produce more and more data, what we miss today are reliable tools for automated information extraction form these images. In the following, we propose a so-called Content Map, a novel Earth Observation value adding product. Basically, it comprises several class files and a viewer showing the different classes of land use and objects contained in the corresponding image data. In order to avoid processing delays, the class files have to be generated in an unsupervised mode as a real time product; thus, interactive user interactions have to be limited to training and testing intervals. As typical examples we use image data of the German TerraSAR-X mission that produces SAR image data in a variety of different modes.\n",
      "Remote sensing Earth Observation images may contain blemishes or artificial structures generated by the processing or directly by the sensors. These artifacts decrease the quality of the images and may lead to analysis and interpretation problems. We are interested in detecting these defects automatically. A visual analysis of such artifacts brings us to the conclusion that they constitute a local modification of the complexity of the image. Therefore, this paper will give a complexity-based approach for the detection of these defects. Our approach will comprise two different methods: in a first approach, the artifacts will be compared with given examples based on a complexity comparison. Due to some weaknesses of this method a second approach will be defined which will not depend on given examples but will take into consideration the local complexity context of the images.\n",
      "In this paper we present two algorithms for information extraction from Single Look Complex (SLC) Synthetic Aperture Radar (SAR) images. The first algorithm is based on Tikhonov regularization with Total Variation (TV) and a Point-Based Feature (PBF) term. Based on the equivalence of Tikhonov and the Bayesian estimate, the second algorithm is a Maximum A Posteriori (MAP) estimation with a complex-valued Gauss-Markov Random Field (GMRF) in addition to the TV prior. The first algorithm produces a despeckled image preserving fine details and texture. The second algorithm gives a denoised image and in addition the estimated feature parameter vector thetas.\n",
      "Ce rapport s’ inscrit dans le cadre de l’étude menée au Centre de Compétences CNES-DLR-ENST au sein du département TSI de Télécom Paris sur l’“Apprentissage automatique de la sémantique dans les images”. Il fait suite au rapport préliminaire [27] et au rapport de la phase 1 délivé en décembre 2007 [26].\n",
      "In exercise of the powers confered by section 52(1) of the Value Added Tax Act, the Minister of Finance, Trade and The Blue Economy hereby makes the following Regulations … 1. These Regulations may be cited as the Value Added citation … 2. The First Schedule to the Value Added Tax Act is Amendment or … 2711.1900 Petroleum gases and other gaseous hydrocarbons (Liquefied) … JEAN-PAUL ADAM MINISTER OF FINANCE, TRADE AND THE BIUE ECONOMY\n",
      "In this paper a wavelet based method for SAR data denoising and compression is presented. An unsupervised stochastic model based approach to image denoising is presented. SAR image is modeled in wavelet domain Gauss Markov Random field and noise is considered as Gaussian with unknown variance. The parameters are estimated from incomplete data using mixtures of wavelet coefficients, and expectation maximization algorithm. The expectation maximization algorithm is used to efficiently compute a maximum a posteriori estimate. Observed wavelet coefficient is estimated using inter and intra scale of wavelet coefficients to estimate image and noise model parameters. Presented wavelet based method efficiently removes noise from SAR images. The second step is to design an entropy coder that efficiently codes despeckled image. The texture parameters obtained at the despeckling stage are used in the compression process. The image coder is tested on X-SAR data with and achieves comparable compression results with the wavelet based state-of-the art coders for SAR data compression.\n",
      "In this paper a wavelet based method for SAR data denoising is presented. The SAR image is corrupted by a multiplicative noise that can be modeled as an additive noise in wavelet domain. In this paper an image is modeled as a Gauss Markov Random field and noise is considered as Gaussian with unknown variance. An unsupervised stochastic model based approach to image denoising is presented. The parameters are estimated from incomplete data using mixtures of wavelet coefficients, and expectation maximization algorithm. Observed wavelet coefficient is estimated using inter and intra scale of wavelet coefficients to estimate image and noise model parameters. Presented wavelet based method efficiently removes noise from SAR images.\n",
      "SCAMPI-Staff College Automated Military Periodical Index. Database of articles on military and naval science, operational warfare, joint planning, national and international politics, and other areas researched by Joint Forces Staff College from 1985 to present.\n",
      "The article, presents and analyses the existing body of knowledge for information extraction from meter resolution SAR data, dealing with the methods of complex image analysis, target detection and recognition, scene reconstruction.\n",
      "The availability of Earth Observation (EO) imagery is relatively recent, i.e. less than 20 years. With the development of REMOTE Sensing (RS) technology, (e.g. high-resolution images, higher acquisition frequencies and new sensor types), the scope of RS Images allows users to perform a huge variety of specific applications, such as land cover mapping, thanks to increased levels of information and the possibility of synergy between data sets. Information in forms of geo-referenced DEMs / Images should be used for 3D real-time visualisation over large area at the country scale while preserving high resolution data/content and realistic rendering. Up to now, the exploitation / integration of large and complex databases integration in the overall interactive 3D visualisation process is currently extremely difficult. However, the demand for such technologies exploded in the last years and lead to a reinforcement of world acquisition programs (SRTM2). Therefore, RS and Virtual Reality communities are faced to several challenges to deal in real-time with such amount of data: e.g. Landsat images mosaic / ERS Tandem DEM over the whole Germany (gridding: 25m) Ô (40000² pixel images) × (R-G-B channels + elevation information). In addition to the rendering time constraints, realistic visualisations require to enhance / regularise the database. In this purpose, an important level of understanding and content extraction have to be reached in order to perform significant improvements in the data and particularly in the DEMs, which bring the geometry information. Indeed, DEM information is now recognised as one of the most important data structures used …\n",
      "The interpretation of EO data requires not only data and/or information fusion for better understanding of Earth cover structures, but, at a higher level, needs the aggregation with existing bodies of knowledge specific to the application fields. Thus, from this perspective, the interpretation of EO data is a knowledge driven task. The knowledge consists in the ensemble of existing information, known causalities and other type of associations between information and concepts. During the interpretation process new information and causalities are discovered, thus we have a dual process of knowledge acquisition. To formalize the knowledge both in knowledge driven the interpretation and in the knowledge acquisition we need to define a hierarchy from the point of view of information categories. In the approach we propose now, it is possible to use the knowledge and semantic stored in KIM like systems, to provide to other EO interpretation tools information which is often omitted when humans operate such system because it is clearly an image content element. Thus the idea is to build intelligent interfaces, which explain each other, such to arrive at a compromise for a common understanding. The index system of image databases has a hierarchical structure: image, features, semantics, and domain ontology. The structure can be attached to a tree representation, which is like a union of sub-trees for domain ontology. When a user is training a new semantic label on a image, the system may try to identify the other semantic labels closest to it and give the user the possibility to choose an old one or to define a new one. An entropy measure has been …\n",
      "This paper presents a transformed-based compression of high resolution Synthetic Aperture Radar (SAR) images using wavelet transformation. SAR images are corrupted by multiplicative noise called speckle. To achieve higher compression ratio, this noise is firstly removed and denoised image is compressed. To remove speckle from SAR images a Bayesian filter in wavelet domain is developed. Lossy quantization is implemented using Bayesian theory in order to predict observed wavelet coefficient using inter and intra-scale dependencies in wavelet domain. The predicted indices are encoded. The signal-to noise ratio of reconstructed images and achieved compression ratios are compared with the state-of-the-art compression methods applied to the SAR images with resolution of one meter.\n",
      "I. INTRODUCTION The process of searching and analyzing data in order to discover potentially useful information is a crucial matter when dealing with large databases. Considering the huge amount of data collected by satellite observation systems, opportunities to generate multispectral image time-series are increasing. Exploratory methods are needed to understand the dynamics of Earth observation scenes and of their objects. In this paper, information mining methods are proposed. They first rely on a hierarchical model based information representation. Entropic measurement similarity in a modeled dynamic feature space characterizing the dynamics of objects and of image structures are then researched.\n",
      "9 Gauss–Markov random fields have been successfully used as texture models in a host of applications, ranging from 10 synthesis, feature extraction, classification and segmentation to query by image content and information retrieval in 11 large image databases. An issue that deserves special consideration is the selection of the neighbourhood order (model 12 complexity), which should faithfully reflect the Markovianity of spatial interactions. Estimating the parameters for the 13 wrong model will not capture the essential statistical properties of the texture in question: a lower order model will not 14 be informative enough, while a higher order will clutter the description with superfluous information, fitting the noise 15 rather than the data. 16 We give a full Bayesian solution for estimating the model complexity, using an appropriate set of prior probabilities 17 on the parameters. The closed-form decision criterion is derived by employing a Gaussian approximation of the posterior 18 probability around the mode. The validity and benefits of this approach are demonstrated on two important problems 19 arising in machine vision: texture replication and image classification.© 2002 Published by Elsevier Science BV\n",
      "Scene understanding of remotely sensed images requires a certain amount of preprocessing in order to remove, or alleviate the effects of, all those factors that disturb the imaging process. These factors depend essentially on the peculiar way in which each kind of sensor acquires the image (sensor-related factors) and on the terrain topography, the illumination and the view angle (radiometric factors). In this paper, a Bayesian model-based maximum a posteriori estimation approach to correct these disturbing factors is suggested.\n",
      "Knowledge of land-cover classes can help to interpret and assess the quality of digital elevation models, derived from interferometric synthetic aperture radar data, eg ERS-Tandem or future X-SAR/SRTM archive. We propose the Bayesian approach to image classification using information fusion from different sources. The method of classification is based on the three processing steps: information fission by feature extraction, dimensionality reduction by unsupervised clustering and supervised classification with information fusion using Bayesian networks. The potential of the classification method is illustrated by examples from ERS-Tandem data, airborne DLR E-SAR data and live down-link X-SAR/SRTM data.\n",
      "The problem of phase unwrapping of two-dimensional phase signals has gained a considerable interest in recent years. The areas of applications include speckle imaging, magnetic resonance imaging and Synthetic Apert;re Radar (SAR) interferometry. Phase unwrapping deals with the problem of estimating an absolute phase f from the observation of its noisy principal (wrapped) values g. This is an ill-posed problem since many possible solutions correspond to a given observation. We give an overview of several phase unwrapping algorithms and analyze them in the Bayesian framework, discussing the quality of models used to encapsulate the a priori knowledge.\n",
      "The authors make a comparison of the state of the art algorithms for snow areas segmentation in optical satellite images. The comparison address the accuracy of the forward model used and the informational theoretical aspects characterising the detection/segmentation algorithms. They also, comparatively, introduce and a new approach: the segmentation of the snow cover as ill-posed inverse problem and its solution in the frame of the Bayesian inference.\n",
      "In this paper a novel treatment of Interferometric SAR as a Bayesian estimation problem is presented. Application of the Bayesian approach involves devising: a model relating system geometry, surface topography and reflectivity to the measured radar signals, a stochastic model of the topographic surface embodying the dominant terrain characteristics of slope and curvature and a stochastic model of the surface reflective properties. This information is combined into a conditional probability density function of the model parameters given the measured data. System models are proposed, and possible algorithms for estimating model parameters are considered. The issue of formulating an error estimate is discussed.\n",
      "IEEE GRSS Distinguished Achievement Award the benefit and advancement of the Geoscience and Remote Sensing Society. The award shall be considered annually but not be presented if a suitable candidate is not identified. The following factors are suggested for consideration: leadership, innovation, activity, service, duration, breadth of participation and cooperation. GRSS membership is required. The awardee receives a certificate.\n",
      "The high complexity of the remotely sensed images and measurements provided by the last generations of sensors demand new techniques for scene understanding and analysis. The similarity of fractal and real world objects was observed and intensively studied from the very beginning. The fractal geometry became a tool for computer graphics and data visualisation in the simulation of the real world. In order to perform visual analysis and comparisons between natural and synthetic scenes several techniques have been developed. After a period of qualitative experiments fractal geometry began to be used for objective and accurate purposes: modelling image formation processes, generation of geometrically and radiometrically accurate synthetic scenes and images, evaluation of the characteristics of the relief, determination of the surface roughness, analysis of textures. The techniques based on fractals show promising results in the field of image understanding and visualisation of high complexity data. In the aim to give an introduction to the theory of fractals the following topics will be summarised in this paper: the definition and analysis of fractals based on self-similarity and self-affinity behaviours, definitions for fractal dimension, fractal synthesis, the projection properties of fractal surfaces. The derived techniques with applications in geo-information processing and understanding will be underlined: synthetic DEMs generation, fractal resampling of actual DEMs, algorithms for computation of the fractal dimension, multiresolution analysis of fractal images, multiresolution analysis and fractal dimension estimation. The paper presents also …\n",
      "❖ Coastal areas call for dedicated analysis tools as they are characterized by characteristic static and dynamic features [2].\n",
      "Les données de télédétection sont en pleine expansion, tant du point de vue de l'amélioration de la fréquence d'observation, des résolutions spatiales, que de la facilité d'accès aux données. Aussi, ce changement de contexte récent permet de bénéficier des apports des méthodes de deep learning dans le domaine des images d'observation terrestre. Les temps de revisite au dessus d'un même site devenant de plus en plus courts (quelques jours pour les satellites), cela permet d'envisager la mise à jour rapide des produits d'occupation des sols. Aujourd'hui, cette réactualisation reste un processus long et onéreux, essentiellement réalisé par expertise humaine. Bénéficier d'une méthode automatique exploitant l'imagerie satellite permettrait d'améliorer la fréquence de réactualisation de ces bases. Dans ce domaine, de nombreux travaux ont déjà été entrepris, tant au sujet des images radar que des images optiques, chacun de ces modes présentant des avantages et inconvénients différents:\n",
      "Page 1. Big Data Analytics for Detailed Urban Mapping Mihai Datcu Daniela Molina Espinoza, Octavian Dumitru, Gottfried Schwarz Page 2. Institut für Methodik der Fernerkundung bzw. Deutsches Fernerkundungsdatenzentrum Folie 2 Big Data: The German EO Digital Library The data access Page 3. Institut für Methodik der Fernerkundung bzw. Deutsches Fernerkundungsdatenzentrum Folie 3 Information vs. Data TerraSAR-X 11-OCT-2008 512x512 pixels ERS1 24-JUL-1992 512x512 pixels Page 4. Institut für Methodik der Fernerkundung bzw. Deutsches Fernerkundungsdatenzentrum Folie 4 Page 5. Institut für Methodik der Fernerkundung bzw. Deutsches Fernerkundungsdatenzentrum Folie 5 EOLib: Earth Observation image Librarian ▪ EOLib is a modular system composed of several components: PGS in blue and new EOLib in orange ▪ EOLib offers mining/search …\n",
      "Design”, IEEE Transactions on Geoscience and Remote Sensing, Vol. 48, Issue 2, pp. 606-614, Feb. 2010.[2] C. Dumitru, M. Datcu, S. Cui, and G. Schwarz,“Information Content of. Very High Resolution SAR Images: Semantics, Geospatial Context, and Ontologies”,\n",
      "Table of Contents Page 1 JUNE 2017 VOLUME 10 NUMBER 6 IJSTHZ (ISSN 1939-1404) SPECIAL ISSUE ON THE 2016 IEEE INTERNATIONAL GEOSCIENCE AND REMOTE SENSING SYMPOSIUM Foreword to the Special Issue on the 2016 IEEE International Geoscience and Remote Sensing Symposium . . . . . . . . . . .. 2428 Sensing Platforms Simulation Study of Geometric Characteristics and Coverage for Moon-Based Earth Observation in the Electro-Optical Region . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .Y. Ren, H. Guo, G. Liu, and H. Ye 2431 Potential Applications of Small Satellite Microwave Observations for Monitoring and Predicting Global Fast-Evolving Weathers . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . Y. Ma, X. Zou, and F. Weng 2441 Computational Infrastructure Parallel Implementation of a Full Hyperspectral Unmixing Chain \n",
      "The article aims at presenting the most recent developments and trends in information extraction from Synthetic Aperture Radar SAR data.\n",
      "A Simple and Efficient Feature Extraction Algorithm for Geophysical Phenomena ...................... .............................................................5 R. Ramachandran, X. Li, S. Movva, S. Graves Coalescing ICA and Wavelets Coefficients for Image Information Mining in Earth Observation Data Archives........................................9 VP Shah, SS Durbha, NH Younan, RL King Categorization based Relevance Feedback Search Engine for Earth Observation Images Repositories … Inter-Satellite Microwave Radiometer Calibration Between AMSR and TMI.................................. ..........................................................89 L. Hong, W. Linwood Jones, TT Wilheit Early Results on Cloud Profiling Radar Post-launch Calibration and Operations .................................................................. … Interpolation Effects on Accuracy of Mutual Information Based Image Registration..............................................................................180 Qi Li, I. Sato, Y. Murakami …\n",
      "About the Cover: Cameron’s coarse classification of target symmetric scattering. Patches represent the six elemental scatterer classes: trihedral, dihedral, dipole, cylinder, narrow diplane, and quarter wave. Cameron’s classification tolerates a scattering class dispersion of up to 8 dB. Colors go from blue (0-dB dispersion on the diamonds) to red (7–8 dB). Such large class (or channel imbalance) dispersion cannot be tolerated in the context of known polarimetric SAR calibration requirements. For more information, see “Characterization of Target Symmetric Scattering Using Polarimetric SARs” by R. Touzi and F. Charbonneau, which begins on page 2507.\n",
      "New image understanding methods are needed to address the large amount of complex scenes that is going to be produced in the forecoming years by next generation high resolution synthetic aperture radar (SAR) sensors. These methods must be able to deal with the uncertainty that is present in the problem in form of missing or ambiguous data. It is thus a direct necessity that they have a probabilistic foundation.\n",
      "Page 1. Calibration Aspects for Time Series of High Resolution TerraSAR-X Images Gottfried Schwarz and Mihai Datcu German Aerospace Center DLR Remote Sensing Technology Institute Page 2. Image Time Series - http://en.wikipedia.org/wiki/Satellite_Image_Time_Series “Satellite observations offer new opportunities for understanding how Earth is changing, for determining what reasons cause these changes, and for predicting future changes…” - We aim at automated data analysis and mainly search for changes of visible and hidden phenomena. - We look for events as well as for gradual changes. - We study o pixel brightness histories and o the evolution of extracted features, classes, objects, image content. Page 3. Europa District in Stuttgart, Germany seen by TerraSAR-X Overview Image Color Coded Temporal Changes Page 4. Time Series: Requirements, Caveats and Extra Steps - Requirements …\n",
      "In an era where the satellite image collections are in a continuous growth, Earth Observation (EO) image annotation and classification is becoming an important component of data exploitation. In this paper we present how feature extraction methods such as Gabor (G) and Weber Local Descriptor (WLD) are performing in a patch-based approach in the frame of Sentinel-1 and Sentinel-2 image data analysis. Having the goal to develop an application capable to join feature extraction and classification algorithms, in our assessment, we performed supervised support vector machines (SVM) and k-Nearest Neighbors (k-NN) classifications to extract a few generic classes from synthetic aperture radar (SAR), multi-spectral (MSI) and data fusion (DFI) images. The result of this study is intended to establish the optimum number of classes that can be found in the Sentinel-1 and Sentinel-2 images when using patch based image classification techniques. Also another important objective of this paper is to determine the best patch sizes suitable for this classification type in order to return best results for Sentinel-1 and Sentinel-2 EO images.\n",
      "Traditional approaches for SAR image classification and target recognition in high resolution acquisitions discard phase information and are solely based on the detected data. When one makes use of several SLC image acquisitions, the phase variation is the main source of information. We propose a method for feature definition and extraction which combines single SAR acquisitions with interferometric information. Not only that phase becomes less random, but it describes the changes that occur on the received scene reflectivity. In the hypothesis that two successive acquisitions are taken on a stationary scene (tandem acquisitions), combined information from these data can be employed to describe the scene content. Thus, we propose the usage of spectral based descriptors that make use of the full complex signal from two or more SLC acquisitions to construct robust image descriptors. The experiments show that the interferometric information can be very valuable for the recognition of coherent targets, increasing the recognition rate. Our approach relies on the estimation of the SAR image spectra, from which features are derived in two stages: the estimation of the model order and the extraction of the most relevant descriptors. The set of descriptors is extracted from the complex spectrum of the SAR image, using a spectral decomposition method. We consider the problem of estimating the parameters of complexvalued two-dimensional sinusoidal signals observed in noise. Our approach considers not just isolated objects but also takes into account the complexity of high resolution urban scenes, where there is a large variety of structures …\n",
      "Foreword to the Special Issue on Synthetic Aperture Radar (SAR)—New Techniques, Missions and Applications . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . G. Krieger, A. Moreira, M. Zink, M. Shimada, and S. Hensley … An Airborne Radar Sensor for Maritime and Ground Surveillance and Reconnaissance—Algorithmic Issues and Exemplary Results . . . . . . . . . . . . . . . . . . M. Kirscht, J. Mietzner, B. Bickert, A. Dallinger, J. Hippler, J. Meyer-Hilberg … Multichannel Wideband Synthetic Aperture Radar for Ice Sheet Remote Sensing: Development and the First Deployment in Antarctica . . . . . . Z. Wang, S. Gogineni, F. Rodriguez-Morales, J.-B. Yan, J. Paden, C. Leuschen, RD Hale, J. Li, CL Carabajal, D. Gomez-Garcia, B. Townley, R. Willer, L. Stearns, S. Child, and D. Braaten … Independent Verification of the Sentinel-1A System Calibration …\n",
      "This document is the second deliverable for WP6 (A Virtual Observatory for TerraSAR-X data) of TELEIOS. The objective of WP6 is to build a Virtual Earth Observatory for TerraSAR-X data and demonstrate its functionality by developing selected rapid mapping applications. The present document continues the work started with Deliverable D6. 1 “Requirements specification for the VO for TerraSAR-X data and applications” where the user requirements for the TerraSAR-X Earth Observatory were presented.\n",
      "With the launch of the new imaging satellite sensors, content extraction methodologies for scene understanding require updates that aim at bridging the gap between science, operational activities and politics on various levels. In order to fully benefit from these spaceborne sensors, the new directions of research should integrate the language that all parties involved easily understand–semantics. By following the new standards of cartography introduced by EO emergency centers, the automated technology presented in this paper authorizes simultaneous information retrieval, mapping and semantic annotation of the data. The first step is patch-level analysis of the image, this enabling automatic generation of map legends. Following an agreement between the learning model and the spatial resolution of the images, we exploit Latent Dirichlet Allocation model (LDA) to map heterogeneous pixels with no semantic meaning into thematic classes with high-level ontology attached directly by the users.\n",
      "The progress of Earth Observation (EO) meter and sub-meter resolution sensors, both optical and Synthetic Aperture Radar (SAR) images rises major problems for the optimal exploitation of the image information content. While, in the past decades the exploitation of the acquired EO images with resolution of tens of meters was limited to maximum of 5% from data acquired, with the advent of higher resolution sensors, this figure could decrease. Thus, it is need a new generation of concepts and tools to add value to EO images, to facilitate the access to the image content, in direct understandable manner. The Image Librarian is concept to enable interprets contents, associate it with other information, creates categories, understand user the inquiry, dialogues with the user to refine expression of needs, comments and inform users about data content, and suggest the most appropriate products and their interpretation …\n",
      "In the context of Earth Observation, this paper presents a method whose purpose is to supersede human inductive learning and reasoning in complex scene understanding and characterization by automatic adding high-level ontology to the image. The innovation in this direction of data mining consists in a hierarchical analysis of remote sensing image content. Spectral and spatial information are both assessed in a statistically balanced combination. The aim of the proposed algorithm is to provide high-level semantic classifications for image content. According to a user interest, objects are firstly extracted using a Knowledge Based Information Mining (KIM) System. Further, invariant descriptors for the relative positioning of objects inside a configuration are computed in order to describe topological arrangements inside the scene. New patterns containing spectral and topological information about similar objects configurations are defined through a k-means classification. This approach is exemplified on a WorldView2 scene acquired over Bucharest, Romania.\n",
      "During the last years, it became evident that despite the increasing volume of Earth observation images, a continuous interactive analysis and classification resulting in a semantic labelling of these data is feasible. As a consequence, a number of ESA-financed projects aimed at the interactive semi-automated extraction of user-defined image contents as well as the integration of these capabilities with meta-data descriptor concepts and web-based services. While conventional meta-data annotations provide the capability for browsing among pre-defined entries such as acquisition dates and image coordinates, our new extraction capabilities allow for the systematic annotation and retrieval of scenes containing labelled objects such as ships, airports, or crop types. The typical issues encountered during the development of conventional descriptor concepts appear again: individual solutions will be succeeded by interoperable strategies and co-ordinated efforts are required to cover the various technical peculiarities of active and passive imaging instruments. The article presents the results and experience gained using the Information Mining techniques and functions implemented in the TerraSAR-X PGS system and analyses future issues regarding the multi-mission use of Sentinels and the potential for novel GMES services.\n",
      "Conventional query techniques for remote sensing image archives as they are available from various satellite data providers are reviewed. The Swiss National Remote Sensing Image Archive is currently being installed at the Swiss Center for Scientific Computing (CSCS/SCSC) and a status report will be given. In parallel with classical query and retrieval possibilities, content-based image search becomes increasingly important. This leads to a new architecture for remote sensing ground segments. A concept for querying by content from large remote sensing image archives is presented.\n",
      "In this paper we measure the informational content of the Wigner-Ville spectral representation of SAR images in a patch-wise approach, making use of the parametric stochastic measure given by the Renyi Entropy. Following the informational measures defined by Flandrin, we perform a local analysis of the time-frequency representation of the SAR patch, resulting in a set of descriptors with further use to identify the presence of a given Scene Class in a patch database and to retrieve the patches that have similar content with respect to this specific informational measure. Copyright  2009 Universitatea Politehnica Bucuresti.\n",
      "Discrimination, feature and model selection analyses from the perspective of classification performance conducts to the discussion of the relationships between Support Vector Machine (SVM), Bayesian and Maximum Entropy (MaxEnt) formalisms. Maximum Entropy discrimination can be seen as a particular case of Bayesian inference, which at its turn can be seen as a regularization approach applicable to SVM. Probability measures can be attached to each feature vector thus, feature selection can be described by a discriminative model over the feature space. Further the probabilistic SVM allows to define a posterior probability model for a classifier. In addition, the similarities with the kernels based on Kullback-Leibler divergence can be deduced, thus returning to a Maximum Entropy similarity.\n",
      "In the context of satellite image segmentation, we describe some enhancement techniques: the Absorption of Small Objects and the Classification based on a Similarity Measure between Regions. The paper suggests that the only useful automatic segmentation is a very versatile, highly customizable one.\n",
      "The article presents two methods to asses the image complexity for further use to improve sustainable humanitarian crisis response in risk reduction using Earth Observation images. An image can be partitioned into different objects, with different attributes depending on the observer interest. Similar techniques with the one used to locate words, regarded as molecules, formed by combining atoms, are proposed to describe images based on their information content. In this paper, we use primitive feature extraction and clustering to code the image information content. Our purpose is to describe the complexity of the coded image with a two-sided look: based on two approaches namely the rate-distortion theory and the Kullback-Leibler divergence.\n",
      "Sentinel 2 (S2) satellite provides a systematic global coverage of land surfaces, measuring physical properties within 13 spectral intervals at a temporal resolution of 5 days. Computer-based data analysis is highly required to extract similarity by processing and assist human understanding and semantic annotation in support of Earth surface mapping. This paper proposes an exploratory search methodology for S2 data underpinning both visual and latent characteristics by means of data visualization and content representation. For optimized results, the authors focus on a detailed assessment of top relevant state-of-the-art algorithms for features extraction and classification to determine which one could handle best the characteristics of S2 data\n",
      "The Sentinel-1 mission provides a freely accessible opportunity for urban image interpretation based on synthetic aperture radar (SAR) data with a specific resolution, which is of paramount importance for Earth observation. In parallel, with the rapid development of advanced technologies, especially deep learning, we urgently need a large-scale SAR dataset supporting urban image interpretation. This article presents OpenSARUrban: a Sentinel-1 dataset dedicated to the content-related interpretation of urban SAR images, including a well-defined hierarchical annotation scheme, data collection, well-established procedures for dataset compilation and organization as well as properties, visualizations, and applications of this dataset. Particularly, our OpenSARUrban collection provides 33 358 image patches of urban SAR scenes, covering 21 major cities of China, including 10 different target area categories, 4 kinds \n",
      "To investigate the limits and merits of information extraction from a single high-resolution synthetic aperture radar (SAR) backscatter image, we introduce a model-based algorithm for the automatic reconstruction of building areas from single-observation meter-resolution SAR intensity data. The reconstruction is based on the maximum a posteriori estimation by Monte Carlo methods of an optimal scene that is modeled as a set of mutually interacting Poisson-distributed marked points describing parametric building objects. Each of the objects can be hierarchically decomposed into a collection of radiometrically and geometrically specified object facets that in turn get mapped into data features by ground-to-range projection and inverse Gaussian statistics. The detection of the facets is based on a likelihood ratio. Results are presented for airborne data with resolutions in the range of 0.5-2 m on urban scenes covering agglomerations of buildings. To achieve robust results for building reconstruction, the integration with data from other sources is needed.\n",
      "Throughout the years, various Earth Observation (EO) satellites have generated huge amounts of data. The extraction of latent information in the data repositories is not a trivial task. New methodologies and tools, being capable of handling the size, complexity and variety of data, are required. Data scientists require support for the data manipulation, labeling and information extraction processes. This paper presents our Earth Observation Image Librarian (EOLib), a modular software framework which offers innovative image data mining capabilities for TerraSAR-X and EO image data, in general. The main goal of EOLib is to reduce the time needed to bring information to end-users from Payload Ground Segments (PGS). EOLib is composed of several modules which offer functionalities such as data ingestion, feature extraction from SAR (Synthetic Aperture Radar) data, meta-data extraction, semantic definition of the …\n",
      "As a newly emerging technology, deep learning is a very promising field in big data applications. Remote sensing applications often involve huge volume data obtained daily by numerous in-orbit satellites. This makes it a perfect area for data-driven applications. Over the past years, there has been an exponentially increasing interest in deep learning for remote sensing image processing, including not only optical imagery but also synthetic aperture radar (SAR) imagery. In addition to the rapidly growing size and spectral, spatial and temporal resolution of remote sensing data, there are other challenges that are unique in this area, eg the intrinsic complexity and particularity of each specific sensor and their multi-modality, the fundamental physical properties embedded in the data, the underlying principles for information retrieval, etc. To promote the research in this area, we have organized a special focus feature on …\n",
      "Deep learning methods are often used for image classification or local object segmentation. The corresponding test and validation data sets are an integral part of the learning process and also of the algorithm performance evaluation. High and particularly very high-resolution Earth observation (EO) applications based on satellite images primarily aim at the semantic labeling of land cover structures or objects as well as of temporal evolution classes. However, one of the main EO objectives is physical parameter retrievals such as temperatures, precipitation, and crop yield predictions. Therefore, we need reliably labeled data sets and tools to train the developed algorithms and to assess the performance of our deep learning paradigms. Generally, imaging sensors generate a visually understandable representation of the observed scene. However, this does not hold for many EO images, where the recorded images only depict a spectral subset of the scattered light field, thus generating an indirect signature of the imaged object. This spots the load of EO image understanding, as a new and particular challenge of Machine Learning (ML) and Artificial Intelligence (AI). This chapter reviews and analyses the new approaches of EO imaging leveraging the recent advances in physical process-based ML and AI methods and signal processing.\n",
      "With the on going development of the satellite image time series (SITS), information retrieval in earth monitoring and automatic recognition of changes in time series have become important and challenging tasks. The purpose of the present paper is to determine dictionaries of atoms directly learned from the time series images such that a sparse representation of the images is maintained. The filterbanks learned using gradient descent techniques depend on the frequency band at which the satellite’s sensor captures the scene, i.e., for the visible part of the spectra, the learned filters are close to mean filters over small subregions, whilst, for the infrared part of the spectra, the filters are similar to gradient ones. Furthermore, we aim to express the time changes in SITS in a compact form provided by the newly found sparse representations of the images. The experiments are carried on 4 Landsat images at 30 meters spatial resolution, covering a surface of 59×51 km2 over the city of Bucharest, Romania, and containing information both from the visible and from the infrared domains.\n",
      "Phase unwrapping (PU) is the reconstruction, or estimation, of the absolute phase signal from its observed noisy wrapped samples. Based on the fact that phase locked loop (PLL) output can be considered as a MAP estimate, it has already been proposed to be used for phase unwrapping of two dimensional (2D) interferometric phase. On the other hand, the Gaussian Markov Random Field (GMRF) is well known to be an appropriate statistical model for parameter estimation of images. In this work, GMRF-based second order PLL is proposed for 2D phase unwrapping. As opposed to common PU methods dealing with the wrapped phase obtained by the arg(.) operator, PLL operates on the complex interferogram directly. Considering the neighboring pixels as the past based on the GMRF model, error measures, i.e., the phase detector outputs, from neighboring samples are averaged to estimate the phase for the current pixel. The performance of the proposed approach is evaluated for both simulated fractal Brownian surface, which is considered to be a proper model for 2D absolute phase, and real TerraSAR-X / TanDEM-X interferometric pairs. For both simulated and real data, the phase singularity points (residue points) are detected and the residue maps are extracted. Residues due to phase noise are successfully reduced / removed by means of phase noise filtering, and the results show that the proposed method performs quite well under proper sampling condition, i.e., no aliasing. In case of aliasing, the residues arising from undersampling can be masked and the proposed GMRF-based PLL approach can still be applied.\n",
      "Earth Observation (EO) data has increased significantly over the last decades with satellite and airborne remote sensing sensors collecting and transmitting to Earth receiving stations several terabytes of data a day. This is also the case with TerraSAR-X and TanDEM-X missions. This data acquisition rate is a major challenge to the existing data exploitation, dissemination used approaches for extracting information from these images. And, with plans for more EO systems the challenge is increasingly going to be how to enlarge the usability of the millions of images being stored in archives to a broader group of users. The presentation goal is two folded: it overviews the latest results obtained at DLR for very high resolution SAR image content extraction and presents the latest formalism and solutions to solve the challenge of accessing Big Data repositories. The methods of information retrieval are introduced and discussed. Particularly, the latest concepts of Image Information Mining for enhancing the performance of the PDGS are explained and exemplified. The methods have to be common to all application domains without the weakening effect of specializing it for specific, particular applications fields. The objective is re-formulating the definition of the “relevant information” in relation to the notions of “data content” and “context”. The presentation is introducing: the latest models and algorithms for SAR and InSAR feature extraction, the alternative of using the methods of Algorithmic Information Theory for parameter free SAR data interpretation, kernel methods for data classification, methods for SAR Image Time Series analysis, Visual Data Mining …\n",
      "Mapping of land cover structures using satellite images is a tedious task, which often requires manual corrections that are conducted to enhance accuracy in a cycle of trials. We introduce a Data Mining methodology that tackles the problem of satellite image segmentation. The proposed method aims at adapting the granularity of image segmentation to the cartographic scales.\n",
      "In recent years, our ability to acquire and store large quantities of data has greatly surpassed our ability to access and meaningfully extract information from it. For example, EO archives store many millions of images, but only a small percentage of this data is used in applications. Meanwhile, state of the art methods for data or phenomena understanding of relevance for science or engineering are no longer simply based on theory followed by experiments. Sophisticated computations can complement or substitute experiments enabling, exploration, understanding or control of highly complex systems. In addition, investigations of natural phenomena in more flexible, faster or cheaper way are supported. However, the current methods are limited in several important aspects: - they are not effective for analyzing distributed heterogeneous data sets; - they do not identify cause-effected relationships; - they not enable a close man-machine collaboration; - many of the information systems follow a straight forward strategy not being able to learn; - scientific and engineering communities need much higher computing performance. The article presents an overview of the state of the art in Image Information mining (IIM), Knowledge Discovery and Data Mining (KDD), and related methods for accessing and analysing EO data including a discussion of new theoretical developments in fields like: - theory of information transmission and semantic coding - modelling of human conjecture, and semiotic aspects - information representation for communication and understanding - data and information visualization, grammars of the visual language - multimodal data …\n",
      "Aims The objective of the RO-AHFS registry was to evaluate the epidemiology, clinical presentation, inpatient management, and hospital course in a population hospitalized for acute heart failure syndromes. Methods During a 12-month period, 13 Romanian medical centers enrolled all consecutive patients hospitalized with a primary diagnosis of AHFS. Patients were classified into the following 5 clinical profiles at admission: acute decompensated heart failure, cardiogenic shock, pulmonary edema, right heart failure, and hypertensive heart failure. Statistical significance was assessed using Fisher exact test or the chi(2) test for categorical variables and a 1-way analysis of variance for continuous variables. Independent predictors of in-hospital all-cause mortality (ACM) were identified using a multivariate logistic regression model. Results A total of 3,224 consecutive patients hospitalized with AHFS were enrolled. The cohort had a mean age of 69.2 +/- 11.8 years and 56\\% were men. The mean left ventricular ejection fraction was 37.7\\% +/- 12.5\\%. The percentage of patients treated with evidence-based heart failure therapies increased from admission to discharge, but even at discharge, only 56\\%, 66\\%, and 54\\% of patients were on a beta-blocker, an angiotensin-converting enzyme inhibitors or an angiotensin receptor blocker, and a mineralocorticoid receptor antagonist, respectively. In-hospital ACM was 7.7\\% with substantial variation between sites (4.1\\%-11.0\\%). Increasing age, inotrope therapy, the presence of life-threatening ventricular arrhythmias, and elevated baseline blood urea nitrogen were all found to be independent risk factors for in-hospital ACM, whereas elevated systolic blood pressure and baseline treatment with a beta-blocker had a protective effect. Conclusions The RO-AHFS study found substantial variation both among sites and between Romania and other European countries. National and regional registries have important clinical implications for patient care and the design and conduct of global clinical trials. (Am Heart J 2011;162:142-153.e1.)\n",
      "With the increase of the Synthetic Aperture Radar (SAR) sensor resolution, a more detailed analysis and a finer description of SAR images are needed. Nevertheless, when dealing with urban areas, the high diversity of man-made structures combined with the complexity of the scattering processes makes the analysis and information extraction, from high resolution SAR images over such areas, not easily reachable.In general, an automatic full understanding of the scene requires the capability to identify both relevant and reliable signatures (called also features), depending on variable image acquisition geometry, arbitrary objects poses and configurations. Then, since SAR images are formed, by coherently adding the scattered radiations from the components of the illuminated scene objects, we can make the assumption that, the SAR image is a superposition of different sources. Following this approach, one alternative for a better understanding of the HR SAR scenes, could be a combination between the Principal Components Analysis (PCA) and the Independent Components Analysis (ICA) decompositions. Indeed, while the PCA exploits at most the information stored in the sample covariance matrix. the ICA is a de-mixing process whose goal is to express a set of random variables as linear combinations of statistically independent component variables. Such an approach could be useful for the recognition of urban structures, in HR SAR. images. In this paper, we compare the Principal Components (PCs) to the Independent Components (ICs). Furthermore, we present some preliminary results oil learning and decomposing SAR images, using PCA and ICA.\n",
      "High Resolution (HR) Synthetic Aperture Radar (SAR) Single Look Complex (SLC) observations, mainly of strong scattering scenes or objects show phase patterns.Phase patterns may occur due to the system, behavior or they may be signatures of the imaged objects. Since state of the art stochastic models of SAR SLC data describe mainly the pixel information. Now studies are needed to elaborate better models for the full information content. Thus, new statistical models of HR SAR SLC are proposed., they aim at the characterization of the spatial phase feature of Polarimetric SAR (PolSAR) SLC data, i.e. they describe multi-band, complex valued textures.The definition of texture must be changed because it is not anymore characterizing the optical features but the electromagnetic properties of the illuminated targets.The content of the SAR image is a stochastic process characterized from its own structure and geometry, which differs from the real one of the illuminated scene, and is dominated from strong scatterers.Nevertheless we are going to accept the classical texture definition, inherited from computer vision, in homogeneous areas and, furthermore, we are going to extend it for a characterization of isolated and structured objects The proposed models are in the class of simultaneous Auto-Regressive (sAR) defined on a generalized set of cliques in the pixel vicinity.Models may have different orders, thus capturing different degrees of the data complexity. To cope with the problem of estimation and model order selection Bayesian inference is used. The results are presented on PolSAR. data.\n",
      "The diagnose methods based on medical images are constantly expanding. The need for easily accessed databases deals with more and more problems, due to the fact that the medical information must be retrieved no matter which technical method was used to acquire the image. The queried information must be also achieved for any imaging orientation, for different body regions, considering the analyzed biological system. In our study we have applied a Content-Based Image Retrieval (CBIR) system, implemented for earth observation images, to archive and to administrate a medical database consisting of dental Xray and dermatological images\n",
      "This paper aims to present some information theory measures like entropy and Kullback Leibler divergence to describe the information content in remote sensing imagery. Anomaly detection in Earth Observation images refers to the detection of irregularity in the scene that appears unlikely according to a probabilistic or physical model of the scene. The results of these measures denote how much an image scene corresponds to Image information content. Optical remote sensing images, represented in feature space, are clustered using an unsupervised classification algorithm. Then, we infer the conditional model of the cluster structure in the data and we quantify image content using entropy measure.\n",
      "This paper discusses the formation of corals arranged silver nanocrystals in a KCl matrix starting from Ag- ions ( similar to 10(17) ions/cm(3)) by subsequent thermal annealing at temperatures between 400-700 degrees C and 250 degrees C. In the last case only, by illumination with total radiation of a 100W Xe-lamp, spherical separated silver clusters were obtained. The stepwise annealing processes were followed by the recording of the optical absorption spectra at 20 degrees C. The sizes of silver clusters were determined through transmission electron microscopy. (C) 1999 Published by Elsevier Science B.V. All rights reserved.\n",
      "In this paper, a wavelet-based speckle-removing algorithm is represented and tested on synthetic aperture radar (SAR) images. The SAR image is first transformed using a dyadic wavelet transform. The noise in the wavelet-transformed image is modeled as an additive signal-dependent noise with Gaussian distribution. The distribution of a noise-free image in a wavelet domain is modeled as a generalized Gauss-Markov random field (GGMRF). An unsupervised stochastic model-based approach to image denoising is represented. If the observed area is homogeneous, the parameters of the Gaussian distribution and GGMRFs are estimated from incomplete data using mixtures of wavelet coefficients. An expectation-maximization algorithm is used to estimate the parameters of both noisy and noise-free images. The unknown parameters are estimated using image and noise models that are defined in the wavelet domain for heterogeneous areas. Different inter- and intrascale dependences of wavelet coefficients were used to estimate the unknown parameters, The represented wavelet-based method efficiently removes noise from SAR images.\n",
      "This letter presents synthetic aperture radar (SAR) image despeckling using dyadic wavelet transform. Maximum a posteriori (MAP) estimation is used to despeckle a SAR image in the wavelet domain. A wavelet transformed speckle-free image is approximated with a Gauss–Markov random field, and a Gaussian model is chosen to approximate speckle in the wavelet domain. A speckle-free wavelet coefficient is estimated with Bayesian inference using image and noise model parameters, which produce the highest evidence. The experimental results showed that the despeckling algorithm removes speckle noise in the homogeneous areas better than the state-of-the-art methods, which operate in the wavelet and image domain. The proposed method is very simple and computationally not demanding.\n",
      "This letter presents the despeckling of single-look complex (SLC) synthetic aperture radar (SAR) images using nonquadratic regularization. The objective function consists of an image model, a gradient, and a prior model. The Huber-Markov random field (HMRF) models the prior. A numerical solution is achieved through extensions of half-quadratic regularization methods using complex-valued SAR data. The proposed method using the HMRF prior together with nonquadratic regularization shows the superior results on SLC synthetic and actual SAR images.\n",
      "Speckle hinders information in synthetic aperture radar (SAR) images and makes automatic information extraction very difficult. The Bayesian approach allows us to perform the despeckling of an image while preserving its texture and structures. This model-based approach relies on a prior model of the scene. This paper presents an evaluation of two despeckling and texture extraction model-based methods using the two levels of Bayesian inference. The first method uses a Gauss-Markov random field as prior, and the second is based on an auto-binomial model (ABM). Both methods calculate a maximum a posteriori and determine the best model using an evidence maximization algorithm. Our evaluation approach assesses the quality of the image by means of the despeckling and texture extraction qualities. The proposed objective measures are used to quantify the despeckling performances of these methods …\n",
      "In this letter, we present a novel technique for unsupervised change analysis that leads to a method of ranking the changes that occur between two satellite images acquired at different moments of time. The proposed change analysis is based on binary descriptors and uses the Hamming distance as a similarity metric. In order to render a completely unsupervised solution, the obtained distances are further classified using vector quantization methods (i.e., Lloyd's algorithm for optimal quantization). The ultimate goal in the change analysis chain is to build change intensity maps that provide an overview of the severeness of changes in the area under analysis. In addition, the proposed analysis technique can be easily adapted for change detection by selecting only two levels for quantization. This discriminative method (i.e., between changed/ unchanged zones) is compared with other previously developed techniques that use principal component analysis or Bayes theory as starting points for their analysis. The experiments are carried on Landsat images at a 30-m spatial resolution, covering an area of approximately 59 x 51 km(2) over the surroundings of Bucharest, Romania, and containing multispectral information.\n",
      "Information mining/knowledge discovery and the associated data management are changing the paradigms of user/data interaction by providing simpler and wider access to Earth Observation (EO) data archives. Today, EO data in general and images in particular are retrieved from archives based on such attributes as geographical location, time of acquisition and type of sensor, which provide no insight into the image's actual information content. Experts then interpret the images to extract information using their own personal knowledge, and the service providers and users combine that extracted information with information from other disciplines in order to make or support decisions.In this scenario, the current offering, which is 'data sets' or 'imagery', does not match the customer's real need, which is for 'information'. The information extraction process is too complex, too expensive and too dependent on user conjecture to be applied systematically over an adequate number of scenes. This hinders access to already available or new data (data accumulation rate is increasing), penalises large environmental-monitoring type projects, and might even leave critical phenomena totally undetected. Emerging technologies could now provide a breakthrough, permitting automatic or semi-automatic information mining supported by 'intelligent' learning systems.\n",
      "The last two decades showed an important development of satellite imagery with past and present satellites acquiring enormous volumes of data. Meanwhile, the quality of the acquired images increased permitting the recording of high resolution images (0.6 divided by 2.5 meters/pixel) in multispectral bands. Thus, both the data volume and the information detail increase dramatically.Consequently, new methods and tools to access and interpret Earth Observation (EO) images are needed.The present paper presents a semantic search engine for High Resolution (HR) EO images based on a hierarchical information model of satellite image contents.To face the potentially ambiguos meaning of image structures depending on their contextual understanding, the search engine uses Bayesian inference to learn categories and a Support Vector Machine (SVM) classifier to assign semantics. The categories are grouping and memorising the semantics of image structures, facilitating their recognition in various contexts. Also the generation of categories helps learning from a small training data set (i.e. image examples); thus, the method is useful for the exploitation of very large data volumes. The concept has enhanced inferred power, therefore optimising the Human Machine Communication (HMC), which is enhanced with learning/unlearning functions.\n",
      "In this paper we present a brief survey of the ant based multi-agent exploration algorithms and a performance comparison of these algorithms obtained by analyzing them in a variety of scenarios.\n",
      "Satellite and airborne remote sensing has reached a new level of sophistication, but available interpretation methodologies cannot cope with the huge amounts of acquired data. At the same time, new generations of high resolution SAR sensors have opened the perspective on novel applications related to the understanding of complex observations.At meter resolution, mainly for man-made scenes, the complexity of the scene structures and of imaging phenomenology can be very high. This is reflected in the complexity of the observed images. New methods are needed for their interpretation, both for 2-and 3- dimensional analysis. The present work proposes methods of 2-dimensional information extraction from SAR and InSAR metric resolution observations.\n",
      "The high complexity of remotely sensed images and measurements, provided by the last generation of sensors, demands new techniques for scene understanding and analysis. The paper introduces topics in multisensor and synthetic images fusion. The fractal geometry is applied for unknown information modelling. Integrated techniques in computer graphics and computer vision are used. A new method is introduced for more accurate representation and visualisation of the fractal surfaces. A multiresolution approach is considered for the accurate description of surface radiometry and geometry. The image synthesis is based on the knowledge of surface geometry, on radiation source, and sensor characteristics, and on the radiation scattering process for different cover types. In the final part, results of the developed techniques are applied in satellite imagery understanding.\n",
      "Synthetic Aperture Radars (SAR) are currently one of the most popular systems in the remote sensing domain, being widely utilized in the earth observation field. Their range of applicability extends in both marine and terrestrial regions. In the maritime domain, SAR systems are intensively used for the study of oceanic waves, waves breaking, marine currents, underwater topography, oil stains, for monitoring the glacier's ice flow, and also for ships detection and localization. In the land areas, a class of applications which exploits the coherence propriety of SAR signals is able to retrieve information related to terrain's characteristics, like topography and displacements. In this work, a processing chain for linear deformation rates estimation is presented and implemented on a dataset of 30 SAR images of Buzau and Foc.ani cities regions (Romania). The algorithm is based on identification of targets with stable electromagnetic response, exploiting their temporal coherence to obtain reliable estimates. An iterative phase regression analysis is conducted exclusively in the set of detected stable targets. The main challenge is represented by the estimation of the residual component of the phase, due to its random nature. Main feature of the proposed processing chain consists in the fact that it includes a step for terrain's topography estimation, instead of using an external digital elevation model.\n",
      "This paper presents the image information mining based on a communication channel concept. The feature extraction algorithms encode the image, while an analysis of topic discovery will decode and send its content to the user in the shape of a semantic map. We consider this approach for a real meaning based semantic annotation of very high resolution remote sensing images. The scene content is described using a multi-level hierarchical information representation. Feature hierarchies are discovered considering that higher levels are formed by combining features from lower level. Such a level to level mapping defines our methodology as a deep learning process. The whole analysis can be divided in two major learning steps. The first one regards the Bayesian inference to extract objects and assign basic semantic to the image. The second step models the spatial interactions between the scene objects based on Latent Dirichlet Allocation, performing a high level semantic annotation. We used a WorldView2 image to exemplify the processing results.  2012 EURASIP.\n",
      "In this article the classification of C -band opportunistic bistatic SAR images is assessed. The acquisition setup assumes Sentinel 1 spaceborne transmitter and the ground-based stationary receiver, COBIS located in an urban area. The synchronization/ echoed data spans many monostatic apertures; thus, an increased angular diversity may be exploited. The proposed framework is based on the use of sub-aperture decomposition of the backscatter in order to create the feature vector. Specifically, the goal of such an approach is to identify different scatterer signatures and associate them to specific semantic labels. Because the data dimension increased as a consequence of feature extraction approach, a technique for dimensionality reduction is suitable. The Doppler decomposition features are further embedded in the three-dimensional space in a semi-supervised manner. This operation is performed by UMAP algorithm. Finally, an unsupervised classification is achieved by DBSCAN. The presented results are obtained using manually labeled pixels from the following classes: forest, dam and water.\n",
      "The machine learning algorithms are an essential tool to measure the impact that severe weather has on the environment. Addressing the land cover changes generated by extreme natural phenomena, in this paper, we present the ability of the bag-of-words (BoW) framework for change detection in remote sensing images. Regarding this, we used Sentinel-2 images related to two case studies: the massive bushfires from Kangaroo Island, on January 2020, and 2019 Midwestern U.S floods. Our experimental results demonstrated that the proposed methodology can achieve promising performance for both fires and floods scenarios.\n",
      "Wildfires become more frequent in the context of global warming and severe drought in several parts of the globe. Earth observation data can be used to provide information in such cases, but sometimes, when using optical satellite imagery, the evaluation of the effects produced by ongoing large scale forest fires, can be impeded by smoke. It can reduce the accuracy of the information required by disaster management authorities when allocating resources. To improve both the usability of optical remote sensing data and the quality of the obtained information we compare multiple feature extraction, classification, and visual enhancement methods and algorithms for land cover mapping of smoke covered Sentinel-2 data. The demonstration is performed for the 2019 forest fires in Australia.\n",
      "Sentinel-2 satellites provide systematic global coverage of land surfaces, measuring physical properties within 13 spectral intervals at a temporal resolution of five days. Computer-based data analysis is highly required to extract similarity by processing and to assist human understanding and semantic annotation in support of mapping Earth's surface. This article proposes a data mining concept that uses advanced data visualization and explainable features to enhance relevant aspects in the Sentinel-2 data and enable semantic analysis. There is a two-stage process. At first, spectral, texture, and physical parameters related features are extracted from the data and included in a learning process that models the data content according to statistical similarities. In parallel, the second processing stage maximizes the data impact on the human visual system to help image understanding and interpretation. Target classes\n",
      "We deal with the problem of zero-shot cross-modal image retrieval involving color and sketch images through a novel deep representation learning technique. The problem of a sketch to image retrieval and vice-versa is of practical importance, and a trained model in this respect is expected to generalize beyond the training classes, e.g., the zero-shot learning scenario. Nonetheless, considering the drastic distributions-gap between both the modalities, a feature alignment is necessary to learn a shared feature space where retrieval can efficiently be carried out. Additionally, it should also be guaranteed that the shared space is semantically meaningful to aid in the zero-shot retrieval task. The very few existing techniques for zero-shot sketch-RGB image retrieval extend the deep generative models for learning the embedding space; however, training a typical GAN like model for multi-modal image data may be non-trivial at times. To this end, we propose a multi-stream encoder-decoder model that simultaneously ensures improved mapping between the RGB and sketch image spaces and high discrimination in the shared semantics-driven encoded feature space. Further, it is guaranteed that the class topology of the original semantic space is preserved in the encoded feature space, which subsequently reduces the model bias towards the training classes. Experimental results obtained on the benchmark Sketchy and TU-Berlin datasets establish the efficacy of our model as we outperform the existing state-of-the-art techniques by a considerable margin.\n",
      "The Sentinel-1 mission provides a freely accessible opportunity for urban image interpretation based on synthetic aperture radar (SAR) data with a specific resolution, which is of paramount importance for Earth observation. In parallel, with the rapid development of advanced technologies, especially deep learning, we urgently need a large-scale SAR dataset supporting urban image interpretation. This article presents OpenSARUrban: a Sentinel-1 dataset dedicated to the content-related interpretation of urban SAR images, including a well-defined hierarchical annotation scheme, data collection, well-established procedures for dataset compilation and organization as well as properties, visualizations, and applications of this dataset. Particularly, our OpenSARUrban collection provides 33 358 image patches of urban SAR scenes, covering 21 major cities of China, including 10 different target area categories, 4 kinds \n",
      "Semantic segmentation for synthetic aperture radar (SAR) imagery is a rarely touched area, due to the specific image characteristics of SAR images. In this research, we propose a dataset which consists of three data sources: TerraSAR-X images, Google Earth images and OpenStreetMap data, with the purpose of performing SAR and optical image semantic segmentation. By using fully convolutional networks and deep residual networks with pre-trained weights, we investigate the accuracy and mean IOU values of semantic segmentation for both SAR and optical image patches. The best segmentation accuracy results for SAR and optical data are around 60% and 82%. Moreover, we study SAR models by combining multiple data sources: Google Earth images and OpenStreetMap data.\n",
      "For many years, high resolution SAR (Synthetic Aperture Radar) imaging was limited to airborne instruments. Nowadays, the analysis of spaceborne high resolution SAR images with up to 1 meter spatial resolution has become possible with the advent of German, Italian, and Canadian missions and their subsequent data distribution. For instance, compared to previous missions with much lower resolution, the German TerraSAR-X data allow us to analyze SAR images containing an increased amount of details and information content. As a consequence, a robust detection and recognition of small scale man-made structures representing buildings, roads, harbors, bridges, etc has become a new challenging task. An important property of SAR data is the presence of speckle phenomena which, in most cases, precludes an automated interpretation of SAR images. Therefore, we use a Bayesian approach relying on …\n",
      "Geographical maps are usually obtained from the processing of many various data. In the case of the European project CORINE Land Cover (CLC), maps are generated using satellite images and many ancillary data such as topographics maps, aerial photographs and ground thruth. The diversity of the used data conducts to seek how much information does the single satellite image bring to the generation of the map. For this purpose, the Maximum a Posteriori (MAP) supervised clasification method on multispectral SPOT images with 20m resolution was investigated in this paper. Using spectral and textural features into a per-pixel classification, and then taking into account the relationships between a pixel and its neighbourhood, it results that the required amount of information depends on the description of each CLC class.\n",
      "The article proposes a methodology to perform azimuth focusing of spaceborne transmitter-stationary receiver bistatic synthetic aperture radar data across multiple along-track apertures to increase azimuth resolution. The procedure uses as input several azimuth apertures (continuous groups of range compressed pulses) from one or more satellite bursts and comprises the following stages: antenna pattern compensation, slow time resampling, reconstruction of missing azimuth samples between neighboring sets of pulses using an autoregressive (AR) model and back-projection focusing of the resulting multiaperture range image. A novel, highly efficient method is proposed to estimate the optimal order for the AR model. It differs from the traditional approach that uses the Akaike Information Criterion to directly estimate the order because the proposed method estimates the order indirectly by detecting the number of\n",
      "This paper discusses the formation of corals arranged silver nanocrystals in a KCl matrix starting from Ag- ions ( similar to 10(17) ions/cm(3)) by subsequent thermal annealing at temperatures between 400-700 degrees C and 250 degrees C. In the last case only, by illumination with total radiation of a 100W Xe-lamp, spherical separated silver clusters were obtained. The stepwise annealing processes were followed by the recording of the optical absorption spectra at 20 degrees C. The sizes of silver clusters were determined through transmission electron microscopy. (C) 1999 Published by Elsevier Science B.V. All rights reserved.\n",
      "The recent multiplication of open access initiatives to Big Data from Space is giving momentum to the field by widening substantially the spectrum of scientific communities and users, as well as awareness among the public, while offering new benefits at all levels from individual citizens to the whole society. Following a detailed and rigorous review process, 14 articles have been selected out of 48 submissions for this special issue. These are briefly summarized.\n",
      "Domain-agnostic data retrieval has lately become essential amidst the availability of large-scale data from different types of sensors. However, the unavailability of a sufficient amount of samples of certain classes during training curtails the utility of existing retrieval models in remote sensing (RS) applications. Here, we propose a novel framework for zero-shot intermodal data retrieval of RS data. Thereupon, we design an encoderdecoder structure that ensures enhanced overlapping among the two data domains utilizing cross-triplet and cross-projection loss functions. Furthermore, we propose a sketch-based representation of the RS database Earth on Canvas with diverse classes. We perform a thorough benchmarking of this data set and demonstrate that the proposed framework outperforms state-of-the-art methods for zero-shot sketch-based retrieval framework for RS data.\n",
      "Copernicus is the European programme for monitoring the Earth. It consists of a set of systems that collect data from satellites and in-situ sensors, process this data and provide users with reliable and up-to-date information on a range of environmental and security issues. The data and information processed and disseminated puts Copernicus at the forefront of the big data paradigm, giving rise to all relevant challenges, the so-called 5 Vs: volume, velocity, variety, veracity and value. In this short paper, we discuss the challenges of extracting information and knowledge from huge archives of Copernicus data. We propose to achieve this by scale-out distributed deep learning techniques that run on very big clusters offering virtual machines and GPUs. We also discuss the challenges of achieving scalability in the management of the extreme volumes of information and knowledge extracted from Copernicus data. The envisioned scientific and technical work will be carried out in the context of the H2020 project ExtremeEarth which starts in January 2019.\n",
      "Very High Spatial Resolution (VHSR) large-scale SAR image databases are still an unresolved issue in the Remote Sensing field. In this work, we propose such a dataset and use it to explore patch-based classification in urban and periurban areas, considering 7 distinct semantic classes. In this context, we investigate the accuracy of large CNN classification models and pre-trained networks for SAR imaging systems. Furthermore, we propose a Generative Adversarial Network (GAN) for SAR image generation and test, whether the synthetic data can actually improve classification accuracy.\n",
      "The article aims at presenting the most recent developments and trends in information extraction from Synthetic Aperture Radar SAR data.\n",
      "This paper addresses the problem of multitemporal analysis of an available TerraSAR-X data time series covering the Sendai region in order to assess flood extent and damages caused by Tohuku-oki tsunami. Over the last decade the use of Earth Observation satellites to support disaster and emergency relief has considerably grown. In order to fully exploit highresolution satellite images, a method based on patches (each image is divided into non-overlapping tiles) is proposed to extract relevant contextual information. The local features of each patch act as a compact content descriptor. Further on, considering the available descriptors, the next step is to cluster the data in order to find similar semantic classes. The SVM classifier implements the concept of query by example using image content. The results include well-defined semantic classes, derived through semiautomatic methods thus developing an effective approach to the multitemporal analysis.\n",
      "This paper discusses a feature extraction procedure based on the estimation of spectral components of the complex SAR image for scene classification. The estimation is performed in an iterative manner, using the periodogram of SAR image patches of fixed size. A Ränyi Entropy constraint is introduced in the process of selection of best spectral components for content characterization. Results are presented on a database consisting of 1650 image patches covering urban areas. Results show that by selecting the spectral components that maximize the Ränyi entropy of the spectrum with α=3 can improve the accuracy of the classification.\n",
      "Sentinel 2 (S2) satellite provides a systematic global coverage of land surfaces, measuring physical properties within 13 spectral intervals at a temporal resolution of 5 days. Computer-based data analysis is highly required to extract similarity by processing and assist human understanding and semantic annotation in support of Earth surface mapping. This paper proposes an exploratory search methodology for S2 data underpinning both visual and latent characteristics by means of data visualization and content representation. For optimized results, the authors focus on a detailed assessment of top relevant state-of-the-art algorithms for features extraction and classification to determine which one could handle best the characteristics of S2 data.\n",
      "In this paper, we introduce a compressive sensingbased approach for increasing bistatic synthetic aperture radar imaging quality in the context of multi-aperture acquisition. The analyzed data is recorded over an opportunistic bistatic setup including a stationary ground based receiver (COBIS) and Sentinel 1 C-band transmitter. Since the terrain observation by progressive scans mode is operated, the receiver is able to record synchronization pulses and echoed signals from the scene during many apertures. Hence, it is possible to improve the azimuth resolution by exploiting the multi-aperture data. Obviously, the recorded data is not contiguous and a naive integration of the chopped azimuth phase history would generate undesired grating lobes. The proposed processing scheme exploits the natural sparsity characterizing the illuminated scene. Therefore, a matching pursuit compressive sensing algorithm is employed for filling the gaps occurring in Doppler spectrum. The sparsifying basis/dictionary is constructed using the synthetic generated azimuth chirp. The obtained results show a significant improvement of the azimuth resolution along with dramatic attenuation of the side-lobes.\n",
      "In this article, we propose a promising approach for the application-oriented content classification of spaceborne radar imagery that presents an interesting alternative to popular current machine learning algorithms. In the following, we consider the problem of unsupervised feature-free satellite image classification with already known classes as an explainable data mining problem for regions with no prior information. Three important issues are addressed here: explainability, feature independence, and unsupervision. There is an increasing demand toward explainable machine learning models as they strive to meet the right to explanation. The importance of feature-free classification stems from the problem that different classification outcomes are obtained from using different features and the complexity of computing sophisticated image primitive features. Developing unsupervised discovery techniques helps \n",
      "We propose a novel framework for cross-modal zero-shot learning (ZSL) in the context of sketch-based image retrieval (SBIR). Conventionally, the SBIR schema mainly considers simultaneous mappings among the two image views and the semantic side information. Therefore, it is desirable to consider fine-grained classes mainly in the sketch domain using highly discriminative and semantically rich feature space. However, the existing deep generative modeling based SBIR approaches majorly focus on bridging the gaps between the seen and unseen classes by generating pseudo-unseen-class samples. Besides, violating the ZSL protocol by not utilizing any unseen-class information during training, such techniques do not pay explicit attention to modeling the discriminative nature of the shared space. Also, we note that learning a unified feature space for both the multi-view visual data is a tedious task \n",
      "Deutsches Zentrum fur Luft- und Raumfahrt eV, eLib - DLR electronic library.\n",
      "Danisor, Cosmin und Popescu, Anca und Datcu, Mihai (2017) Persistent Scatterers Interferometry for Estimation of Linear Deformation Rates. Case Study of Buzau and Focsani Cities, Romania. Fringe 2017, 5.-9. Juni 2017, Helsinki, Finand Dieses Archiv kann nicht den gesamten Text zur Verfugung stellen Copyright  2008-2017 Deutsches Zentrum fur Luft- und Raumfahrt (DLR). Alle Rechte vorbehalten.\n",
      "The two Sentinel-2 satellites provide, since March 2017, high-resolution worldwide images every five days, freely distributed, generating terabytes of high-dimensional data. An intuitive manner to summarize the main characteristics of the data and gather knowledge is visual exploratory analysis, which is often based on dimensionality reduction methods to represent high-dimensional data. From previous research and the state-of-the-art literature, turned out that t-distributed Stochastic Neighbour Embedding is one of the most appropriate technique to reduce the dimensionality of a dataset, but it requires very high computational power. To overcome this inconvenience, we proposed two hybrid DR algorithms, which combine the DR with the nearest neighbour technique or random forest regression. The main conclusion is that our approaches reduce computational power without compromising the representation quality.\n",
      "Discovering potential concepts and events by analyzing Earth Observation (EO) data may be supported by fusing other distributed data sources such as non-EO data, for instance, in-situ citizen observations from social media. The retrieval of relevant information based on a target query or event is critical for operational purposes, for example, to monitor flood events in urban areas, and crop monitoring for food security scenarios. To that end, we propose an early-fusion (low-level features) and late-fusion (high-level concepts) mechanism that combines the results of two EU-funded projects for information retrieval in Sentinel imagery and social media data sources. In the early fusion part, the model is based on active learning that effectively merges Sentinel-1 and Sentinel-2 bands, and assists users to extract patterns. On the other hand, the late fusion mechanism exploits the context of other geo-referenced \n",
      "Deep learning based patch-wise Synthetic Aperture Radar (SAR) image classification usually requires a large number of labeled data for training. Aiming at understanding SAR images with very limited annotation and taking full advantage of complex-valued SAR data, this paper proposes a general and practical framework for quad-, dual-, and single-polarized SAR data. In this framework, two important elements are taken into consideration: image representation and physical scattering properties. Firstly, a convolutional neural network is applied for SAR image representation. Based on time-frequency analysis and polarimetric decomposition, the scattering labels are extracted from complex SAR data with unsupervised deep learning. Then, a bag of scattering topics for a patch is obtained via topic modeling. By assuming that the generated scattering topics can be regarded as the abstract attributes of SAR images \n",
      "This paper presents a time-domain synthetic aperture radar (SAR) processor designed for Sentinel-l Terrain Observation by Progressive Scans (TOPS) monostatic data. The processor focuses Interferometric Wide (IW) swath and Extra Wide (EW) swath data on a selected region-of-interest (ROI) and consists of the following main stages: decoding of Level-0 data, selection of the relevant burst and pulses for the targeted ROI, range compression, azimuth frequency unfolding and resampling, and image focusing by a fast subaperture-based version of the back-projection algorithm. The performances of the developed processor are assessed on datasets acquired in IW and EW imaging modes. Such a time-domain processor can be regarded as a first step towards a geometry/frequency-agnostic SAR processing kernel for future monostatic/multi static spaceborne SAR missions.\n",
      "In this paper is presented a new methodology for synthetic aperture radar images focusing called bidimensional mixed compressive sensing back-projection (CS-BP-2D). Spatial compressibility of the radar images is exploited by constructing the sparsity basis using the backprojection focusing framework and solving the reconstruction problem by means of the orthogonal matching pursuit algorithm (OMP).\n",
      "Due to the complexity and difficult comprehension of remote sensing data, ubiquitous methods for content exploitation are difficult to identify. The main limitation is ascribed to the fact that different perceptions, individual human experts and non-identical remote sensors fabricate a total heterogeneous context. In order to overpass these breaches, an interactive learning model is demanded, where different experts, participating into a validation process, expose and verify shared dictionaries based on users' understanding. We propose a federated system for collaborative labeling of remote sensing datasets that transform blockchain storage into blockchain knowledge. This writing wants to provide insights into a decentralized methodology, capable of building a publicly available, large-scale benchmark data for image classification and hosting a permanently updated machine learning (ML) model.\n",
      "The Markov Random Field (MRF) is used for extracting feature information in images and is formed as an Ising-like model. The quantum annealing is a novel method to optimize objective functions, and objective functions have to be expressed in terms of the Ising model. Hence, the MRF can be embedded into the the quantum annealing method, and feature information of remote sensing images then can be extracted using a quantum annealing computer. Extracted information or features are used to segment an image.\n",
      "In this paper, we present our image search system for remote sensing imagery leveraging the capabilities of Elasticsearch, a well-known full-text search engine. We use bag of visual words and bag of visual topics model to represent the earth observation images in a text- equivalent format. The image files are stored in Elasticsearch in their text-equivalent format, making it feasible to apply some sophisticated text-based search functionalities of Elasticsearch on the data. This gives great flexibility to the search clauses allowing the user to match chosen fragments of images. We also implement visual topic search which enables search by higher level semantics. The proposed methods are simple and fast as they do not require any complex image feature computation.\n",
      "This paper describes the work done with the Data Mining components of the H2020 CANDELA project, mainly the Data Model component on the CANDELA platform as its back end, and the user interaction component of the local user machine as front end. The Data Mining tool is basically composed of four main submodules: the Data Model Generation for Data Mining (DMG-DM), the database management system (DBMS) sub-module that has already been dockerized and deployed on the CANDELA platform, the image search and semantic annotation (KDD) sub-module and the multi-knowledge and query (QE) sub-module. They all require user inputs, and connect directly to the database on the platform; they can be started as a normal GUI (Graphical User Interface) tool.\n",
      "The content of earth observation images can be analyzed by knowledge-based image information mining.\n",
      "Deep Learning offers numerous techniques for data analysis and feature extraction, useful in Earth Observation. However, a persistent problem is the small number of labeled datasets and the variety of the data, due to the different instruments used for collecting scenes. For example, to what extent can a deep neural network handle image patches of different resolutions, and to what extent do we need very high-resolution images? In this paper, we study the impact of the resolution in SAR images on the capability of a convolutional neural network to classify urban scenes. The goal is to find urban classes that are recognizable in images with different resolution. We start by training a convolutional neural network on OpenSARUrban [14], a dataset with patches originating from high-resolution scenes (20 meters), and then we lower the resolution of the patches by several factors and train the same network on them\n",
      "In this paper, we present three methods that reduce the computational time of training Deep Neural Networks with multispectral images, optimize the resource occupation of the dataset, and obtain high performance for reduced datasets. In the first two methods, we reduce the dimension of the input data with either histograms of pixel intensity or Bag-of-Words. Then we train a Convolutional Neural Network with either histograms or Bag-of-Words and we achieve an accelerated training. Moreover, storing the image patches from the dataset in the form of histograms or Bag-of-Words reduced the memory storage significantly. In the last method, we subsample the training dataset randomly to 50%, 20% and 10% of the original dataset, thus training a Convolutional Neural Network on a smaller number of samples (in the form of histograms or Bag-of-Words), and the classification performance is almost unaffected. This is an important achievement, as there are few labelled datasets for Earth Observation and the number of images in these datasets is small. Our results show that the training time is reduced by a maximum of 387 times and the datasets with histograms or Bag-of-Words occupy 633 times less space.\n",
      "Faur, Daniela und Gavat, Inge und Datcu, Mihai (2008) Salient Image Segmentation based on Rate-Distortion Measure. ESA-EUSC 2008: Image Information Mining, 2008-03-04 - 2008-03-06, Frascati, Italy Dieses Archiv kann nicht den gesamten Text zur Verfugung stellen Copyright  2008-2017 Deutsches Zentrum fur Luft- und Raumfahrt (DLR). Alle Rechte vorbehalten.\n",
      "Knowledge-based image information mining has important applications in the field of security and risk assessments.\n",
      "Faur, Daniela und Datcu, Mihai und Gavat, Inge (2006) Algorithms evaluation for remote sensing image segmentation. In: Proceedings of the Fifth International PhD Students' Workshop Control and Information Technology. IWCIT 2006, 2006-09-21 - 2006-09-22, Gliwice, Poland Dieses Archiv kann nicht den gesamten Text zur Verfugung stellen Different algorithms exist for the segmentation of remote sensing images. We compare their performance Copyright  2008-2017 Deutsches Zentrum fur Luft- und Raumfahrt (DLR). Alle Rechte vorbehalten.\n",
      "This paper presents a detection method for stable scatterers (SS) used for single-pass resolution enhancement in spaceborne transmitter (TX)  ground based receiver (RX) bistatic Synthetic Aperture Radar (SAR). Resolution is improved by coherently focusing multiple sub-apertures, each sub-aperture being represented by the data received from a different sub-swath. This requires that the transmitting satellite operate in Terrain Observation with Progressive Scans SAR (TOPSAR) mode. Detecting which zones in the image are common and coherent among the sub-apertures is paramount to image quality and Signal to Noise Ratio (SNR).\n",
      "This article presents a new scheme called 2-D mixed compressive sensing back-projection (CS-BP-2D), for synthetic aperture radar (SAR) imaging on a geocoded grid, in a single measurement vector frame. The back-projection linear operator is derived in matrix form and a patched-based approach is proposed for reducing the dimensions of the dictionary. Spatial compressibility of the radar image is exploited by constructing the sparsity basis using the back-projection focusing framework and fast solving the reconstruction problem through the orthogonal matching pursuit algorithm. An artifact reduction filter inspired by the synthetic point spread function is used in postprocessing. The results are validated for simulated and real-world SAR data. Sentinel-1 C-band raw data in both monostatic and space-borne transmitter/stationary receiver bistatic configurations are tested. We show that CS-BP-2D can focus both monostatic and bistatic SAR images, using fewer measurements than the classical approach, while preserving the amplitude, the phase, and the position of the targets. Furthermore, the SAR image quality is enhanced and also the storage burden is reduced by storing only the recovered complex-valued points and their corresponding locations.\n",
      "This article introduces a compressive sensing (CS)-based approach for increasing bistatic synthetic aperture radar (SAR) imaging quality in the context of a multiaperture acquisition. The analyzed data were recorded over an opportunistic bistatic setup including a stationary ground-based-receiver opportunistic C-band bistatic SAR differential interferometry (COBIS) and Sentinel-1 C-band transmitter. Since the terrain observation by progressive scans (TOPS) mode is operated, the receiver can record synchronization pulses and echoed signals from the scene during many apertures. Hence, it is possible to improve the azimuth resolution by exploiting the multiaperture data. The recorded data are not contiguous and a naive integration of the chopped azimuth phase history would generate undesired grating lobes. The proposed processing scheme exploits the natural sparsity characterizing the illuminated scene. For azimuth profiles recovery greedy, convex, and nonconvex CS solvers are analyzed. The sparsifying basis/dictionary is constructed using the synthetically generated azimuth chirp derived considering Sentinel-1 orbital parameters and COBIS position. The chirped-based CS performance is further put in contrast with a Fourier-based CS method and an autoregressive model for signal reconstruction in terms of scene extent limitations and phase restoration efficiency. Furthermore, the analysis of different receiver-looking scenarios conducted to the insertion in the processing chain of a direct and an inverse Keystone transform for range cell migration (RCM) correction to cope with squinted geometries. We provide an extensive set of simulated and real-world results that prove the proposed workflow is efficient both in improving the azimuth resolution and in mitigating the sidelobes.\n",
      "The recognition and classification of urban structures from SAR observations is a particularly complex task. In this article we present a new concept, aiming at the accurate and detailed classification of the city scenes observed with metric resolution SAR sensors.SAR images of build-up areas at resolution of 2-3 meters are characterized by strong patterns induced by the geometry of buildings and the phenomenology of scattering of the radar signals. Thus, resulting in high complexity images.The accuracy of image interpretation relies on the descriptive power of the low level image information extraction. The article presents a method based on the Bayesian concepts. A hierachical 3 layers model is used for the SAR observations. The first layer describes the speckle effect as a Gamma distribution. the second, the cross-section, is modeled as Gibbs Random Field (GRF), the third layer the parameters of the Gibbs random field is considered a Jeffrey's prior. The GRF describes the cross-section structures induced by the geometry of the buildings. The model is non-stationary, its parameters adapt locally to the image structures.\n",
      "The reconstruction of urban structures from InSAR (interferometric synthetic aperture. radar) observations is a complex task. Until now it has been typically approached using the methods of radargrammetry and SAR interferometry, in a direct extension of what had been done in the past for the reconstruction of natural surfaces from, generally. much lower resolution data.We present a new concept aiming at the accurate and detailed reconstruction of the observed city scenes from metric SAR observations. We use a model-based approach for the synergetic analysis of the different sources of information in InSAR data. We define a hierarchical model of the InSAR observation that is both deterministic and stochastic. While the deterministic section describes the SAR imaging geometry and its effects and expresses the different scene structures, the stochastic part encapsulates instead prior knowledge about the signal and defines its attributes while also describing incertitude over the parameters of the geometrical model.Bayesian inference is used to couple the different levels of the model, and to further define parameter estimation algorithms.\n",
      "From classical image processing we know that correlations can be computed either in the spatial domain or in the Fourier transform domain. The advent of efficient wavelet transform techniques prompted us to investigate the chances for such computations using wavelet transformed data. We selected complex chirp signals as a typical example of signal correlation in the field of SAR data processing. Basic figures of merit are the fall-off of the correlation peak, the magnitude of secondary maxima, and the shift invariance of the selected correlation technique. Further, the correlation performance of noisy and degraded signals is of prime importance. In comparison with conventional chirp correlations in the Fourier de main, a straightforward signal correlation of wavelet transformed data leads to typical shift-variance and wavelet se lection problems. The number of decomposition levels has to be optimized, too. All these problems can be tackled by re-arranging the wavelet transform coefficients and by using a non-decimating wavelet transform. On the other hand, we have to constrain the magnitude of secondary correlation maxima. The performance of various alternatives will be demonstrated by comparing algorithmic approaches, their implementation, and their figures of merit.\n",
      "The maximum entropy (ME) and minimum cross-entropy (MCE) formalisms provide a coherent tool for incorporating new information (in terms of constraints) into initial models and also an alternative tool for solving inverse problems. Our paper discusses some particularities of the application of ME and MCE formalisms to image processing problems; given the ME-MCE framework, one has to identify the proper constraint system which applies for the concrete problem. The relation between Bayesian maximum aposteriori probability (MAP) methods and ME-MCE methods are also discussed. Examples are given in the field of the restoration of synthetic aperture radar images, whose resolution is affected by the well- known speckle noise, a side effect of the coherency of the image formation system.\n",
      "Conventional ground segments for spaceborne SAR instruments collect raw SAR data and convert them into standard image and interferometry products. Typical examples are the routine generation of complex, detected, or geocoded image products. These data are archived and accessible via user interfaces linked to browsing tools that use catalogues with quicklooks, metadata, etc. On the other hand, during the last years, considerable effort has been spent in the design of data mining systems and specific image information mining techniques that allow the retrieval of images from large archives based on their content. We will describe how the PIMS ground segment architecture combines product generation, archiving, and cataloguing with image information mining functions permitting automated feature extraction as well as interactive data analyses by users of various disciplines.\n",
      "We present results of large-scale experimentation with the enhanced model-based despeckling (EMBD) filter aiming at its validation from a pragmatical point of view. Furthermore, we point out criteria for the choice of a prior model for synthetic aperture radar (SAR) images. These criteria rely oil ail evidence maximization step - part of the EMBD algorithm itself - and on the verification of the obtained speckle statistics against the assumptions made in the filtering.\n",
      "For many applications in data mining and knowledge discovery in databases, clustering methods are used for data reduction. If the amount of data increases like in image information mining, where one has to process GBytes of data, for instance, many of the existing clustering algorithms cannot be applied because of a high computational complexity. To overcome this disadvantage, we developed an efficient clustering algorithm called dyadic k-means. The algorithm is a modified and enhanced version of the traditional k-means. Whereas k-means has a computational complexity of O(nk) with n samples and k clusters, dyadic k-means has one of O(n log k). Our algorithm is particularly efficient for the grouping of very large data sets with a high number of clusters.In this article we will present statistically-based methods for the objective evaluation of clusters obtained by dyadic k-means. The main focus is on how well the clusters describe the data point distribution in a multidimensional feature space and how much information can be obtained from the clusters. Both the filling of the feature space with samples and the characterization of this configuration with dyadic k-means produced clusters will be considered. We will use the well-established scatter matrices to measure the compactness and separability of clustered groups in the feature space. The probability of error, which is another indicator for the characterization of samples in the feature space by clusters, will be calculated for each point, too. This probability delivers the relationship of each point to its cluster and can therefore be considered as a measurement of cluster reliability. We will test the evaluation methods both on a synthetic and a real world data set.\n",
      "High resolution imaging is a persistent goal for many users of optical and microwave remote sensing data as it allows better detection, discrimination and classification of the objects contained within a recorded scene. High resolution can be obtained either by instrument design, by data acquisition methods, or by dedicated post-processing and interpretation of the acquired data. The interpretation can be based on a visual inspection by a human photointerpreter, or consist of automated model-based scene understanding.We will compare various methods used for optical and SAR instruments and their processing chains. Primary criteria for high resolution imaging as encountered in remote sensing of solid surfaces are ground resolution per pixel, motion compensation during data acquisition, attainable contrast and signal-to-noise ratio, removal of instrumental and non-target effects, geometrical correction, use of multi-channel and neighbourhood target property data like spectral and textural signatures, and the potential for data fusion from multiple sources.The inclusion of model knowledge obtained from collections of pre-recorded physical target data leads to a comparison of the acquired data with representative models. Similarities and deviations revealed during the comparison allow a detailed high resolution interpretation of the image data and lead to a full image understanding.\n",
      "During the last years, wavelets have become very popular in the fields of signal processing and pattern recognition and have led to a large number of publications. In the discipline of remote sensing several applications of wavelets have emerged, too. Among them are such diverse topics as image data compression, image enhancement, feature extraction, and detailed data analysis.On the other hand, the processing of remote sensing image data-both for optical and radar data-follows a well-known systematic sequence of correction and data management steps supplemented by dedicated image enhancement and data analysis activities. In the following we will demonstrate where wavelets and wavelet transformed data can be used advantageously within the standard processing chain usually applied to remote sensing image data.Summarizing potential wavelet applications for remote sensing image data, we conclude that wavelets offer a variety of new perspectives especially for image coding, analysis, classification, archiving, and enhancement. However, applications requiring geometrical corrections and separate dedicated representation bases will probably remain a stronghold of classical image domain processing techniques.\n",
      "The present article focuses on the development of interactive exploratory tools for visually mining the image content in large remote sensing archives. Two aspects are treated: the iconic visualization of the global information in the archive and the progressive visualization of the image details. The proposed methods are integrated in the Image Information Mining ((IM)-M-2) system. The images and image structure in the (IM)-M-2 system are indexed based on a probabilistic approach. The resulting links are managed by a relational data base. Both the intrinsic complexity of the observed images and the diversity of user requests result in a great number of associations in the data base. Thus new tools have been designed to visualize, in iconic representation the relationships created during a query or information mining operation: the visualization of the query results positioned on the geographical map, quick-looks gallery, visualization of the measure of goodness of the query, visualization of the image space for statistical evaluation purposes. Additionally the I2M system is enhanced with progressive detail visualization in order to allow better access for operator inspection. (IM)-M-2 is a three-tier Java architecture and is optimized for the Internet.\n",
      "Applications like real time on-board processed Synthetic Aperture Radar (SAR) image transmission for ships, ice or oil slick monitoring and detection, and also ground segment applications require a new philosophy-for data representation and compression. This also includes high speed & high resolution data dissemination as for example monitoring of floodings, where the transmission in near real time of high resolution data via Internet could be a major improvement on mission level. Conventional SAR quicklook images do not satisfy the spatial resolution requirements for such applications. As an alternative, we propose a new visual epitome based on a wavelet feature coding technique for SAR images in order to preserve the spatial resolution and to achieve high compression factors. Combining data compression, despeckling, and image restoration allows us to reach compression rates of up to about 850, thus permitting easy storage in centralized archives as well as rapid dissemination over standard networks. After decompression at the user site, the quality of the quicklook images permits the visual inspection and analysis of all spatially important image details. This becomes apparent when comparing conventional multilook quicklook images with wavelet feature coded decompressed counterparts. Typical examples will be demonstrated. Due to the extremely high compression rates, the radiometric quality of the quicklook images is degraded. However, the use of wavelet multiresolution representation of the images bears the additional potential of progressive transmission that is stopped interactively when an acceptable level of radiometric fidelity is reached. The decompression effort is small, robust algorithms are available and further compression optimizations are being investigated.\n",
      "While the analysis and understanding of multispectral (i.e., optical) remote sensing images have made considerable progress during the last decades, the automated analysis of synthetic aperture radar (SAR) satellite images still needs some innovative techniques to support nonexpert users in the handling and interpretation of these big and complex data. In this article, we present a survey of existing multispectral and SAR land cover image datasets. To this end, we demonstrate how an advanced SAR image analysis system can be designed, implemented, and verified that is capable of generating semantically annotated classification results (e.g. , maps) as well as local and regional statistical analytics such as graphical charts. The initial classification is made based on Gabor features and followed by class assignments (labeling). This is followed by inclusion. This can be accomplished by the inclusion of expert \n",
      "Hyperspectral images (HSIs) showing objects belonging to several distinct target classes are characterized by dozens of spectral bands being available. However, some of these spectral bands are redundant and/or noisy, and hence, selecting highly informative and trustworthy bands for each class is a vital step for classification and for saving internal storage space; then the selected bands are termed a highly informative spectral band subset. We use a mutual information (MI)-based method to select the spectral band subset of a given class and two additional binary quantum classifiers, namely a quantum boost (Qboost) and a quantum boost plus (Qboost-Plus) classifier, to classify a two-label dataset characterized by the selected band subset. We pose both our MI-based band subset selection problem and the binary quantum classifiers as a quadratic unconstrained binary optimization (QUBO) problem. Such a \n",
      "electronic library - Land Cover Classification using Sentinel-2 Data elib DLR-Header DLR-Logo -> http://www.dlr.de DLR Portal Home | Impressum | Datenschutz | Kontakt | English Schriftgroße: [-] Text [+] Erweiterte Suche Versenden Drucken Land Cover Classification using Sentinel-2 Data Georgescu, Florin-Andrei und Vaduva, Corina und Datcu, Mihai (2017) Land Cover Classification using Sentinel-2 Data. ESA World Cover 2017, 14.-16. Marz 2017, Frascati, Italien. Dieses Archiv kann nicht den Volltext zur Verfugung stellen. Offizielle URL: http://worldcover2017.esa.int/ elib-URL des Eintrags: https://elib.dlr.de/118539/ Dokumentart: Konferenzbeitrag (Poster) Titel: Land Cover Classification using Sentinel-2 Data Autoren: Autoren Institution oder E-Mail-Adresse Autoren-ORCID-iD Georgescu, Florin-Andrei Military Technical Academy, Romania NICHT SPEZIFIZIERT Vaduva, Corina Politehnica University of \n",
      "A basic image content 'vocabulary' is automatically generated using spectral and textural information and a hybrid method is used to understand and describe semantic rules that link different levels of ontology information. Concerning applications of object recognition, our method describes semantic connections between similar objects in an image, with respect to user-defined similarity measures related to size, shape, angle and distance between objects in the scene (e.g., buildings).\n",
      "In synthetic aperture radar (SAR) image classification applications, there are three categories of data, including training and benchmark data with fixed classes, as well as actual data in practical applications. A real problem comes that there exist unknown classes not included in training and benchmark data, which is defined as the open set condition. However, little work on recognizing unknown classes and analyzing the separability of SAR datasets has been developed. Motivated by this observation, this article demonstrates the difficulty of practical classification and analyzes SAR dataset separability in open set conditions. In this article, the SAR separability analyzer (SAR-SA) is proposed to model each known class as a multivariate Gaussian distribution. SAR-SA can classify the known classes and recognize the samples locating in each known distribution with low probabilities as unknown. Besides, SAR datasetwise separability index (DSI) and classwise separability index (CSI) are defined to quantify the separability in open set conditions at the dataset level and class level. DSI and CSI are effective indicators of the difficulty of SAR classification datasets. Extensive experimental results demonstrate that the DSI in open set conditions is nearly half of that in supervised conditions. Dataset with low DSI is hard to realize accurate classification in open set conditions. At the class level, even though the SAR image classes are semantically different from each other, there exists more or less overlap between the distributions of supervised known classes and unknown classes. Classes with low CSI are harder to be correctly classified and recognized.\n",
      "This report summarizes the results of Learning to Understand Aerial Images (LUAI) 2021 challenge held on ICCV'2021, which focuses on object detection and semantic segmentation in aerial images. Using DOTA-v2.0 [7] and GID-15 [35] datasets, this challenge proposes three tasks for oriented object detection, horizontal object detection, and semantic segmentation of common categories in aerial images. This challenge received a total of 146 registrations on the three tasks. Through the challenge, we hope to draw attention from a wide range of communities and call for more efforts on the problems of learning to understand aerial images.\n",
      "Quantum Annealer (QA) is well-suited for a certain class of optimization problems which can be expressed as a Quadratic Unconstrained Binary Optimization (QUBO) problem. A QUBO problem belongs to the family of Integer Programming problems which are called the NP-hard optimization problems. Feasible solutions of such problems can be found by using classical optimization techniques. However, studies claim that QA can find a feasible global solution that is faster than a classical annealer for QUBO problems. Hence, it appears promising to program and use the QA-to-QUBO approach for Earth Observation. In search of the QUBO problem in the domain of Earth Observation, we examined several Inteferometric Synthetic Aperture Radar (InSAR) applications and identified a residue connection problem in the phase unwrapping procedure. In particular, we consider the residue connection problem with multiples of 2p as a QUBO problem. For this practical problem, we studied how to formulate this QUBO problem, and we examined the challenges to program the D-Wave quantum annealer, in particular, embedding the QUBO problem into our QA architecture with a so-called Pegasus topology, and the annealing parameter settings in the D-Wave quantum annealer. We then analysed the parameter effects on finding the global minimum of the residue connection problem. From these results, we derived and enhanced our insight for programming future quantum annealers; for instance, choosing real-world problems in Earth Observation, conceiving the embedding procedure, and the tuning of the annealing parameters.\n",
      "<jats:p>&amp;lt;p&amp;gt;During the last years, much progress has been reached with machine learning algorithms. Among the typical application fields of machine learning are many technical and commercial applications as well as Earth science analyses, where most often indirect and distorted detector data have to be converted to well-calibrated scientific data that are a prerequisite for a correct understanding of the desired physical quantities and their relationships.&amp;lt;/p&amp;gt;&amp;lt;p&amp;gt;However, the provision of sufficient calibrated data is not enough for the testing, training, and routine processing of most machine learning applications. In principle, one also needs a clear strategy for the selection of necessary and useful training data and an easily understandable quality control of the finally desired parameters.&amp;lt;/p&amp;gt;&amp;lt;p&amp;gt;At a first glance, one could guess that this problem could be solved by a careful selection of representative test data covering many typical cases as well as some counterexamples. Then these test data can be used for the training of the internal parameters of a machine learning application. At a second glance, however, many researchers found out that a simple stacking up of plain examples is not the best choice for many scientific applications.&amp;lt;/p&amp;gt;&amp;lt;p&amp;gt;To get improved machine learning results, we concentrated on the analysis of satellite images depicting the Earth&amp;amp;#8217;s surface under various conditions such as the selected instrument type, spectral bands, and spatial resolution. In our case, such data are routinely provided by the freely accessible European Sentinel satellite products (e.g., Sentinel-1, and Sentinel-2). Our basic work then included investigations of how some additional processing steps &amp;amp;#8211; to be linked with the selected training data &amp;amp;#8211; can provide better machine learning results.&amp;lt;/p&amp;gt;&amp;lt;p&amp;gt;To this end, we analysed and compared three different approaches to find out machine learning strategies for the joint selection and processing of training data for our Earth observation images:&amp;lt;/p&amp;gt;&amp;lt;ul&amp;gt;&amp;lt;li&amp;gt;One can optimize the training data selection by adapting the data selection to the specific instrument, target, and application characteristics [1].&amp;lt;/li&amp;gt;&amp;lt;li&amp;gt;As an alternative, one can dynamically generate new training parameters by Generative Adversarial Networks. This is comparable to the role of a sparring partner in boxing [2].&amp;lt;/li&amp;gt;&amp;lt;li&amp;gt;One can also use a hybrid semi-supervised approach for Synthetic Aperture Radar images with limited labelled data. The method is split in: polarimetric scattering classification, topic modelling for scattering labels, unsupervised constraint learning, and supervised label prediction with constraints [3].&amp;lt;/li&amp;gt;&amp;lt;/ul&amp;gt;&amp;lt;p&amp;gt;We applied these strategies in the ExtremeEarth sea-ice monitoring project (http://earthanalytics.eu/). As a result, we can demonstrate for which application cases these three strategies will provide a promising alternative to a simple conventional selection of available training data.&amp;lt;/p&amp;gt;&amp;lt;p&amp;gt;[1] C.O. Dumitru et. al, &amp;amp;#8220;Understanding Satellite Images: A Data Mining Module for Sentinel Images&amp;amp;#8221;, Big Earth Data, 2020, 4(4), pp. 367-408.&amp;lt;/p&amp;gt;&amp;lt;p&amp;gt;[2] D. Ao et. al., &amp;amp;#8220;Dialectical GAN for SAR Image Translation: From Sentinel-1 to TerraSAR-X&amp;amp;#8221;, Remote Sensing, 2018, 10(10), pp. 1-23.&amp;lt;/p&amp;gt;&amp;lt;p&amp;gt;[3] Z. Huang, et. al., &amp;quot;HDEC-TFA: An Unsupervised Learning Approach for Discovering Physical Scattering Properties of Single-Polarized SAR Images&amp;quot;, IEEE Transactions on Geoscience and Remote Sensing, 2020, pp.1-18.&amp;lt;/p&amp;gt;</jats:p>\n",
      "<jats:p>        &amp;lt;p&amp;gt;During the last years, one could see a broad use of machine learning tools and applications. However, when we use these techniques for geophysical analyses, we must be sure that the obtained results are scientifically valid and allow us to derive quantitative outcomes that can be directly compared with other measurements.&amp;lt;/p&amp;gt;&amp;lt;p&amp;gt;Therefore, we set out to identify typical datasets that lend themselves well to geophysical data interpretation. To simplify this very general task, we concentrate in this contribution on multi-dimensional image data acquired by satellites with typical remote sensing instruments for Earth observation being used for the analysis for:&amp;lt;/p&amp;gt;&amp;lt;ul&amp;gt;&amp;lt;li&amp;gt;Atmospheric phenomena (cloud cover, cloud characteristics, smoke and plumes, strong winds, etc.)&amp;lt;/li&amp;gt;&amp;lt;li&amp;gt;Land cover and land use (open terrain, agriculture, forestry, settlements, buildings and streets, industrial and transportation facilities, mountains, etc.)&amp;lt;/li&amp;gt;&amp;lt;li&amp;gt;Sea and ocean surfaces (waves, currents, ships, icebergs, coastlines, etc.)&amp;lt;/li&amp;gt;&amp;lt;li&amp;gt;Ice and snow on land and water (ice fields, glaciers, etc.)&amp;lt;/li&amp;gt;&amp;lt;li&amp;gt;Image time series (dynamical phenomena, their occurrence and magnitude, mapping techniques)&amp;lt;/li&amp;gt;&amp;lt;/ul&amp;gt;&amp;lt;p&amp;gt;Then we analyze important data characteristics for each type of instrument. One can see that most selected images are characterized by their type of imaging instrument (e.g., radar or optical images), their typical signal-to-noise figures, their preferred pixel sizes, their various spectral bands, etc.&amp;lt;/p&amp;gt;&amp;lt;p&amp;gt;As a third step, we select a number of established machine learning algorithms, available tools, software packages, required environments, published experiences, and specific caveats. The comparisons cover traditional &amp;amp;#8220;flat&amp;amp;#8221; as well as advanced &amp;amp;#8220;deep&amp;amp;#8221; techniques that have to be compared in detail before making any decision about their usefulness for geophysical applications. They range from simple thresholding to k-means, from multi-scale approaches to convolutional networks (with visible or hidden layers) and auto-encoders with sub-components from rectified linear units to adversarial networks.&amp;lt;/p&amp;gt;&amp;lt;p&amp;gt;Finally, we summarize our findings in several instrument / machine learning algorithm matrices (e.g., for active or passive instruments). These matrices also contain important features of the input data and their consequences, computational effort, attainable figures-of-merit, and necessary testing and verification steps (positive and negative examples). Typical examples are statistical similarities, characteristic scales, rotation invariance, target groupings, topic bagging and targeting (hashing) capabilities as well as local compression behavior.&amp;lt;/p&amp;gt;        </jats:p>\n",
      "<jats:p>        &amp;lt;p&amp;gt;This abstract describes the Data Fusion tool of the Horizon 2020 CANDELA project. Here, Sentinel-1 (synthetic aperture radar) and Sentinel-2 (multispectral) satellite images are fused at feature level. This fusion is made by extracting the features from each type of image; then these features are combined in a new block within the Data Model Generation sub-module of the Data Fusion system.&amp;lt;/p&amp;gt;&amp;lt;p&amp;gt;The corresponding tool has already been integrated with the CANDELA cloud platform: its Data Model component on the platform is acting as backend, and the user interaction component on the local user machine as frontend. There are four main sub-modules: Data Model Generation for Data Fusion (DMG-DF), DataBase Management System (DBMS), Image Search and Semantic Annotation (ISSA), and multi-knowledge and Query (QE). The DMG-DF and DBMS sub-modules have been dockerized and deployed on the CANDELA platform. The ISSA and QE sub-modules require user inputs for their interactive interfaces. They can be started as a standard Graphical User Interface (GUI) tool which is linked directly to the database on the platform.&amp;lt;/p&amp;gt;&amp;lt;p&amp;gt;Before using the Data Fusion tool, users have to prepare the already co-registered Sentinel-1 and Sentinel-2 products as inputs. The S1tiling service provided on the platform is able to cut out the overlapping Sentinel-1 area based on Sentinel-2 tile IDs.&amp;lt;/p&amp;gt;&amp;lt;p&amp;gt;The pipeline of the Data Fusion tool starts from the DMG-DF process on the platform, and the data will be transferred via Internet; then local end users can perform semantic annotations. The annotations will be ingested into the database on the platform via Internet.&amp;lt;/p&amp;gt;&amp;lt;p&amp;gt;The Data Fusion process consists of three steps:&amp;lt;/p&amp;gt;&amp;lt;ul&amp;gt;&amp;lt;li&amp;gt;On the platform, launch a Jupyter notebook for Python, and start the Data Model Generation for Data Fusion to process the prepared Sentinel-1 and Sentinel-2 products which cover the same area;&amp;lt;/li&amp;gt;&amp;lt;li&amp;gt;On the local user machine, by clicking the Query button of the GUI, users can get access to the remote database, make image search and queries, and perform semantic annotations by loading quick-look images of processed Sentinel-1 and Sentinel-2 products via Internet. Feature fusion and image quick-look pairing are performed at runtime. The fused features and paired quick-looks help obtain better semantic annotations. When clicking on another ingestion button, the annotations are ingested into the database on the platform;&amp;lt;/li&amp;gt;&amp;lt;li&amp;gt;On the platform, launch a Jupyter notebook for Python, and the annotations and the processed product metadata can be searched and queried.&amp;lt;/li&amp;gt;&amp;lt;/ul&amp;gt;&amp;lt;p&amp;gt;Our preliminary validation results are made based on visual analysis, by comparing the obtained classification maps with already available CORINE land cover maps. In general, our fused results generate more complete classification maps which contain more classes.&amp;lt;/p&amp;gt;        </jats:p>\n",
      " Coastal areas call for dedicated analysis tools as they are characterized by characteristic static and dynamic features [2].\n",
      "Cascaded learning is a promising option for efficient machine learning. This has been verified with satellite images of TerraSAR-X.\n",
      "There is an unceasing interest in a global understanding of the processes governing the Earth involving observations of large extended areas, and over long periods of time, with a broad variety of Earth Observation (EO) sensors. The collected EO data volumes are increasing immensely, with the current EO technologies these will further grow rapidly, the horizons lie beyond Zettabytes of data. The challenge is the exploration of these data and the timely delivery of focused information and knowledge in a simple understandable format.\n",
      "Since modern imaging sensors continuously deliver enormous amounts of data. The extensive availability of high and very high resolution images is not only exploding the volumes of acquired data but also brings unavailable image detail, thus fantastically growing the information content. As for example ENVISAT provided measurements of the atmosphere, ocean, land, and ice over 10 years of operations generating a data archive that reaches many petabytes. TerraSAR-X contains an extensive data archive of more than 100,000 scenes covering the majority of the Earth's surface. In 2010, a second, almost identical to TerraSAR-X satellite was launched, the TanDEM-X (TerraSAR-X add-on for Digital Elevation Measurement). Since then both satellites started the synchronous data acquisition and completed the first coverage of the Earth's entire landmass within only 13 months. In the coming years, the Sentinels (1-5) will be launched contributing with data for land monitoring, e.g. imagery of vegetation, soil and water cover, inland waterways and coastal areas, etc.\n",
      "electronic library - From Shannon communication theory to semantic coding: Concepts for image information mining elib DLR-Header DLR-Logo -> http://www.dlr.de DLR Portal Home | Impressum | Datenschutz | Kontakt | English Schriftgroße: [-] Text [+] Erweiterte Suche Versenden Drucken From Shannon communication theory to semantic coding: Concepts for image information mining Datcu, Mihai und Schwarz, Gottfried (2011) From Shannon communication theory to semantic coding: Concepts for image information mining. IGARSS 2011, 24.-29. Jul. 2011, Vancouver, Kanada. Dieses Archiv kann nicht den Volltext zur Verfugung stellen. Offizielle URL: http://www.igarss11.org/Papers/AbstractSearch.asp?show=search Kurzfassung We outline basic concepts for image informatiin mining. elib-URL des Eintrags: https://elib.dlr.de/73736/ Dokumentart: Konferenzbeitrag (Vortrag) Titel: From Shannon communication \n",
      "Lokking at a target from different directions reveals a lot of details about the target. We show typical examples of high resolution SAR images.\n",
      "Information mining bears a considerable potential for multitemporal data analysis of Earth observation images. The current status and challenges will be described.\n",
      "electronic library - High resolution TerraSAR-X image mining using RELAX elib DLR-Header DLR-Logo -> http://www.dlr.de DLR Portal Home | Impressum | Datenschutz | Kontakt | English Schriftgroße: [-] Text [+] Erweiterte Suche Versenden Drucken High resolution TerraSAR-X image mining using RELAX Popescu, Anca und Datcu, Mihai (2011) High resolution TerraSAR-X image mining using RELAX. In: ESA-EUSC-JRC Conference Proceedings, Seiten 133-136. JRC. ESA-EUSC-JRC 2011, 30. Mar. - 01. Apr.2011, Ispra, Italien. ISBN 978-92-79-19708-6. Dieses Archiv kann nicht den Volltext zur Verfugung stellen. Offizielle URL: http://bookshop.europa.eu/is-bin/INTERSHOP.enfinity/WFS/EU-Bookshop-Site/en_GB/-/EUR/ViewPublication-Start?PublicationKey=LBNA24762 Kurzfassung We present a feature extraction procedure for SAR images based on the RELAX algorithm. elib-URL des Eintrags: https://elib.dlr.\n",
      "Information similarity meaasures, including mutual information, variational information and mixed information, are estimated and evaluated for multi-temporal change detection.\n",
      "electronic library - Image Information Mining elib DLR-Header DLR-Logo -> http://www.dlr.de DLR Portal Home | Impressum | Datenschutz | Kontakt | English Schriftgroße: [-] Text [+] Erweiterte Suche Versenden Drucken Image Information Mining Datcu, Mihai (2008) Image Information Mining. Ph.D. Geoinformation Program, 2008-09-27 - 2008-09-28, Rom. Dieses Archiv kann nicht den Volltext zur Verfugung stellen. Kurzfassung Modern geoinformation based on remote sensing data can profit from image information mining. elib-URL des Eintrags: https://elib.dlr.de/57738/ Dokumentart: Konferenzbeitrag (Vortrag) Titel: Image Information Mining Autoren: Autoren Institution oder E-Mail-Adresse Autoren-ORCID-iD Datcu, Mihai NICHT SPEZIFIZIERT NICHT SPEZIFIZIERT Datum: September 2008 Open Access: Nein Gold Open Access: Nein In SCOPUS: Nein In ISI Web of Science: Nein Status: veroffentlicht Stichworter: \n",
      "electronic library - Comparison of Multigrade and Wavelet Techniques for InSAR Phase Unwrapping. elib DLR-Header DLR-Logo -> http://www.dlr.de DLR Portal Home | Impressum | Datenschutz | Kontakt | English Schriftgroße: [-] Text [+] Erweiterte Suche Versenden Drucken Comparison of Multigrade and Wavelet Techniques for InSAR Phase Unwrapping. Datcu, Mihai (1996) Comparison of Multigrade and Wavelet Techniques for InSAR Phase Unwrapping. In: IGARSS '96. Dieses Archiv kann nicht den Volltext zur Verfugung stellen. elib-URL des Eintrags: https://elib.dlr.de/23781/ Dokumentart: Konferenzbeitrag (Paper) Zusatzliche Informationen: LIDO-Berichtsjahr=1996, Titel: Comparison of Multigrade and Wavelet Techniques for InSAR Phase Unwrapping. Autoren: Autoren Institution oder E-Mail-Adresse Autoren-ORCID-iD Datcu, Mihai NICHT SPEZIFIZIERT NICHT SPEZIFIZIERT Datum: 1996 Erschienen in: \n",
      "electronic library - Report on DLR work in SMART elib DLR-Header DLR-Logo -> http://www.dlr.de DLR Portal Home | Impressum | Datenschutz | Kontakt | English Schriftgroße: [-] Text [+] Erweiterte Suche Versenden Drucken Report on DLR work in SMART Keller, Martin und Dietrich, Bjorn und Muller, Rupert und Reinartz, Peter und Datcu, Mihai (2004) Report on DLR work in SMART. DLR-Interner Bericht, Projektbericht. 126 S. Dieses Archiv kann nicht den Volltext zur Verfugung stellen. Offizielle URL: http://www.smart.rma.ac.be/Report_on_DLR_work_in_SMART.pdf elib-URL des Eintrags: https://elib.dlr.de/22152/ Dokumentart: Berichtsreihe (DLR-Interner Bericht, Projektbericht) Titel: Report on DLR work in SMART Autoren: Autoren Institution oder E-Mail-Adresse Autoren-ORCID-iD Keller, Martin NICHT SPEZIFIZIERT NICHT SPEZIFIZIERT Dietrich, Bjorn NICHT SPEZIFIZIERT NICHT SPEZIFIZIERT Muller, Rupert \n",
      "Graph convolution networks (GCNs) are useful in remote sensing (RS) image retrieval. It is found to be effective because, in a graph representation, the relative geometrical interactions between different regions (or segments) are appropriately captured, along with their region-wise features in their region adjacency graphs. Also, the attention mechanism has often been applied to the nodes to highlight the essential features in each node. In this regard, a significant amount of high-frequency information is missed since each image segment is effectively summarized within a single node. To account for this and increase the learning capacity, we propose to attend over the edge/adjacency matrix to highlight the interactions among meaningful regions that contribute to supervised learning from images. We exploit this novel edge attention mechanism together with node attention to highlight essential image context by \n",
      "Quantum algorithms are designed to process quantum data (quantum bits) in a gate-based quantum computer. They are proven rigorously that they reveal quantum advantages over conventional algorithms when their inputs are certain quantum data or some classical data mapped to quantum data. However, in a practical domain, data are classical in nature, and they are very big in dimension, size, and so on. Hence, there is a challenge to map (embed) classical data to quantum data, and even no quantum advantages of quantum algorithms are demonstrated over conventional ones when one processes the mapped classical data in a gate-based quantum computer. For the practical domain of earth observation (EO), due to the different sensors on remote-sensing platforms, we can map directly some types of EO data to quantum data. In particular, we have polarimetric synthetic aperture radar (PolSAR) images characterized by polarized beams. A polarized state of the polarized beam and a quantum bit are the Doppelganger of a physical state. We map them to each other, and we name this direct mapping a natural embedding, otherwise an artificial embedding. Furthermore, we process our naturally embedded data in a gate-based quantum computer by using a quantum algorithm regardless of its quantum advantages over conventional techniques; namely, we use the QML network as a quantum algorithm to prove that we naturally embedded our data in input qubits of a gate-based quantum computer. Therefore, we employed and directly processed PolSAR images in a QML network. Furthermore, we designed and provided a QML network with an additional layer of a neural network, namely, a hybrid quantum-classical network, and demonstrate how to program (via optimization and backpropagation) this hybrid quantum-classical network when employing and processing PolSAR images. In this work, we used a gate-based quantum computer offered by an IBM Quantum and a classical simulator for a gate-based quantum computer. Our contribution is that we provided very specific EO data with a natural embedding feature, the Doppelganger of quantum bits, and processed them in a hybrid quantum-classical network. More importantly, in the future, these PolSAR data can be processed by future quantum algorithms and future quantum computing platforms to obtain (or demonstrate) some quantum advantages over conventional techniques for EO problems.\n",
      "This letter studies how to program and assess a parameterized quantum circuit (PQC) for classifying Earth observation (EO) satellite images. In this exploratory study, we assess a PQC for classifying a two-label EO image dataset and compare it with a classic deep learning classifier. We use the PQC with an input space of only 17 quantum bits (qubits) due to the current limitations of quantum technology. As a real-world image for EO, we selected the Eurosat dataset obtained from multispectral Sentinel-2 images as a training dataset and a Sentinel-2 image of Berlin, Germany, as a test image. However, the high dimensionality of our images is incompatible with the PQC input domain of 17 qubits. Hence, we had to reduce the dimensionality of the input images for this two-label case to a vector with 16 elements; the 17th qubit remains reserved for storing label information. We employed a very deep convolutional network with an autoencoder as a technique for the dimensionality reduction of the input image, and we mapped the dimensionally reduced image onto 16 qubits by means of parameter thresholding. Then, we used a PQC to classify the two-label content of the dimensionally reduced Eurosat image dataset. A PQC classifies the Eurosat images with high accuracy as a classic deep learning method (and with even better accuracy in some instances). From our experiment, we derived and enhanced deeper insight into programming future gate-based quantum computers for many practical problems in EO.\n",
      "Current visualization techniques of Earth Observation (EO) multispectral data rely on limited settings depending on the combination of three spectral bands or the usage of the true-color representation. The visual information is incomplete, many spectral similarities or dissimilarities remain hidden to the human visual perception. We propose a deep learning-based approach translating the multispectral signatures into R  G  B images. A stacked autoencoder (SAE) is used to embed the information from all spectral bands into three bands. The resulted bands are further used for the false-color representation of the image. The experimental evidences using both Sentinel 2 and Landsat 8 datasets show that the proposed method improves the visualization performance compared with classical methods like R  G  B, minimum redundancy maximum relevance criterion (mRMR) and principal component analysis (PCA). Mutual information quantization is used for results evaluation.\n",
      "Land cover maps are among the most important products of Remote Sensing (RS) imagery. Despite remarkable advancements in land cover classification techniques, abundant detailed information in the very high-resolution RS images necessitates further improvements to harness the data and discover detailed semantic information. Moreover, scarcity of the labelled data and its quality is a major limitation in RS land cover mapping. In the present study, Latent Dirichlet Allocation is employed for semantic discovery in RS images and a novel kernel-based Bag of Visual Words model is proposed for land cover mapping.\n",
      "This paper aims to present a new algorithm to remove thin clouds and retain information in corrupted images without the use of auxiliary data. By injecting physical properties into the cycle consistent generative adversarial network (GAN), we were able to convert a cloudy multispectral image to a cloudless image. To recover information beneath clouds and shadows we create a synthetic multispectral space to obtain illumination invariant features. Multispectral vectors were transformed from Cartesian coordinates to Polar coordinates to obtain spectral angular distance (SAD) then we employed them as input to train the deep neural network (DNN). Afterward, the outputs of DNN were transformed to Cartesian coordinates to obtain shadow and cloud-free multispectral images. The proposed method, Hybrid GAN-SAD yields trustworthy reconstructed results because of exploiting transparent information from certain multispectral bands to recover uncorrupted images.\n",
      "Although the number of labeled dataseis in Earth Observation (EO) is increasing, there is still a major gap between the Deep Learning (DL) classifiers designed in this field versus the models in Computer Vision. This gap is produced mainly by the number of datasets available, but also by the diversity of data. In EO, there are different sensors acquiring images, from multispectral (MS) or hyperspectral data, to SAR imagery. In this paper, we want to demonstrate how to reduce the divergence created by the diversity of data. We trained several DL architectures on Bag-of-Words from large-scale MS and SAR datasets, and then we used transfer learning on smaller ones and evaluated the results. With this method, we demonstrate that a DL architecture can be trained with any type of large-scale data, transformed into Bag-of-Words, and the trained model can be used further on other types of data, without regard on the number of channels.\n",
      "Bistatic radar receivers that use an opportunistic transmitter require a reference channel to capture the original transmitted signal, which is then used as a reference signal for constructing the matched-filter during the range compression step. Because the reference signal is received from line-of-sight, it is orders in magnitude larger than the reflections captured by the receive channel. It is generally difficult to construct the system such that the reference signal is not leaked into the received signal, either via coupling in the circuitry or via reflections off objects in the vicinity of the receiver. Due to its much larger amplitude, the reference signal can easily mask smaller targets with its side-lobes. In this paper we propose a novel deconvolution method for bistatic SAR images as a means of eliminating leakage of the reference signal.\n",
      "Conventional remote sensing data analysistechniques have a significant bottleneck of operating on a selectively chosen small-scale dataset. Availability of an enormous volume of data demands handling large-scale, diverse data, which have been made possible with neural network-based architectures. This article exploits the contextual information capturing ability of deep neural networks, particularly investigating multispectral band properties from Sentinel-2 image patches. Besides, an increase in the spatial resolution often leads to nonlinear mixing of land-cover types within a target resolution cell. We recognize this fact and group the bands according to their spatial resolutions, and propose a classification and retrieval framework. We design a representation learning framework for classifying the multispectral data by first utilizing all the bands and then using the grouped bands according to their spatial \n",
      "Remote sensing multispectral images are extensively used by applications in various fields. The degradation generated by haze or smoke negatively influences the visual analysis of the represented scene. In this paper, a deep neural network based method is proposed to address the visualization improvement of hazy and smoky images. The method is able to entirely exploit the information contained by all spectral bands, especially by the SWIR bands, which are usually not contaminated by haze or smoke. A dimensionality reduction of the spectral signatures or angular signatures is rapidly obtained by using a stacked autoencoders (SAE) trained based on contaminated images only. The latent characteristics obtained by the encoder are mapped to the R - G - B channels for visualization. The haze and smoke removal results of several Sentinel 2 scenes present an increased contrast and show the haze hidden areas from the initial natural color images.\n",
      "In this work, we address a cross-modal retrieval problem in remote sensing (RS) data. A cross-modal retrieval problem is more challenging than the conventional uni-modal data retrieval frameworks as it requires learning of two completely different data representations to map onto a shared feature space. For this purpose, we chose a photo-sketch RS database. We exploit the data modality comprising more spatial information (sketch) to extract the other modality features (photo) with cross-attention networks. This sketch-attended photo features are more robust and yield better retrieval results. We validate our proposal by performing experiments on the benchmarked Earth on Canvas dataset. We show a boost in the overall performance in comparison to the existing literature. Besides, we also display the Grad-CAM visualizations of the trained model's weights to highlight the framework's efficacy.\n",
      "This paper describes an active learning tool for the generation of Earth Observation (EO) benchmark datasets. This tool is able to generate training datasets, based on its active learning strategy with a classification accuracy of around 90%. Afterwards, a data cleaning tool is needed, in order to correct noisy data and provide a clean dataset to be stored in the benchmark database, and for subsequent benchmark verification. The data cleaning procedure is supported by unsupervised learning, using clustering algorithms to group similar patterns, and dimension reduction algorithms to embed them in lower dimension with annotated labels. Moreover, interactive visualizations are implemented in most modules to help better manipulate datasets and get better understandings.\n",
      "Over the last few years, natural disasters elevated dangerously in terms of immensity and prevalence over areas covered by forest and urban woodlands. Fast-spreading nature of the wildfires determine quick uncontrollable situations, causing significant effects in short periods. Despite increased difficulty in image processing approaches due to temporal resolution, complexity of spectral bands and illumination conditions, imagery data streams available from sun-synchronous satellites provide geospatial intelligence in monitoring and preventing fire threats. In this paper, we proposed a local scale burned area estimation framework that employs multispectral images in a deep learning architecture for detecting burned surfaces at patch level. This goal is accomplished by using an autoencoder (AE) network in which the latent feature layer learns normal background distribution, beneficial to background reconstruction. Furthermore, an outlier detection method (OCSVM) is used with aggregated features, latent and covariance components, in order to estimate burned coverage. Our method operates on data retrieved from Sentinel-2 (S2) constellation streaming source, which mainly contain normal scenes and limited fire affected spots.\n",
      "Integrating the special electromagnetic characteristics of Synthetic Aperture Radar (SAR) in deep neural networks is essential in order to enhance the explainability and physics awareness of deep learning. In this paper, we first propose a novel physically explainable convolutional neural network for SAR image classification, namely physics guided and injected learning (PGIL). It comprises three parts: (1) explainable models (XM) to provide prior physics knowledge, (2) physics guided network (PGN) to encode the knowledge into physics-aware features, and (3) physics injected network (PIN) to adaptively introduce the physics-aware features into classification pipeline for label prediction. A hybrid Image-Physics SAR dataset format is proposed for evaluation, with both Sentinel-1 and Gaofen-3 SAR data being experimented. The results show that the proposed PGIL substantially improve the classification performance in case of limited labeled data compared with the counterpart data-driven CNN and other pre-training methods. Additionally, the physics explanations are discussed to indicate the interpretability and the physical consistency preserved in the predictions. We deem the proposed method would promote the development of physically explainable deep learning in SAR image interpretation field.\n",
      "<jats:p>Satellite instruments monitor the Earth’s surface day and night, and, as a result, the size of Earth observation (EO) data is dramatically increasing. Machine Learning (ML) techniques are employed routinely to analyze and process these big EO data, and one well-known ML technique is a Support Vector Machine (SVM). An SVM poses a quadratic programming problem, and quantum computers including quantum annealers (QA) as well as gate-based quantum computers promise to solve an SVM more efficiently than a conventional computer; training the SVM by employing a quantum computer/conventional computer represents a quantum SVM (qSVM)/classical SVM (cSVM) application. However, quantum computers cannot tackle many practical EO problems by using a qSVM due to their very low number of input qubits. Hence, we assembled a coreset (“core of a dataset”) of given EO data for training a weighted SVM on a small quantum computer, a D-Wave quantum annealer with around 5000 input quantum bits. The coreset is a small, representative weighted subset of an original dataset, and its performance can be analyzed by using the proposed weighted SVM on a small quantum computer in contrast to the original dataset. As practical data, we use synthetic data, Iris data, a Hyperspectral Image (HSI) of Indian Pine, and a Polarimetric Synthetic Aperture Radar (PolSAR) image of San Francisco. We measured the closeness between an original dataset and its coreset by employing a Kullback–Leibler (KL) divergence test, and, in addition, we trained a weighted SVM on our coreset data by using both a D-Wave quantum annealer (D-Wave QA) and a conventional computer. Our findings show that the coreset approximates the original dataset with very small KL divergence (smaller is better), and the weighted qSVM even outperforms the weighted cSVM on the coresets for a few instances of our experiments. As a side result (or a by-product result), we also present our KL divergence findings for demonstrating the closeness between our original data (i.e., our synthetic data, Iris data, hyperspectral image, and PolSAR image) and the assembled coreset.</jats:p>\n",
      "Hyperspectral, multispectral and multitemporal satellite images are considered as 3D signals and processed using 3D signal techniques. The third dimension is given by the spectral/temporal channels and the idea to perform a 3D processing is an attempt to take advantage of the correlation existing between these channels in order to achieve higher data compression rates. Two methods are investigated and compared: a 3D linear predictor based on a low order Markov model and a 3D wavelet decomposition procedure. Although the compression rate depends highly on the structure of the data, the 3D algorithms perform always better than the 2D ones. This justifies the use of 3D signal processing techniques in remote sensing applications involving a large number of correlated spectral or temporal channels.\n",
      "Visualization of multispectral images through band selection methods determines an information loss that in utmost cases proves to be critical for the adequate understanding of the represented scene. The R-G-B representation obtained by mapping the visual bands to the R, G, and B channels is highly used due to its great resemblance with the natural color one and aspects perceivable by the human eye. However, despite the similarity in terms of color code, ambiguities between classes such as water and vegetation or atmospheric phenomena like fog, clouds, and smoke that have been penetrated by other bands, remain visible and hinder the process of visualization of the Earth surface. This article presents a set of five different methods to offset the effects caused by ambiguities, fog, light clouds, and smoke by transferring relevant information between bands in order to visually reconstitute those parts of the image affected by atmospheric phenomena. The general concept shared by these methods implies a stacked autoencoder that successfully encompasses the information from all spectral bands into a latent representation used for visualization. Each proposed method is defined by different combination of input and error function formula. Spectral and polar coordinates features represent the possible options for the input, while formulas based on mean squared error or angular spectral distances determine the potential choices in terms of error function definition. The property of angular spectral distance and polar coordinates transformation to obtain illuminant invariant features determined their use in three out of five methods. We evaluate the methods through spectral signature graphical comparison and visual comparison related to the R-G-B representation. We conduct experiments on multiple Sentinel 2 full images.\n",
      "Recent advances in remote sensing technology have provided (very) high spatial resolution Earth Observation data with abundant latent semantic information. Conventional data processing algorithms are not capable of extracting the latent semantic information form these data and harness their full potential. As a result, semantic information discovery methods, based on data mining techniques, such as latent Dirichlet allocation and bag of visual words models, can discover the latent information. Despite their crucial rule, there are only a few studies in the field of semantic data mining for remote sensing applications. This article is focused on this shortage. Three different scenarios are used to evaluate the semantic information discovery in various remote sensing applications, including both optical and synthetic aperture radar (SAR) data with different spatial resolutions. In the first scenario, semantic discovery method correlated the semantic perception of the user and machine to correct and enhance the user defined Ground Truth map in very high-resolution RGB data. The potential of the semantic discovery is evaluated for wildfire affected area detection in Sentinel-2 data in the second scenario. Finally, in the third scenario, the semantic discovery method is utilized to detect the misclassifications as well as the patches with ambiguous or multiple semantic labels in a Sentinel-1 SAR patch-based benchmark dataset to enhance the robustness and accuracy of the annotation in the dataset. Our results in these three scenarios demonstrated the capability of the data-mining-based semantic information discovery methods for various remote sensing.\n",
      "Spaceborne synthetic aperture radar (SAR) can provide meters-scale images of the ocean surface roughness day-or-night in nearly all weather conditions. This makes it a unique asset for many geophysical applications. Sentinel-l SAR wave mode (WV) vignettes have made possible to capture many important oceanic and atmospheric phenomena since 2014. However, considering the amount of data provided, expanding applications requires a strategy to automatically process and extract geophysical parameters. In this study, we propose to apply subaperture decomposition (SD) as a preprocessing stage for SAR deep learning models. Our data-centring approach surpassed the baseline by 0.7%, obtaining state-of-the-art on the TenGeoP-SARwv data set. In addition, we empirically showed that SD could bring additional information over the original vignette, by rising the number of clusters for an unsupervised segmentation method. Overall, we encourage the development of data-centring approaches, showing that, data preprocessing could bring significant performance improvements over existing deep learning models.\n",
      "This paper presents a methodology based on matched-adaptive filters that is used to mitigate the effect of near-range multipath in multistatic SAR systems and transponders. It is challenging to physically construct a bistatic receiver such that the reference signal is not leaked into the received signal, either via coupling in the circuitry or via reflections off objects in the vicinity of the receiver. Due to its much larger amplitude, the reference signal can easily mask near-range targets with its side-lobes. A similar signal degradation is observed in active transponders that are used for calibrating radar systems, when objects exist in their vicinity. In this paper we address these two issues: the coupling between the reference channel and the imaging channel, and the parasitic echoes present in the transponder response. A novel methodology is proposed that is capable of time-domain filtering the undesired components in real time. The novelty consists in combining matched and adaptive filters as a means of boosting performance and resolution estimation, resulting in an extremely accurate multipath elimination method. The proposed methodology is experimentally evaluated and optimized for each of the two aforementioned problems.\n",
      "Synthetic aperture radar (SAR) is the most efficient tool to provide high-resolution data for Earth Observation (EO). Doppler centroid (DC) estimation is indispensable for high precision SAR data analysis such as extracting the ocean surface current, which is important for scientific pursuits. Correlation doppler estimation (CDE), and energy balancing (EB) based DC methods are implemented in this paper. A 2-D sliding window is deployed to estimate DC on small blocks of data while covering the whole scene so that all parts of the scene are potentially represented. We analyzed Sentinel-1 single look complex (SLC) data from the coastline of a non-homogeneous scene. The CDE method utilizes the azimuth shift in the time domain which is associated with the DC, and this fDc history is used to extract ocean surface current. We find the results of DC estimates are confined to primitive baseband (PRF/2). Moreover, the corresponding retrieved ocean surface current component is reasonable, particularly values vary within the limit of error bounds. Finally, the parameters of ocean surface current are compared with ocean wave models reported in the literature. Efficacy and simulation of implemented methods are good fit for Sentinel-1 SAR data.\n",
      "The recent technological advancements in remote sensing lead to an increased importance regarding the analysis of satellite data targeting security and surveillance tasks. Although the availability of data products is constantly augmented and the advances in Deep Learning technologies are constant, Synthetic Aperture Radar (SAR) image classification remains a challenge in the remote sensing domain because standard convolutional neural network-based architectures may encounter difficulties in recognizing objects that are characterized by similar texture, but different backscattering patterns. Moreover, training deep learning architectures requires a large volume of annotated data, which, in general, represents an obstacle, especially in the case of the remote sensing domain. This article addresses complex-valued SAR image classification through both spatial and Fourier-domain features, extracted by means of pretrained neural networks. While spatial features allow extracting knowl-edge regarding the structure and texture of the objects from intensity images, the physical properties of the objects are learned from radar spectrograms. In addition, we show that considering different polarizations of the SAR sensor, we are able to obtain better visual classifications. The experiments are conducted over Sentinel-1images, which are freely available for download under the Copernicus initiative.\n",
      "The High-Performance and Disruptive Computing in Remote Sensing (HDCRS) Working Group (WG) was recently established under the IEEE Geoscience and Remote Sensing Society (GRSS) Earth Science Informatics (ESI) Technical Committee to connect a community of interdisciplinary researchers in remote sensing (RS) who specialize in advanced computing technologies, parallel programming models, and scalable algorithms. HDCRS focuses on three major research topics in the context of RS: 1) supercomputing and distributed computing, 2) specialized hardware computing, and 3) quantum computing (QC). This article presents these computing technologies as they play a major role for the development of RS applications. The HDCRS disseminates information and knowledge through educational events and publication activities which will also be introduced in this article.\n",
      "In the past decade, object detection has achieved significant progress in natural images but not in aerial images, due to the massive variations in the scale and orientation of objects caused by the bird's-eye view of aerial images. More importantly, the lack of large-scale benchmarks has become a major obstacle to the development of object detection in aerial images (ODAI). In this paper, we present a large-scale Dataset of Object deTection in Aerial images (DOTA) and comprehensive baselines for ODAI. The proposed DOTA dataset contains 1,793,658 object instances of 18 categories of oriented-bounding-box annotations collected from 11,268 aerial images. Based on this large-scale and well-annotated dataset, we build baselines covering 10 state-of-the-art algorithms with over 70 configurations, where the speed and accuracy performances of each model have been evaluated. Furthermore, we provide a code \n",
      "SAR images have shown to be of high complexity and to require dedicated processing techniques. This paper presents two applications of the wavelet and multiresolution theory to the enhancement and characterization of SAR data. The rst application describes an improved method for speckle reduction. The second method uses a fractal-based texture measure to provide elements for SAR image segmentation. The methods have been applied to airborne C-band SAR images.\n",
      "The techniques based on fractals show promising results in the field of image understanding and visualization of high complexity data. In the aim to give an introduction to the theory of fractals the following topics will be summarised in this paper: the definition and analysis of fractals based on self-similarity and self-affinity behaviours, definitions for fractal dimension, fractal synthesis, multiresolution approach in the analysis and synthesis of fractals, fractals and hierarchic stochastic processes. The derived techniques with applications in geo-information processing and understanding will be underlined: generation of synthetic DEMs, fractal resampling of actual DEMs, algorithms for computation of the fractal dimension, unknown information modelling and data fusion, multiresolution synthesis and analysis of fractal images, multiresolution analysis and fractal dimension estimation. The paper presents also several experiments using fractals to generate accurate models for landforms and cover types, generation of synthetic images for model based picture processing, and image processing techniques for the analysis of remotely sensed images. The techniques have been applied both for optical and Synthetic Aperture Radar (SAR) image interpretation.\n",
      "<jats:p>Abstract. These last decades, Earth Observation brought a number of new perspectives from geosciences to human activity monitoring. As more data became available, Artificial Intelligence (AI) techniques led to very successful results for understanding remote sensing data. Moreover, various acquisition techniques such as Synthetic Aperture Radar (SAR) can also be used for problems that could not be tackled only through optical images. This is the case for weather-related disasters such as floods or hurricanes, which are generally associated with large clouds cover. Yet, machine learning on SAR data is still considered challenging due to the lack of available labeled data. To help the community go forward, we introduce a new dataset composed of co-registered optical and SAR images time series for the detection of flood events and new neural network approaches to leverage these two modalities.                    </jats:p>\n",
      "Understanding the physical properties and scattering mechanisms contributes to synthetic aperture radar (SAR) image interpretation. For single-polarized SAR data, however, it is difficult to extract the physical scattering mechanisms due to lack of polarimetric information. Time-frequency analysis (TFA) on complex-valued SAR image provides extra information in frequency perspective beyond the image domain. Based on TFA theory, we propose to generate the subband scattering pattern for every object in complex-valued SAR image as the physical property representation, which reveals backscattering variations along slant-range and azimuth directions. In order to discover the inherent patterns and generate a scattering classification map from single-polarized SAR image, an unsupervised hierarchical deep embedding clustering (HDEC) algorithm based on TFA (HDEC-TFA) is proposed to learn the embedded \n",
      "The normalized information distance (NID) is an universal metric distance based on Kolmogorov complexity. However, NID is not computable in a Turing sense. The normalized compression distance (NCD) is a computable distance that approximates NID by using normal compressors. NCD is a parameter-free distance that compares two signals by their lengths after separate compression relative to the length of the signal resulting from their concatenation after compression. The use of NCD for image retrieval over large image databases is difficult due to the computational cost of compressing the query image concatenated with every image in the database. The use of dictionaries extracted by dictionary-based compressors, such as the LZW compression algorithm, has been proposed to overcome this problem. Here we propose a Content-Based Image Retrieval system based on such dictionaries for the mining of \n",
      "The last two decades showed an important development of satellite imagery with past and present satellites acquiring enormous volumes of data. Meanwhile, the quality of the acquired images increased permitting the recording of high resolution images (0.6divide2.5 meters/pixel) in multispectral bands. Thus, both the data volume and the information detail increase dramatically. Consequently, new methods and tools to access and interpret earth observation (EO) images are needed. The present paper presents a semantic search engine for high resolution (HR) EO images based on a hierarchical information model of satellite image contents. To face the potentially ambiguous meaning of image structures depending on their contextual understanding, the search engine uses Bayesian inference to learn categories and a support vector machine (SVM) classifier to assign semantics. The categories are grouping and \n",
      "The new generation of high resolution imaging satellites acquires huge amounts of data which are stored in large archives. The state-of-the-art Systems for data access allow only queries by geographical location, time of acquisition or type of sensor. This information is often less important than the content of the scene, ie structures, objects or scattering properties. Meanwhile, many new applications of remote sensing data are closer to Computer vision and require the knowledge of complicated spatial and structural relationships among image objects. We are creating an intelligent satellite information mining system, a next generation architecture to help users to rapidly collect information, a tool to enhance and to manage the huge amount of historical and newly acquired satellite data-sets by giving experts access to relevant information in an understandable and directly usable form and to provide friendly interfaces for information query and browsing. Research topics are within the frame of Bayesian learning, content-based querying, data modelling and adaptation to user conjecture.\n",
      "Radiometric evolution classification in high resolution satellite image time series SITS - Archive ouverte HAL Acceder directement au contenu Acceder directement a la navigation Toggle navigation CCSD HAL HAL HALSHS TEL MediHAL Liste des portails AUReHAL API Data Documentation Episciences.org Episciences.org Revues Documentation Sciencesconf.org Support HAL - Archives Ouvertes Accueil Depot Consultation Les derniers depots Par type de publication Par discipline Par annee de publication Par structure de recherche Les portails de l'archive Recherche Documentation hal-00520970, version 1 Communication dans un congres Radiometric evolution classification in high resolution satellite image time series SITS Camille Le Men 1 Andreea Julea 2, 3 Nicolas Meger 2 Mihai Datcu 1 Philippe Bolon 2 Henri Maitre 1 Details 1 LTCI - Laboratoire Traitement et Communication de l'Information 2 LISTIC - \n",
      "Actually the growing volume of data provided by different sources some times may present inconsistencies, the data could be incomplete with lack of values or containing aggregate data, noisy containing errors or outliers, etc. Then data cleaning consist in filling missing values, smooth noisy data, identify or remove outliers and resolve inconsistencies. In more general definition, data cleaning is a task to identify something that is unusual and try to correct it.\n",
      "5 Conclusions The present paper presents an automatic method for the detection of errors and artifacts in the generation of\n",
      "The high complexity of remotely sensed images and measurements, provided by the last generation of sensors, demands new techniques for scene understanding and analysis. The paper introduces topics in multisensor and synthetic images fusion. The fractal geometry is applied for unknown information modelling. Integrated techniques in computer graphics and computer vision are used. A new method is introduced for more accurate representation and visualisation of the fractal surfaces. A multiresolution approach is considered for the accurate description of surface radiometry and geometry. The image synthesis is based on the knowledge of surface geometry, on radiation source, and sensor characteristics, and on the radiation scattering process for different cover types. In the final part, results of the developed techniques are applied in satellite imagery understanding.\n",
      "The increased number of free and open Sentinel satellite images has led to new applications of these data. Among them is the systematic classification of land cover/use types based on patterns of settlements or agriculture recorded by these images, in particular, the identification and quantification of their temporal changes. In this paper, we will present guidelines and practical examples of how to obtain rapid and reliable image patch labelling results and their validation based on data mining techniques for detecting these temporal changes, and presenting these as classification maps and/or statistical analytics. This represents a new systematic validation approach for semantic image content verification. We will focus on a number of different scenarios proposed by the user community using Sentinel data. From a large number of potential use cases, we selected three main cases, namely forest monitoring, flood \n",
      "This paper presents results from the application of model based techniques for an efficient correction to the topographically induced radiometric influences on the remotely sensed imagery. Thus, in a first step, relief induced geometric distortions of optical imagery must be removed, taking terrain elevation into account. In a second step the radiometry of the image is considered. Synthetic images are generated based on the Digital Elevation Models, and sun and satellite position at the time of acquisition of the image. The synthetically derived images model the image formation process for the direct lighted and shaded areas, using direct, indirect, and diffuse illumination. The resemblance of the synthesized image to reality is evaluated for a mountainous alpine region covered by snow. In a last step the data derived from the synthetic image are used for radiometric correction of the effects of the topography.\n",
      "This paper presents the first results obtained by repeat-pass bistatic synthetic aperture radar (SAR) interferometry using a fixed C-band ground-based receiver and the Sentinel-1A/B satellites as transmitters of opportunity. The methodology developed to obtain repeat-pass bistatic SAR interferograms uses as input a stack of range compressed bistatic acquisition data and mainly consists in the following stages: raw inter-ferograms computation on a two-dimensional grid in ground geometry, atmospheric phase screen removal and topographic phase compensation. The displacements of a high-rise building were estimated using two stacks of bistatic SAR images acquired between April-June 2017 over an area of Bucharest city, Romania.\n",
      "ExtremeEarth is a three-year H2020 ICT research and innovation project which is currently in its final year. The main objective of ExtremeEarth is to develop Artificial Intelligence and Big Data techniques and technologies that scale to the large volumes of big Copernicus data, information and knowledge, and apply these technologies in two of the ESA Thematic Exploitation Platforms: Food Security and Polar. The technical contributions of the project so far include: (i) new deep learning architectures for crop type mapping in the context of the Food Security use case, (ii) new deep learning architectures for sea ice mapping in the context of the Polar use case, (iii) the development and open publication of very large datasets for training these architectures, (iv) new versions of scalable semantic technologies for managing big linked geospatial data, and (v) a new platform for bringing all the previous technologies together and applying them to the two use cases.\n",
      "Reference data sets, necessary to the advancement of the field of object recognition by providing a point of comparison for different algorithms, are prevalent in the field of multimedia. Although sharing the same basic object recognition problem, in the field of remote sensing there is a need for specialized reference data sets. This paper would like to open the topic for discussion, by taking a first attempt at creating a reference data set for a satellite image. In doing so, important differences between annotating photographic and satellite images are highlighted, along with their impact on the creation of a reference data set. The results are discussed with a view toward creating a future methodology for the manual annotation of satellite images.\n",
      "Dans cet article, nous proposons une nouvelle methode dapprentissage actif sur des bases dimages satellites permettant dincorporer linformation a priori contenue dans les donnees ( donnee fait reference ici aux parametres de texture, couleur, forme... extraits des images). Plus precisement, nous utilisons la connaissance dune distribution a priori sur les donnees, dans notre cas un melange de Gaussiennes, pour guider lapprentissage dun classifieur SVM. Un algorithme dapprentissage actif qui reprend cette idee est dabord decrit. Les performances de lalgorithme ainsi obtenu sont ensuite comparees en terme de vitesse dapprentissage et de capacite a gerer de gros volumes de donnees a une approche classique utilisant un classifieur SVM qui nexploite pas la structure a priori des donnees. Les tests sont realises sur une base dimages satellites haute resolution QuickBird.\n",
      "Spaceborne Synthetic Aperture Radar (SAR) is one important way to obtain the information of ocean surface velocity. The Doppler Centroid Anomaly (DCA) estimation, which obtain the radical velocity based on the difference between the measured Doppler centroid and the predicted Doppler centroid, have be used to most onboard spaceborne SAR. GaoFen-3 (GF-3), the first full-polarimetric SAR satellite of China. This paper shows the experiments of direct ocean surface velocity measurement for GF-3 SAR Satellite. Comparing the results to the actual ocean current, the proposed method of ocean surface velocity measurement for GF-3 SAR is validated. Thus, GF-3 has the similar ability to retrieve the radical ocean surface velocity as Sentinel-1 and Radarsat-2.\n",
      "This article presents the achievements of the Candela project. This project aims to develop a platform and new algorithms for the handling, analysis and interpretation of earth observation data. The platform is hosted on the CREODIAS cloud ensuring the proximity of data and its processing. To ensure good performances the platform can scale up or down its computing resources. New algorithms based on machine learning methods for change detection and classification have been developed in the project. The results of these new algorithms are transformed into semantic data used to enrich earth observation products and provide new ways of exploitation. Finally, an end-to-end use of the platform is presented with a use case study of the impact of intense meteorological events on vineyards.\n",
      "In this article we propose a parameter-free method for Remote Sensing (RS) image databases Data Mining (DM). DM of RS images requires methodologies robust to the diversity of context found in such large datasets, as well as methodologies with low computational costs and low memory requirements. The methodology that we propose is based on the Normalized Compression Distance (NCD) over lossless compressed data. Normalized Compression Distance is a measure of similarity between two data files using the compression factor as an approximation to the Kolmogorov complexity. This approach allows to directly compare information from two images using the lossless compressed original files, and avoiding the feature extraction/selection process commonly used in pattern recognition techniques. This shortcut makes the proposed methodology suitable for DM applications in RS. We provided a classification experiment with hyperspectral data exemplarizing our methodology and comparing it with common methodologies found on the literature.\n",
      "Construction works in the city of Valencia are changing continuously the appearance of the city: new metro lines, the construction of the high speed railway lines, for the train between Madrid and Valencia, the renewal of the districts of El Grao, Cabanyal and Campanar, and some other works for the extension of the harbor area including commercial docks, the facilities for the Americas Cup and the Formula 1 circuit. All these changes could affect the city of Valencia, for example with subsidence, landslides, uplift, since it is located over a quaternary alluvial plane with a complex hydro-geological system. Due to its proximity to the sea, the phreatic surface is at only seven meters depth. Construction works are always affected by this fact and the special characteristics of an unstable but very fertile soil. Interferometric studies have been done in order to estimate possible cases of subsidence over the city and its surroundings. Our work covers a period of 7 years, from 2003 to the present, and it is focused mainly over the port area, where we could detect the most significant results. Our dataset includes ENVISAT ASAR and TerraSAR-x, the German radar satellite, Stripmap images. The collaboration with the Port of Valencia allowed us to have access to the study area and documents that helped us to explain our results.\n",
      "electronic library - In SAR topographic mapping - a bayesian approach elib DLR-Header DLR-Logo -> http://www.dlr.de DLR Portal Home | Impressum | Datenschutz | Kontakt | English Schriftgroße: [-] Text [+] Erweiterte Suche Versenden Drucken In SAR topographic mapping - a bayesian approach Wilkinson, Andrew und Datcu, Mihai (1997) In SAR topographic mapping - a bayesian approach. European Geophsical Society XXII General Assembly, Vienna, Austria, 21. -25. April 1997. Dieses Archiv kann nicht den Volltext zur Verfugung stellen. elib-URL des Eintrags: https://elib.dlr.de/23930/ Dokumentart: Konferenzbeitrag (Vortrag) Zusatzliche Informationen: LIDO-Berichtsjahr=1997, Titel: In SAR topographic mapping - a bayesian approach Autoren: Autoren Institution oder E-Mail-Adresse Autoren-ORCID-iD Wilkinson, Andrew NICHT SPEZIFIZIERT NICHT SPEZIFIZIERT Datcu, Mihai NICHT SPEZIFIZIERT NICHT \n",
      "The objective of WP6 is to build a Virtual Earth Observatory for TerraSAR-X data and demonstrate its functionality by developing use scenarios such as rapid mapping, semantic cataloguing, etc. This deliverable is the second part of Deliverable 6.2 (Ontologies for the VO for TerraSAR-X data) of the TELEIOS project. The present document continues the work started with Deliverable 6.2. 1 where the first version of DLR ontology for TerraSAR-X data was developed.\n",
      "The High-Performance and Disruptive Computing in Remote Sensing (HDCRS) Working Group (WG) was recently established under the IEEE Geoscience and Remote Sensing Society (GRSS) Earth Science Informatics (ESI) Technical Committee to connect a community of interdisciplinary researchers in remote sensing (RS) who specialize in advanced computing technologies, parallel programming models, and scalable algorithms. HDCRS focuses on three major research topics in the context of RS: 1) supercomputing and distributed computing, 2) specialized hardware computing, and 3) quantum computing (QC). This article presents these computing technologies as they play a major role for the development of RS applications. The HDCRS disseminates information and knowledge through educational events and publication activities which will also be introduced in this article.\n",
      "Mapping of land cover structures using satellite images is often a tedious, manually made task. In contrast, automatic methods are faster and more precise, but have important lacks: incapacity of ignoring unwanted objects and difficulty of working with high resolution images. Data Mining methodology tackles the problem of automatic satellite image segmentation. The proposed method aims at adapting the granularity of image segmentation to the cartographic scales.\n",
      "The Earth Observation processing tools operating in the recent scenario need to be tailored to the new products offered by the sub-meter spatial resolution imaging sensors. The new methods should provide the image analysts the essential automatic support to discover relevant information and identify significant elements in the image. We advocate an automatic technique to select the optimum number features used in classification, object detection and analysis of optical satellite images. Using measures of mutual information between the target classes and the available features, we investigate the criterions of maximum-relevance and maximum-relevance-minimumredundancy for automatic feature selection at very-low cost. Following a comprehensive set of experiments on multiple sensors, applications and classifiers, the results demonstrate the possible operational use of the method in future scenarios of humanmachine interactions in support of Earth Observation technologies.\n",
      "Large arcives of remote sensing data and data mining call for appropriately designed data bases.\n",
      "The article aims at presenting the most recent developments and trends in information extraction from Synthetic Aperture Radar SAR data.\n",
      "The performance of a deep-learning-based model primarily relies on the diversity and size of the training dataset. However, obtaining such a large amount of labeled data for practical remote sensing applications is expensive and labor-intensive. Training protocols have been previously proposed for few-shot learning (FSL) and zero-shot learning (ZSL). However, FSL is not compatible with handling unobserved class data at the inference phase, while ZSL requires many training samples of the seen classes. In this work, we propose a novel training protocol for image retrieval and name it as label-deficit zero-shot learning (LDZSL). We use this novel LDZSL training protocol for the challenging task of cross-sensor data retrieval in remote sensing. This protocol uses very few labeled data samples of the seen classes during training and interprets unobserved class data samples at the inference phase. This strategy is \n",
      "Causality is one of the most important topics in a Machine Learning (ML) research, and it gives insights beyond the dependency of data points. Causality is a very vital concept also for investigating the dynamic surface of our living planet. However, there are not many attempts for integrating a causal model in Remote Sensing (RS) methodologies. Hence, in this paper, we propose to use patch-based RS images and to represent each patch-based image by a single variable (e.g. entropy). Then we use a Structural Equation Model (SEM) to study their cause-effect relation. Moreover, the SEM is a simple causal model characterized by a Directed Acyclic Graph (DAG). Its nodes are causal variables, and its edges represent causal relationships among causal variables if and only if causal variables are dependent.\n",
      "Remotely-sensed images obtained from aircraft and satellite platforms are used for Earth observation tasks. The remotely-sensed images are available in digital format and contain information on the number of spectral bands, radiometric resolution, and spatial resolution. We performed the first exploratory studies for applying quantum computers to remotely-sensed images and problems. Parametrized quantum circuits solve optimization problems and can be utilized as a learning model exploiting different mechanisms and techniques of quantum physics. As a case example, we present therefore the result that parametrized quantum circuits are very competitive in contrast with its classical neural networks.\n",
      "Earth Observation (EO) Data Intelligence is addressing the entire value chain: data processing to extract information, the information analysis to gather knowledge, and knowledge transformation in value. EO technologies have immensely evolved the state of the art sensors deliver a broad variety of images, and have made considerable progress in spatial and radiometric resolution, target acquisition strategies, imaging modes, geographical coverage and data rates. Generally imaging sensors generate an isomorphic representation of the observed scene. This is not the case for EO, the observations are a doppelganger of the scattered field, an indirect signature of the imaged object. EO images are instrument records, i.e. in addition to the spatial information, they are sensing physical parameters, and they are mainly sensing outside of the visual spectrum. This positions the load of EO image understanding, and the outmost challenge of Big EO Data Science, as new and particular challenge of Machine Learning (ML) and Artificial Intelligence (AI). The presentation introduces specific solutions for the EO Data Intelligence, as methods for physically meaningful features extraction to enable high accuracy characterization of any structure in large volumes of EO images. The theoretical background is introduced, discussing the advancement of the paradigms from Bayesian inference, machine learning, and evolving to the methods of Deep Learning and Quantum Machine Learning. The applications are demonstrated for: alleviation of atmospheric effects and retrieval of Sentinel 2 data, enhancing the opportunistic bi-static images with Sentinel 1 \n",
      "<jats:p>&amp;lt;p&amp;gt;For many years, image classification &amp;amp;#8211; mainly based on pixel brightness statistics &amp;amp;#8211; has been among the&amp;lt;br&amp;gt;most popular remote sensing applications. However, during recent years, many users were more and&amp;lt;br&amp;gt;more interested in the application-oriented semantic labelling of remotely sensed image objects being&amp;lt;br&amp;gt;depicted in given images.&amp;lt;br&amp;gt;In parallel, the development of deep learning algorithms has led to several powerful image&amp;lt;br&amp;gt;classification and annotation tools that became popular in the remote sensing community. In most&amp;lt;br&amp;gt;cases, these publicly available tools combine efficient algorithms with expert knowledge and/or&amp;lt;br&amp;gt;external information ingested during an initial training phase, and we often encounter two alternative&amp;lt;br&amp;gt;types of deep learning approaches, namely Autoencoders (AEs) and Convolutional Neural Networks&amp;lt;br&amp;gt;(CNNs). Both approaches try to convert the pixel data of remote sensing images into semantic maps of&amp;lt;br&amp;gt;the imaged areas.&amp;lt;br&amp;gt;In our case, we made an attempt to provide an efficient new semantic annotation tool that helps in&amp;lt;br&amp;gt;the semantic interpretation of newly recorded images with known and/or possibly unknown content.&amp;lt;br&amp;gt;Typical cases are remote sensing images depicting unexpected and hitherto uncharted phenomena&amp;lt;br&amp;gt;such as flooding events or destroyed infrastructure. When we resort to the commonly applied AE or&amp;lt;br&amp;gt;CNN software packages we cannot expect that existing statistics, or a few initial ground-truth&amp;lt;br&amp;gt;annotations made by an image interpreter, will automatically lead to a perfect understanding of the&amp;lt;br&amp;gt;image content. Instead, we have to discover and combine a number of additional relationships that&amp;lt;br&amp;gt;define the actual content of a selected image and many of its characteristics.&amp;lt;br&amp;gt;Our approach consists of a two-stage domain-change approach where we first convert an image into&amp;lt;br&amp;gt;a purely mathematical &amp;amp;#8216;topic representation&amp;amp;#8217; initially introduced by Blei [1]. This representation&amp;lt;br&amp;gt;provides statistics-based topics that do not yet require final application-oriented labelling describing&amp;lt;br&amp;gt;physical categories or phenomena and support the idea of explainable machine learning [2]. Then,&amp;lt;br&amp;gt;during a second stage, we try to derive physical image content categories by exploiting a weighted&amp;lt;br&amp;gt;multi-level neural network approach that converts weighted topics into individual application-oriented&amp;lt;br&amp;gt;labels. This domain-changing learning stage limits label noise and is initially supported by an image&amp;lt;br&amp;gt;interpreter allowing the joint use of pixel statistics and expert knowledge [3]. The activity of the image&amp;lt;br&amp;gt;interpreter can be limited to a few image patches.&amp;lt;br&amp;gt;We tested our approach on a number of different use cases (e.g., polar ice, agriculture, natural&amp;lt;br&amp;gt;disasters) and found that our concept provides promising results.&amp;amp;#160;&amp;amp;#160;&amp;lt;br&amp;gt;[1] D.M. Blei, A.Y. Ng, and M.I. Jordan, (2003). Latent Dirichlet Allocation, Journal of Machine Learning&amp;lt;br&amp;gt;Research, Vol. 3, pp. 993-1022.&amp;lt;br&amp;gt;[2] C. Karmakar, C.O. Dumitru, G. Schwarz, and M. Datcu (2020). Feature-free explainable data mining&amp;lt;br&amp;gt;in SAR images using latent Dirichlet allocation, IEEE Journal of Selected Topics in Applied Earth&amp;lt;br&amp;gt;Observations and Remote Sensing, Vol. 14, pp. 676-689.&amp;lt;br&amp;gt;[3] C.O. Dumitru, G. Schwarz, and M. Datcu (2021). Semantic Labelling of Globally Distributed Urban&amp;lt;br&amp;gt;and Non-Urban Satellite Images Using High-Resolution SAR Data, IEEE Journal of Selected Topics in&amp;lt;br&amp;gt;Applied Earth Observations and Remote Sensing, Vol. 15, pp. 6009-6068.&amp;lt;/p&amp;gt;</jats:p>\n",
      "This paper describes an image validation tool for the generation of good-quality Earth Observation (EO) benchmark datasets. We already developed an active-learning-based semantic annotation tool which allows users to fast annotate images with few samples; this tool reaches about 90% accuracy. A subsequent data cleaning tool then helps correct noisy data, thus increasing the number of correctly labeled images to be qualified as benchmark data. However, this work has an annoying bottleneck, namely the manual correction via visual checks still costs a considerable amount of energy. Therefore, this paper aims to discuss about the label relationships in the embedding space, by proposing new metrics to distinguish four different ambiguous cases within a dataset, based on pattern analysis. The interactive visualization then enables users to visualize a dataset and explore unknown patterns. The benefits are two-fold: firstly, experiments show the proposed metrics greatly help decrease the manual labor whilst keeping the essential data, thus enhancing the degree of automation in the process of generating good-quality benchmark datasets. Secondly, our approach provides possibilities to interactively visualize and explore very large-scale datasets in real time, thus providing help for further data mining.\n",
      "ExtremeEarth is a European H2020 project; it aims at developing analytics techniques and technologies that combine Copernicus satellite data with information and knowledge extraction, and exploiting them on ESAs Food Security and Polar Thematic Exploitation Platforms. The current publication focuses on the Polar case for which a large training dataset has been generated and demonstrates the use of different machine learning/deep learning techniques (e.g., Compression-based pattern recognition, Cascaded learning for semantic labelling, Explainable AI for SAR sea-ice content discovery, Physics-aware deep hybrid architecture). The solution proposed in the project is an active learning approach that represents a simple way to generate semantically annotated datasets from given Sentinel-1/Sentinel-2 images. Active Learning is a form of supervised machine learning in which the learning algorithm is able to interactively query some (human) information source to obtain the desired image classification outputs at new data points. The key idea behind active learning is that a machine learning algorithm (e.g., a Support Vector Machine) can achieve greater accuracy with fewer training labels if its allowed to choose itself among the data from which it learns. In this case, relevance feedback is included; this supports users to search for additional images of interest in a large repository. Further, any new image content classes that do not exist yet can be defined by expert users based on their specific knowledge; however, different users can give different meaning to the new classes. In this case, the number of semantic classes that can be \n",
      "Studying the changes on the Earths surface is always an important research question in remote sensing. Many methods and algorithms have been proposed by researchers to understand the dynamics on regions of Earth using Satellite Image Time Series (SITS), as SITS contain huge amount of information. However, some regions are more challenging because of lack of ground truth data. This contribution presents an explainable machine learning method to produce transparent, trustworthy and interpretable results to understand the dynamics in the Polar region using SAR Sentinel-1 SITS. We propose an explainable artificial intelligence approach to discover the hidden information about the surface cover dynamics over the 2018 and 2019. Visualizations are produced to support explainability of the results. The specific objectives are, to create semantic labels for 24 study months (one image for each month of the selected period) by forwarding some limited amount of domain knowledge, and then to analyze the time series evolution based on these semantic labels. The domain knowledge used in classification consists of a labeled dataset from an Active Learning research activity [1], and knowledge about the mutual closeness of the surface cover classes from another research project [2]. We semantically labeled the images acquired over 24 months of study and each image is tiled into 6,400 patches of size 256256 pixels, giving a total of 153,600 patches. We retrieve 8 semantic classes as: Black border, Glaciers, Icebergs, Mountains, Old ice, First year ice, Young ice, and Water group. The class Water group combines 4 close classes that \n",
      "The rapid monitoring of icebergs potentially crossing arctic shipping routes as well as long-term climate research issues have already led to several attempts to exploit the content of Synthetic Aperture Radar (SAR) satellite images. The European Sentinel-1 mission with its twin satellites allows free and rapid access to its carefully processed image data. As a consequence, the EU-funded research project ExtremeEarth has designed and implemented several highly automated and innovative explainable machine learning and deep neural network algorithms allowing us to train and operate an automated sea-ice monitoring system. In this respect, we analyse its most important innovative aspects and compare it with other approaches that have been developed by various nations. But first of all, in order to verify and implement efficient and innovative methods, we need sufficient datasets with high quality. Here in this contribution, we will present an efficient and very accurate routine based on active learning being able to generate sea-ice datasets annotated by several human experts providing their detailed knowledge with respect to local semantic image classification. Our selected target area is located near the North Pole, in the East part of Greenland. This part of Greenland is called Belgica Bank and was affected by a global warming effect between 2018 and 2019, when a high volume of ice was melted or transformed into water. For demonstration, we selected 36 images (one image per month acquired in 2018, 2019, and 2020) out of 183 available images for this area acquired by Sentinel-1A and Sentinel-1B. The Sentinel-1A/B images were tiled \n",
      "<jats:p>Abstract. When we want to extract knowledge form satellite images, several well-known image classification and analysis techniques can be concatenated or combined to gain a more detailed target understanding. In our case, we concentrated on specific extended target areas such as polar ice-covered surfaces, forests shrouded by fire plumes, flooded areas, and shorelines. These image types can be described by characteristic features and statistical relationships. Here, we demonstrate that both multispectral (optical) as well as SAR (Synthetic Aperture Radar) images can be used for knowledge extraction. The free availability of image data provided by the European Sentinel-1 and Sentinel-2 satellites allowed us to conduct a series of experiments that verified our classification approaches. This could already be verified in our recent work by quantitative quality tests.                    </jats:p>\n",
      "Urban mapping from remote sensing images is important for monitoring urbanization. In this paper, we propose an unsupervised learning algorithm for high-resolution single-polarized synthetic aperture radar (SAR) image to extract man-made targets for urban area analysis. The proposed method mainly focuses on the special physical characteristics of man-made targets that are different from natural areas. Without polarimetric information, we propose the sub-band scattering pattern based on time-frequency analysis to describe the physical properties of targets, and then design an end-to-end neural network to learn the latent features and potential clusters. The proposed method is evaluated on three different urban areas acquired at C-band by Sentinel-1 and Gaofen-3, and X-band by TerraSAR-X, respectively. The experiments present the visualized result of man-made targets extraction and analyze some \n",
      "Earth Observation Big Data Challenges: the AI change of paradigm The volume and variety of valuable Earth Observation (EO) images as well as non-EO related data is rapidly growing. The deluge of EO images of Terabytes per day needs to be converted into meaningful information, largely impacting the socio-economic-environmental triangle. An important particularity of EO images should be considered, is their instrument nature, i.e. in addition to the spatial information, they are sensing physical parameters, and they are mainly sensing outside of the visual spectrum. Machine and deep learning methods are mainly used for image classification or objects segmentation, EO require hybrid AI methods encompassing from mathematical models for the satellite orbit, the physics of electromagnetic propagation and scattering, signal processing, machine learning, or knowledge representation. The new specific AI methods for EO are designed to leverage advances in physical parameters extraction.\n",
      "Our objectives are to employ the current methodologies and achievements made in emergent Quantum Computing to real-world problems in Earth observation; in particular, to enlarge and to broaden Earth Observation methodologies by using a D-Wave quantum annealer and a gate-based quantum computer.\n",
      "electronic library - Artificial Intelligence for Satellite Image Time Series elib DLR-Header DLR-Logo -> http://www.dlr.de DLR Portal Home | Impressum | Datenschutz | Kontakt | English Schriftgroße: [-] Text [+] Erweiterte Suche Versenden Drucken Artificial Intelligence for Satellite Image Time Series Datcu, Mihai (2020) Artificial Intelligence for Satellite Image Time Series. Seminar on Satellite Image Time Series (in the frame of Blaise Pascal International Chair), 23.01.2020, Paris. Dieses Archiv kann nicht den Volltext zur Verfugung stellen. elib-URL des Eintrags: https://elib.dlr.de/138277/ Dokumentart: Konferenzbeitrag (Vorlesung) Titel: Artificial Intelligence for Satellite Image Time Series Autoren: Autoren Institution oder E-Mail-Adresse Autoren-ORCID-iD Datcu, Mihai Mihai.Datcu (at) dlr.de NICHT SPEZIFIZIERT Datum: 2020 Referierte Publikation: Nein Open Access: Ja Gold Open Access: Nein In SCOPUS: Nein In \n",
      "During the last years, we have already seen a number of attempts to use Latent Dirichlet Allocation (LDA) for local image patch classification. We can demonstrate that the reliability of these conventional labelling techniques can still be improved by more meaningful and robust label definitions derived from scene-dependent appropriate combinations of Latent Dirichlet Allocation topics for each label. This is a practical and innovative alternative to sometimes more complicated multi-labels that have been proposed by other authors. Another decided advantage of this adaptive strategy is that we can maximize the identification and discrimination capabilities of satellite image classifiers, in particular for multi-band imagery as provided by typical modern optical or radar instruments. The resulting semantic categories that we expect as classification results fulfill our initial expectations as we can exploit the full information content of the given data. We will describe how freely available and well-calibrated data of the European Sentinel-1 and Sentinel-2 satellite missions can be transformed into semantic content maps. In our case, we concentrate on remote sensing images depicting recent volcano eruptions, forest fires, floods, and ice loss in glaciers/icebergs, and on dedicated optimizations of numerical Latent Dirichlet Allocation parameters. Our results demonstrate that optimized Latent Dirichlet Allocation represents an interesting alternative to many other image classification techniques.\n",
      "Although artificial intelligence methods have achieved notable success in many sectors, there is an increasing demand towards explainability and trustworthiness of these methods. Currently, machine learning models such as deep learning are opaque, such opacity introduced by sub-symbolism. We attempt to explore explainable machine learning methods in understanding Earth observation data. Recently, there have been efforts towards explaining machine learning (X-ML) models, contributing to the paradigm of eXplainable Artificial Intelligence(XAI). The important conceptual propositions X-ML are interpretability, transparency and explainability. Here, we propose an explainable data mining approach based on Latent Dirichlet Allocation (LDA) which supports the idea of transparency, interpretability and explainability. Informally, transparency is the ability to understand the mechanism of each component of a method. Researchers delineate three levels of transparency: design transparency, algorithmic transparency and model transparency. Design transparency is concerned with clear logic behind design decision such as model parameters. Algorithmic transparency is the ability to understand how the algorithm works from a mathematical point of view. A model is called algorithmically transparent if input-out relation and the process can be written down as mathematical formula. Model transparency ensures traceability of the outcomes. We demonstrate of adherence of each step of our 5-step method to design, model and algorithmic transparency. The second aspect of explainable machine learning is interpretability, which is nothing but \n",
      "When we want to classify different ice cover types in thematic maps based on satellite images, we can directly start with the publicly available image products of the European Sentinel-1 and Sentinel-2 missions and include some appropriate classification algorithm. In our case, we are mainly interested in cartographic ice maps generated from selected single images as well as time series of overlapping ice cover images of the Arctic region that can be derived either from polarized synthetic aperture radar images (in case of Sentinel-1) or from multispectral optical images (in case of Sentinel-2 that includes infrared bands). Therefore, in the following, we will concentrate on the selection of appropriate classification algorithms, where the goal of our ice cover analysis is the routine generation of multi-class thematic maps that can be used for the analysis of snow and ice cover phenomena, and for the monitoring of shipping routes. In both cases, we have to interpret large-scale target areas with discernible brightness levels and neighborhood contrast for cold (fresh) or melting (old) ice, snow cover, seawater and local water leads, ships, coastlines, and icebergs.\n",
      "The Polar Use Case in ExtremeEarth aims to address these issues through the development of a range of valuable tools. Deep learning algorithms will be developed to extract valuable sea ice and iceberg information from the ever increasing volumes of data collected by the Copernicus Sentinel satellite constellations. These new algorithms will be implemented on the Polar Thematic Exploitation Platform (Polar TEP) providing processing resources to produce the new information products. New data sets will be released for training and validating the new algorithms. Linked data tools will extend the capabilities for data access and discovery with semantic catalogue services that scale to the volumes of big data produced in the project. Frontend services, such as the PolarTEP and the Norwegian Meteorological Institute ice charts, will provide simple user access to browse and query the data generated.\n",
      "Satellite remote sensing is the only global and continuous Earth Observation (EO) system. In the present context of unprecedented and rapid climate changes EO plays the central role in understanding the planetary scale phenomena. The analysis of the Big EO Data poses many challenges and the solutions are presently mainly based on the advances in Artificial Intelligence (AI). The presentation overviews and analyses specific AI methods for EO data, beginning with the generation of training data sets, data base biases analysis, explainable machine and deep learning paradigms for high complexity phenomena understanding. Selected examples are presented for coastline and polar sea-ice monitoring.\n",
      "Satellites are the only global Earth Observation (EO) data source. The field of EO is presently at a key turning point, EO Big Data are now freely and openly accessible, the areas of Artificial Intelligence (AI) are explosively progressing and the computational and communication capacities are immense. This context and trends bring the AI paradigms and EO methodologies and applications in a new era. The theoretical and technological progress is amplifying the use of the EO broadening the impact in all major domains, climate, food security, urbanization, only to enumerate few. The presentation is an overview of the achievements in the frame of the International Blaise Pascal Chair of Excellence for EO Data Science in these areas, concluding with a vision of the AI4EO domains.\n",
      "The implicit data models and the expected parameters on which they are dependent may introduce biases in the Earth Observation (EO) data analysis methodologies. The estimated parameters can describe only particular, limited observations behavior. The broad diversity of the EO data, as sensing modalities, spatial, spectral, and radiometric resolution, and also the huge variety of the observed scenes make problematic the definition of a general model. The lecture presents a communication channel approach for image information extraction. The information retrieval is elaborated based on data compression methods independent of the type, form, content or purpose of the data. This paradigm is common to any data type without the weakening effect of specializing it for specific, particular applications fields. This is realized by approaching these challenges from an Information Theoretic perspective and using also the latest progress in Algorithmic Information Theory. The objective is re-formulating the definition of the relevant information in relation to the notions of image content and context, for a broader class of data, including scientific and engineering instruments records.\n",
      "Today we are faced with impressive progress in machine learning and artificial intelligence. This not only applies to autonomous driving for car manufacturers but also to Earth observation, where we need reliable and efficient techniques for the automated analysis and understanding of remote sensing data. While automated classification of satellite images dates back more than 50 years, many recently published deep learning concepts aim at still more reliable and user-oriented image analysis tools. On the other hand, we should also be continuously interested in innovative data analysis approaches that have not yet reached widespread use. We demonstrate how established applications and tools for image classification and change detection can profit from advanced information theory together with automated quality control strategies. As a typical example, we deal with the task of coastline detection in satellite \n",
      "This chapter describes a Copernicus Access Platform Intermediate Layers Small-Scale Demonstrator, which is a general platform for the handling, analysis, and interpretation of Earth observation satellite images, mainly exploiting big data of the European Copernicus Programme by artificial intelligence (AI) methods. From 2020, the platform will be applied at a regional and national level to various use cases such as urban expansion, forest health, and natural disasters. Its workflows allow the selection of satellite images from data archives, the extraction of useful information from the metadata, the generation of descriptors for each individual image, the ingestion of image and descriptor data into a common database, the assignment of semantic content labels to image patches, and the possibility to search and to retrieve similar content-related image patches. The main two components, namely, data mining and data fusion, are detailed and validated. The most important contributions of this chapter are the integration of these two components with a Copernicus platform on top of the European DIAS system, for the purpose of large-scale Earth observation image annotation, and the measurement of the clustering and classification performances of various Copernicus Sentinel and third-party mission data. The average classification accuracy is ranging from 80 to 95% depending on the type of images.\n",
      "electronic library - Quantum resources for EO technology elib DLR-Header DLR-Logo -> http://www.dlr.de DLR Portal Home | Impressum | Datenschutz | Kontakt | English Schriftgroße: [-] Text [+] Erweiterte Suche Versenden Drucken Quantum resources for EO technology Datcu, Mihai (2019) Quantum resources for EO technology. Quantum for Earth Observation, ESA & COST Action QTSPace (CA15220), 3 April 2019, Rome, Italy. Dieses Archiv kann nicht den Volltext zur Verfugung stellen. Offizielle URL: http://esamultimedia.esa.int elib-URL des Eintrags: https://elib.dlr.de/130892/ Dokumentart: Konferenzbeitrag (Vorlesung) Titel: Quantum resources for EO technology Autoren: Autoren Institution oder E-Mail-Adresse Autoren-ORCID-iD Datcu, Mihai Mihai.Datcu (at) dlr.de NICHT SPEZIFIZIERT Datum: April 2019 Referierte Publikation: Nein Open Access: Nein Gold Open Access: Nein In SCOPUS: Nein In ISI Web of \n",
      "electronic library - CANDELA architecture for Data Mining and Data Fusion: a DIAS contribution elib DLR-Header DLR-Logo -> http://www.dlr.de DLR Portal Home | Impressum | Datenschutz | Kontakt | English Schriftgroße: [-] Text [+] Erweiterte Suche Versenden Drucken CANDELA architecture for Data Mining and Data Fusion: a DIAS contribution Yao, Wei und Dumitru, Corneliu Octavian und Datcu, Mihai und Rolland, J-Francoise und Castel, Fabien und Lorenzo, Jose (2019) CANDELA architecture for Data Mining and Data Fusion: a DIAS contribution. Neue Perspektiven der Erdbeobachtung Symposium, 12.-13. Nov. 2019, Cologne, Germany. Dieses Archiv kann nicht den Volltext zur Verfugung stellen. Offizielle URL: https://www.dialogplattform-erdbeobachtung.de/cms/programm elib-URL des Eintrags: https://elib.dlr.de/131723/ Dokumentart: Konferenzbeitrag (Vortrag) Titel: CANDELA architecture for \n",
      "electronic library - Methods and Algorithms for Feature Extraction and Semantic Analysis of Very High Resolution Polarimetric Synthetic Aperture Radar Images elib DLR-Header DLR-Logo -> http://www.dlr.de DLR Portal Home | Impressum | Datenschutz | Kontakt | English Schriftgroße: [-] Text [+] Erweiterte Suche Versenden Drucken Methods and Algorithms for Feature Extraction and Semantic Analysis of Very High Resolution Polarimetric Synthetic Aperture Radar Images Tanase, Radu und Datcu, Mihai (2017) Methods and Algorithms for Feature Extraction and Semantic Analysis of Very High Resolution Polarimetric Synthetic Aperture Radar Images. World Cover 2017, 14.-16. Marz 2017, Frascati, Italien. Dieses Archiv kann nicht den Volltext zur Verfugung stellen. Offizielle URL: http://worldcover2017.esa.int/ elib-URL des Eintrags: https://elib.dlr.de/118555/ Dokumentart: Konferenzbeitrag (Poster) Titel: Methods \n",
      "Large volume of detailed features of land covers, provided by High-Resolution Earth Observation (EO) images, has attracted the interests to assess the discovery of these features by Content-Based Image Retrieval systems. In this paper, we perform Latent Dirichlet Allocation (LDA) on the Bag-of-Words (BoW) representation of collections of EO images to discover their high-level features, so-called topics. To assess the discovered topics, the images are represented based on the occurrence of different topics, we name it Bag-of-Topics (BoT). Then, the BoT model is compared to the BoW model of images based on the given human-annotations of the data. In our experiments, we compare the classification accuracy resulted by BoT and BoW representations of two different EO datasets, a Synthetic Aperture Radar (SAR) dataset and a multi-spectral satellite dataset. Moreover, we provide isualizations of feature space for better perceiving the changes in the discovered information by BoT and BoW models. Experimental results demonstrate that the dimensionality of the data can be reduced by BoT representation of images; while it either causes no significant reduction in the classification accuracy or even increase the accuracy by sufficient number of topics.\n",
      "In this paper, we evaluate sample selection strategies based on optimum experimental design for SAR image classification. Traditionally, support vector machine active learning is widely used by selecting the samples close to the decision surface. Recently, new methods based on optimum experimental design have been developed. To gain a complete understanding of these selection strategies, a comparative study on three approaches, transductive experimental design, manifold adaptive experimental design and locally linear reconstruction, has been performed for SAR image classification using different features. Among the three approaches,we show that manifold adaptive experimental design performs best and stably in terms of both accuracy and computational complexity.\n",
      "Efficient long term monitoring of critical infrastructure is a difficult task, due to the presence of decorrelation artifacts, especially in non-urban areas. This tends to be an important drawback, given the errors that appear during the unwrapping phase, leading to unreliable deformation maps. The minimization of the artifacts influence is performed by enhancing the phase estimate using a spatially adaptive multi-looking algorithm. Subsequently, a deformation estimation of linear motions is performed using a stacking-based approach. Results are presented on a database of 32 SLC SM TerraSAR-X images acquired over the area of Bucharest, Romania.\n",
      "electronic library - The Big Data Challenge: Handling Large Volumes of Earth Observation Data - the EOLIB Project elib DLR-Header DLR-Logo -> http://www.dlr.de DLR Portal Home | Impressum | Datenschutz | Kontakt | English Schriftgroße: [-] Text [+] Erweiterte Suche Versenden Drucken The Big Data Challenge: Handling Large Volumes of Earth Observation Data - the EOLIB Project Datcu, Mihai (2013) The Big Data Challenge: Handling Large Volumes of Earth Observation Data - the EOLIB Project. In: Proceeding of 2nd IAA Conference on Space Systems as Critical Infrastructure. Copernicus Conference, 21.-22. May 2013, Bucharest, Romania. Dieses Archiv kann nicht den Volltext zur Verfugung stellen. Offizielle URL: http://www.enveurope.eu/misc/meetings-agendas/GMESConferenceBucharestFinalProgramme.pdf elib-URL des Eintrags: https://elib.dlr.de/89033/ Dokumentart: Konferenzbeitrag (Vortrag) Titel: \n",
      "The volume of Earth Observation data is increasing immensely in order of several Terabytes a day. Therefore, to explore and investigate the content of this huge amount of data, developing more sophisticated Content-Based Information Retrieval (CBIR) systems are highly demanded. These systems should be able to not only discover unknown structures behind the data, but also provide relevant results to the users queries. Since in any retrieval system the images are processed based on a discrete set of their features (i.e., feature descriptors), study and assessment of the structure of feature space, build by different feature descriptors, is of high importance. In this paper, we introduce a clustering-based approach to study the content of image collections. In our approach, we claim that using both internal and external evaluation of clusters for different feature descriptors, helps to understand the structure of feature space. Moreover, the semantic understanding of users about the images also can be assessed. To validate the performance of our approach, we used an annotated Synthetic Aperture Radar (SAR) image collection. Quantitative results besides the visualization of feature space demonstrate the applicability of our approach.\n",
      "Efficient management and exploration of high-volume scientific file repositories have become pivotal for advancement in science. We propose to demonstrate the Data Vault, an extension of the database system architecture that transparently opens scientific file repositories for efficient in-database processing and exploration. The Data Vault facilitates science data analysis using high-level declarative languages, such as the traditional SQL and the novel array-oriented SciQL. Data of interest are loaded from the attached repository in a just-in-time manner without need for up-front data ingestion. The demo is built around concrete implementations of the Data Vault for two scientific use cases: seismic time series and Earth observation images. The seismic Data Vault uses the queries submitted by the audience to illustrate the internals of Data Vault functioning by revealing the mechanisms of dynamic query plan generation and on-demand external data ingestion. The image Data Vault shows an application view from the perspective of data mining researchers.\n",
      "Permanent Scatterer Interferometry (PSInSAR) leads to the formation of networks of targets with a stable behavior in time, used to overcome decorrelation phenomena induced by long revisiting periods of the same area. This technique has been mainly used for the computation of deformation time series in the form of displacement maps. However, the results depend on the quality of the permanent scatterers (PS) extraction methods and on each individual data set. We select the PS candidates from a set of co-registered SLC products using the spectral behavior of stable points, that significantly differs from the one exhibited by distributed targets. We perform a classification of the parameters used for the extraction process, such as the number of acquisitions and decision thresholds (window sizes, SNR threshold etc.). Apart from analyzing the implication of traditional error sources, such as APS and baseline values, PS with anomalous behavior will be identified, isolated and monitored for the duration of the different time series. Causes for the apparition of false detected targets will be studied, based on the amplitude analysis and an in-depth study of each individual scenery. In order to ensure scenario diversity for the validation of the results, three data sets are being analyzed. The data consist of TerraSAR-X StripMap images taken over urban regions from Bucharest (32 images), Valencia (8 images) and San Francisco (7 images) in the frame of MTH1628, MTH0302 and MTH1118 proposals.\n",
      "Image analysis results depend on the model order and the size of analysis windows being employed.\n",
      "Based on experience and components developed in national projects as for example components for land cover and land use monitoring, ROKEO is intended to facilitate knowledge based and interactive learning as a semantic information extraction processes.\n",
      "Kein Folientitel Page 1 DLR Oberpfaffenhofen mihai.datcu@dlr.de Competence Centre on Information Extraction an d Image Understanding for Earth Observation a) b) c) d) Hierarchical Image Clustering (tile-based approach) Sichuan, China (2008 earthquake area): a) despeckled image, b) vegetation, c) large buildings; Classification by a semantic search engine provides target classes. Modeling and Parameter Estimation of TerraSAR-X Images for Scene Classification and Recognition Mihai Datcu(1,2), Daniele Cerra(1), Houda Chaabouni-Chouayakh(1), Daniela Espinoza Molina(1), Amaia de Miguel(1), Fernando Rodriguez Gonzalez(1), Gottfried Schwarz(1), Matteo Soccorsi(1), (1)German Aerospace Center (DLR), Oberpfaffenhofen, 82234 Weßling, Germany (2)Telecom ParisTech, 46 rue Barrault, 75013 Paris, France Advanced despeckling methods allow us to reduce the speckle noise, while preserving local \n",
      "We present adfvanced concepts how a search engine for a satellite image database can be designed.\n",
      "Image information mining is now faced with high resolution data. This opens new opportunities in this field.\n",
      "The diagnose methods based on medical images are constantly expanding. The need for easily accessed databases deals with more and more problems, due to the fact that the medical information must be retrieved no matter which technical method was used to acquire the image. The queried information must be also achieved for any imaging orientation, for different body regions, considering the analyzed biological system. In our study we have applied a Content-Based Image Retrieval (CBIR) system, implemented for earth observation images, to archive and to administrate a medical database consisting of dental X-ray and dermatological images.\n",
      "We give a survey of promising algorithms for the handling of information extraction for satellite-based disaster monitoring\n",
      "I. INTRODUCTION The process of searching and analyzing data in order to discover potentially useful information is a crucial matter when dealing with large databases. Considering the huge amount of data collected by satellite observation systems, opportunities to generate multispectral image time-series are increasing. Exploratory methods are needed to understand the dynamics of Earth observation scenes and of their objects. In this paper, information mining methods are proposed. They first rely on a hierarchical model based information representation. Entropic measurement similarity in a modeled dynamic feature space characterizing the dynamics of objects and of image structures are then researched.\n",
      "The recognition and classification of urban structures from SAR observations is a particularly complex task. In this article we present a new concept aiming at the accurate and detailed classification of the city scenes observed with metric resolution SAR sensors.\n",
      "We present an intelligent satellite information mining system, a next generation architecture to help a user to rapidly gather information about courses of action, a tool to add value and to manage the huge amounts of historical and newly acquired satellite data-sets by giving to experts access to relevant information in an understandable and directly usable form and to provide friendly interfaces for information query and browsing. In a remote sensing image archive the data access by geographical position, time of acquisition or type of sensor is often less important than what is the content of the scene, ie structures, objects, scattering properties. Interesting applications involve complicated spatial and structural relationships among image objects.\n",
      "In this paper we present a multi-level scheme for stochastic description of image content. The different levels are derived from the different degrees of abstraction. On the level of the image data, we use stochastic data models and Bayesian parameter estimation to derive low-level image features. On the next level, we derive meta features that provide both the fit of these models and the actual complexity of the data. The low-level and meta features are combined in an un-supervised clustering scheme to obtain an objective description of the image content. To obtain this objective description we use clustering by melting. The descriptions by several models are then linked to application-oriented, semantic labels using another process of Bayesian inference. We sketch in detail the various processes of inference and give an example for this kind of information on each level of abstraction using satellite images (RESURS-01 and X-SAR).\n",
      "electronic library - Advanced Image Compresssion: Specific Topics for Space Applications, DSP `98, Noordwijk, 1998 elib DLR-Header DLR-Logo -> http://www.dlr.de DLR Portal Home | Impressum | Datenschutz | Kontakt | English Schriftgroße: [-] Text [+] Erweiterte Suche Versenden Drucken Advanced Image Compresssion: Specific Topics for Space Applications, DSP `98, Noordwijk, 1998 Datcu, Mihai und Schwarz, Gottfried (1998) Advanced Image Compresssion: Specific Topics for Space Applications, DSP `98, Noordwijk, 1998. In: Specific Topics for Space Applications,, Conf. Proc.,. Noordwijk-The Netherlands, 1998. Dieses Archiv kann nicht den Volltext zur Verfugung stellen. elib-URL des Eintrags: https://elib.dlr.de/171/ Dokumentart: Konferenzbeitrag (Paper) Zusatzliche Informationen: LIDO-Berichtsjahr=1999, Titel: Advanced Image Compresssion: Specific Topics for Space Applications, DSP `98, Noordwijk, \n",
      "electronic library - Wavelets - ein neues leistungsfahiges Werkzeug fur die Verarbeitungvon Bilddaten in der Fernerkundung elib DLR-Header DLR-Logo -> http://www.dlr.de DLR Portal Home | Impressum | Datenschutz | Kontakt | English Schriftgroße: [-] Text [+] Erweiterte Suche Versenden Drucken Wavelets - ein neues leistungsfahiges Werkzeug fur die Verarbeitungvon Bilddaten in der Fernerkundung Schwarz, Gottfried und Datcu, Mihai (1997) Wavelets - ein neues leistungsfahiges Werkzeug fur die Verarbeitungvon Bilddaten in der Fernerkundung. PFG Photogrammetrie, Fernerkundung, Geoinformation, 97 (3), Seiten 189-202. Dieses Archiv kann nicht den Volltext zur Verfugung stellen. elib-URL des Eintrags: https://elib.dlr.de/23933/ Dokumentart: Zeitschriftenbeitrag Zusatzliche Informationen: LIDO-Berichtsjahr=1997, Titel: Wavelets - ein neues leistungsfahiges Werkzeug fur die Verarbeitungvon Bilddaten in \n",
      "electronic library - Advanced Query and Retrieval Techniques for Remote Sensing Image Data Bases - Project description. elib DLR-Header DLR-Logo -> http://www.dlr.de DLR Portal Home | Impressum | Datenschutz | Kontakt | English Schriftgroße: [-] Text [+] Erweiterte Suche Versenden Drucken Advanced Query and Retrieval Techniques for Remote Sensing Image Data Bases - Project description. Seidel, Klaus und Therre, J.-P. und Datcu, Mihai (1996) Advanced Query and Retrieval Techniques for Remote Sensing Image Data Bases - Project description. In: http://www.vision.ethz.ch. http://www.vision.ethz.ch. Dieses Archiv kann nicht den Volltext zur Verfugung stellen. elib-URL des Eintrags: https://elib.dlr.de/23831/ Dokumentart: Konferenzbeitrag (Paper) Zusatzliche Informationen: LIDO-Berichtsjahr=1996, Titel: Advanced Query and Retrieval Techniques for Remote Sensing Image Data Bases - Project \n",
      "Ce papier propose une methode de detection danomalies pour limagerie SAR basee sur lapprentissage profond. Elle ne necessite pas de verite terrain des anomalies, ce qui repond a un probleme recurrent en teledetection: le manque de donnees annotees pour entrainer les reseaux de neurones. Le modele propose combine un adversarial autoencoder suivi dun detecteur statistique de changement base sur la matrice de covariance. Une etape de despeckling est prealablement effectuee, ce qui permet de filtrer le bruit de speckle et dameliorer significativement les performances de detection. AbstractThis paper proposes an anomaly detection method for SAR imagery based on deep learning. It does not require ground truth of anomalies, which addresses a recurrent problem in remote sensing: the lack of labeled data to train neural networks. The proposed model combines an adversarial autoencoder followed by a statistical change detector based on the covariance matrix. A despeckling step is first performed, which allows to filter the speckle noise and to significantly improve the detection performances.\n",
      "One of the most challenging problems regarding Earth Observation data of very high spatial resolution (< 10cm) is related to the construction of an accurate and fully-automatic semantic annotation workflow approach. The difficulty of this task is related to the increased intra-class variability and complexity of the depicted aerial urban scenes. Lately, interesting methods based on fully Convolutional Neural Networks have shown great potential for resolving this challenging problem. However, despite the overall accuracy of these methods, a precise localization of the classcontours still remains an unresolved issue, mainly due to the uncertainty of precisely localizing the class-boundary between two neighboring land-cover entities. In this paper, we propose learning the Class-Contours directly from the raw images by training a CNN regression model. This allows us get sharper, better localized edges by learning strong priors of particular object classes and enforce local smoothness. This visually improves class boundaries significantly and we improve our previously best-stated outcome from 85.1% to 88.8% overall accuracy.\n",
      "Table of Contents Page 1 JUNE 2017 VOLUME 10 NUMBER 6 IJSTHZ (ISSN 1939-1404) SPECIAL ISSUE ON THE 2016 IEEE INTERNATIONAL GEOSCIENCE AND REMOTE SENSING SYMPOSIUM Foreword to the Special Issue on the 2016 IEEE International Geoscience and Remote Sensing Symposium . . . . . . . . . . .. 2428 Sensing Platforms Simulation Study of Geometric Characteristics and Coverage for Moon-Based Earth Observation in the Electro-Optical Region . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .Y. Ren, H. Guo, G. Liu, and H. Ye 2431 Potential Applications of Small Satellite Microwave Observations for Monitoring and Predicting Global Fast-Evolving Weathers . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . Y. Ma, X. Zou, and F. Weng 2441 Computational Infrastructure Parallel Implementation of a Full Hyperspectral Unmixing Chain \n",
      "2006 IEEE International Sensing Symposium Geoscience and Remote - Table of contents Page 1 vii IGARSS 2006  TABLE OF CONTENTS A Self-Organizing Map Framework for Detection of Man-Made Structures and Changes in Satellite Imagery .........................................1 A Simple and Efficient Feature Extraction Algorithm for Geophysical Phenomena ...................................................................................5 R. Ramachandran, X. Li, S. Movva, S. Graves Coalescing ICA and Wavelets Coefficients for Image Information Mining in Earth Observation Data Archives........................................9 VP Shah, SS Durbha, NH Younan, RL King Categorization based Relevance Feedback Search Engine for Earth Observation Images Repositories...............................................13 M. Costache, H. Maitre, M. Datcu Knowledge Discovery by Mining Association Rules and Temporal-Spatial Information from Large-Scale Geospatial Image Databases .......\n",
      "Table of Contents Page 1 MARCH 2016 VOLUME 9 NUMBER 3 IJSTHZ (ISSN 1939-1404) SPECIAL ISSUE ON SYNTHETIC APERTURE RADAR (SAR)NEW TECHNIQUES, MISSIONS AND APPLICATIONS Foreword to the Special Issue on Synthetic Aperture Radar (SAR)New Techniques, Missions and Applications . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . G. Krieger, A. Moreira, M. Zink, M. Shimada, and S. Hensley 967 An Airborne Radar Sensor for Maritime and Ground Surveillance and ReconnaissanceAlgorithmic Issues and Exemplary Results . . . . . . . . . . . . . . . . . . M. Kirscht, J. Mietzner, B. Bickert, A. Dallinger, J. Hippler, J. Meyer-Hilberg, R. Zahn, and J. Boukamp 971 Multichannel Wideband Synthetic Aperture Radar for Ice Sheet Remote Sensing: Development and the First Deployment in Antarctica . . . . . . Z. Wang, S. Gogineni, F. Rodriguez-Morales, J.-B. Yan, J. Paden, C. \n",
      "Despite the state-of-the-art performance of the deep learning methods for Synthetic Aperture Radar (SAR) data classification, the Real-Valued (RV) networks neglect the phase component of the Complex-Valued (CV) SAR data and lose a lot of useful information. CV deep architectures have been developed in the recent years to exploit the amplitude and phase components of the CV data, in different fields. However, the superiority of CV models over RV models are proved to be different for each application, and more investigation into the advantages and disadvantages of implementing CV models for SAR data classification is necessary. In this study, the performance of the CV Convolutional Neural Network (CV-CNN) for Polarimetric SAR (PolSAR) data classification is compared with its RV equivalent network, in different contexts.\n",
      "The spectral characteristics of single-look complex-inter-ferometric wide (SLC-IW) swath, terrain observation by progressive scan (TOPS), are significantly different from those of strip-map (SM). Due to the burst mode and series of sub-swaths, the target area is scanned for a short period of time. Therefore, swath width comes at the expense of azimuth resolution. To eliminate quadratic phase drift and achieve SLC baseband, significant processing is required. De-ramping is a necessary step to compute ocean circulation parameters. In this work, we extract ocean parameters from the complex echo signal based on data driven Doppler centroid (f-DC) regardless of the OCN product information and geophysical f-DC image. The radial surface velocity (RSV) is retrieved from Doppler history, and the significant wave height (SWH) is estimated with an empirical relationship of RSV. The results of ocean circulation parameters are promising when compared with benchmark and in-situ data. This work demonstrates the efficacy and necessity of de-ramping the TOPS data for subsequent use in a variety of ocean remote sensing applications.\n",
      "The Normalized Difference Vegetation Index (NDVI) is an important factor to be considered in vegetation tracking and analysis, which can be easily derived from multispectral (MS) images. However, the limitation imposed by the atmospheric conditions makes the calculation of this index difficult. Because of the clouds, only a limited number of multispectral bands can capture the land appropriately. Furthermore, the multispectral sensors are dependent on the sunlight, which makes the acquisition of data more limited. These limitations do not hinder other types of Earth Observation (EO) data, like the scenes captured by the Synthetic Aperture Radar (SAR). However, SAR images cannot be used in NDVI calculation. In this article, we propose a deep learning (DL) based method for NDVI estimation from SAR data. Using a database with corresponding MS and SAR patches, we calculate the NDVI for each sample, then use a convolutional neural network (CNN) for predicting the NDVI of SAR images. This simple method leads to a precision of 70% in NDVI estimation from SAR images.\n",
      "The Sentinel-1 SAR images acquired using the TOPSAR modes i.e., IW and EW on cross-polarization are significantly affected by the thermal noise on low-back-scattering areas. For example, in the arctic and some desert zones both inter-swath and inter-burst noise amplification occurs. In this paper we propose a workflow for removing the thermal noise from Sentinel-1 ground detected SAR images on low back-scattering conditions by employing the co-polarization SAR image and the Gaussian Process Regression. Our processing flow uses the noise vectors provided in the European Space Agency (ESA) ground detected product and scales them such that a slightly over-denoised image is produced. Then, the Gaussian Process Regression is used to map the co-polarization SAR image into the cross-polarization SAR image. Prior to this step, a radiometric correction is applied on the co-polarization data, since its pixel values are heavily dependent on the incidence angle. Finally, the denoised cross-polarization image is obtained as a linear combination between the over-denoised version and the predicted image. Since, the co-polarization channel is employed for the prediction of the missing values in the cross-polarization channel there is no need for co-registration and the de noising procedure is trustworthy.\n",
      "Quantum machine learning (QML) networks promise to have quantum advantage for classifying supervised datasets over some conventional deep learning (DL) techniques due to its expressive power via local effective dimension. There are, however, two main challenges regardless of promised quantum advantage of QML networks: 1) Currently available quantum bits (qubits) are very small in number while real-world datasets are characterized by hundreds of large-scale elements (features). Additionally, there is not a single unified approach for embedding real-world large-scale datasets in limited qubits. 2) Some real-world datasets are very small for training QML networks. Hence, to tackle these two challenges for benchmarking and validating QML networks on real-world, small, and large-scale datasets in one-go, we employ quantum transfer learning composed a multi-qubit QML network and very deep convolutional network (VGG16) extracting informative features from any small, large-scale dataset. We use real amplitudes and strong entangling N-layer QML networks with and without data re-uploading layers as a multi-qubit QML network and evaluate their expressive power quantified by using local effective dimension; the lower local effective dimension of a QML network is, the better its performance on unseen data is. Our numerical result shows that the strong entangling N-layer QML network has lower local effective dimension than the real amplitudes QML network and outperforms it and classical transfer learning on the hard-to-classify three-class labelling problem. In addition, quantum transfer learning helps us to tackle the two \n",
      "In the past decade, anomaly detection has experienced an expanding attraction in satellite data analysis. Monitoring wildfire dynamics plays a substantial part in global land management, i.e., to detect and determine the expansion of such areas, estimate the deterioration of forest regions, and assist the intervention plan. In this article, we proposed an approach for Sentinel-2 scenes that detects anomalies in burned area contexts using a rank-ordered method on a single post-event image. We adopted a self-supervised paradigm in learning image representations by training a deep convolutional model to differentiate in a series of geometric transformations. Dirichlet distributions are selected as priors to characterize the variability of the random multinomial distribution in multispectral data. Dirichlet precision parameters are computed from observed data and are used to construct a ranking function that quantifies the degree of anomaly in data based on the softmax responses given by the trained classifier. We evaluated the performance of the proposed method through a cumulative effort of two remote sensing tasks, namely, open-set detection (i.e., test datasets contain classes unseen at the training time) and location separation (i.e., test datasets include images from distinct spatial location than the training images). The experiments were performed on three different datasets, BigEarthNet, and two actual burned area Sentinel-2 datasets from predisposed zones to fire events, Australia and Bolivia. We achieved in all test datasets state-of-the-art performance, considering the substantial and diversified types of natural anomalies in multispectral data.\n",
      "Coastline extraction by exploiting optical images is challenging during adverse weather conditions. This letter proposes coastline extraction from synthetic aperture radar (SAR) data. Since collecting in-situ data is expensive and not always possible, the Doppler parameter is used to delineate coastlines when neither in-situ data nor cloud-free optical images are available. We propose a novel coastline extraction method based on classic coastal dynamic variation, such as Doppler centroid (fDC), since coastline is static and has zero Doppler with respect to the dynamic sea-state. The results of the Doppler-based novel technique allow us to investigate the impact of natural hazards on coastline degradation. We compare the proposed method to state-of-the-art (SOA) coastline extraction methods based on polarimetric correlations and the reference method from Sentinel-2. The results show that using scattering from dual and cross-polarization for coastline extraction is more reliable than using co-polarization. Based on empirical distributions and using the constant false alarm rate (CFAR) method, the relevant threshold has been adapted to distinguish land and sea in an unsupervised manner. We compare the results of polarimetric and Sentinel-2 with Doppler-based coastline extraction, which emphasizes the accuracy of the proposed fDC method for extracting coastlines at full resolution.\n",
      "This paper aims to provide a deep neural network (DNN) considering the statistical properties of data for robust oneclass classification. To achieve that, we take advantage of the properties of Wavelet Scattering Transform (WST) to guide the DNN. WST is a translation-invariant image representation that retains high-frequency information for classification while being stable to rotation. The resulting stable and low-variance features make the clustering of data easier for DNN. The importance of WST in guiding the DNN for the classification of highly textured images is evaluated in terms of accuracy gain and robustness to outlier pollution. Superior robustness to both translation and rotation is also demonstrated. The method is not only evaluated in a standard computer vision dataset (CfAR10), but the use of largely invariant features allows for coping with the more challenging case of satellite imagery (EuroSAT).\n",
      "Deep learning techniques have attracted many interests in various fields, including Synthetic Aperture Radar (SAR). A few researches have extended the deep learning framework into the complex-domain to exploit the phase and amplitude of the Complex-Valued (CV)-SAR data. In this study, a complex-valued Convolutional AutoEncoder (CV-CAE) is de-veloped for CV-SAR data reconstruction from the lower resolution azimuth subaperture images. Finally, the performance of the CV-CAE is evaluated, in terms of the reconstruction quality and the coherency preservation, and showed that the CV-CAE is capable of reconstructing the CV-SAR images and preserving the coherency, with a remarkably small training dataset.\n",
      "This paper studies remote sensing image retrieval using kernel-based support vector data description (SVDD). We exploit deep SVDD, which is a well-known method for one-class classification, to recover the most relevant samples from the archive. To this end, a deep neural network (DNN) is jointly trained to map the data into a hypersphere of minimum volume in the latent space. It is expected that similar samples to the query are compressed inside of the hypersphere. The closest embedding to the center of the hypersphere is related to the most relevant sample to query. We enhance deep SVDD by injecting the statistical information of data to the DNN by means of additional terms in the cost function. The first enhancement method takes advantage of covariance regularization of batches of the training set to penalize unnecessary redundancy and minimize the correlation between the different dimensions of the embedding. The second method involves unlocking the hypersphere&#x0027;s predefined center while preventing network divergence during training. Therefore, two parameters are designed to control the importance of the drifting of the center and the importance of a fixed predefined center (convergence), respectively. This has been implemented by considering the average of batches of embedding in each iteration as the updated center. This pushes irrelevant samples away from query samples, making data clustering easier for the DNN. The performance of the proposed methods is evaluated on benchmark datasets. The source code is available at github.com/omid-ghozatlou/Query-by-Example-Using-SVDD\n",
      "Deep Learning methods have become ubiquitous tools in many Earth observation applications, delivering state-of-the-art results while proving to generalise for a variety of scenarios. One such domain concerns the Sentinel-2 satellite mission, which provides multi-spectral images in the form of 13 spectral bands, captured at 3 different spatial resolutions: 10m, 20m and 60m. This research aims to provide a super-resolution mechanism based on fully convolutional neural networks (CNNs) for up-sampling the low-resolution spectral bands of Sentinel-2 up to 10m spatial resolution. Our approach is centered on attaining good performance with respect to two main properties: consistency and synthesis. While the synthesis evaluation, also known as Walds protocol, has spoken for the performance of almost all previously introduced methods, the consistency property has been overlooked as a viable evaluation \n",
      "We address the question how to characterize spatio-temporal features in remote sensing images. The information bottleneck approach appears to be a promising concept.\n",
      "New trends in exploration and visualization are highly demanded in dealing with the massive amount of collected Earth Observation (EO) data. In this work, we propose an immersive visual analytic of EO data utilizing Virtual Reality technology. Precisely, we introduce the visualization of large scale SAR images in an immersive 3D environment and also introduce an interactive learning algorithm for the data clustering using Nonnegative Matrix Factorization framework. We conduct our experiments on a dataset of SAR images represented by different features and show that the proposed interactive clustering outperforms the others.\n",
      "<jats:p>&amp;lt;p&amp;gt;The European Copernicus Sentinel-1 SAR mission offers a unique chance to compare and analyse long time series of freely accessible SAR images with frequent coverage in the northern polar areas. In our case, during the ExtremeEarth project (H2020 grant agreement No 825258), we concentrated on a two-year analysis of multi-season ice cover categories around Belgica Bank in Greenland where we can easily use typical examples of SAR image targets ranging from snow-covered ice to melting ice surfaces as well as open sea scenes with ships and icebergs.&amp;lt;/p&amp;gt;&amp;lt;p&amp;gt;Our primary goal was to search for most powerful ice type classification algorithms exploiting the well-known characteristics of the Sentinel-1 satellites for SAR imaging in polar areas, both taken from ascending and descending orbit branches with C-band transmission and an incidence angle of about 39&amp;amp;#176;, a resulting ground sampling distance of 10 m or more, HH or HV polarization, and recorded in wide-swath or high-resolution modes as provided and distributed routinely by ESA&amp;amp;#180;s level-1 processing system as amplitude or complex-valued data.&amp;lt;/p&amp;gt;&amp;lt;p&amp;gt;In order to be compatible with established international ice type standards we used the Canadian MANICE semantic labelling system providing up to 10 different polar ice and polar target types.&amp;lt;/p&amp;gt;&amp;lt;p&amp;gt;Our algorithms are based on a patch-based classification approach, where we assigned the most probable primary label for each given square image patch with a size of 256&amp;amp;#215;256 pixels. This prevented us from creating many noise-related single-pixel categories.&amp;lt;/p&amp;gt;&amp;lt;p&amp;gt;Within the ExtremeEarth project, were generated semantic classification maps, topic representations, change maps, or physical scattering representations. A library of algorithms was created, among these algorithms we mention the following ones: classification based on Gabor filtering and SVMs, classification based on compression rates, variational auto-encoders for SAR feature learning, topic representations based on LDA, physical scattering representations based on LDA and CNNs, etc.&amp;lt;/p&amp;gt;&amp;lt;p&amp;gt;When the attempted image content classification based on current machine learning approaches, it turned out that we had to consider several important parameters such as typical applications, main semantic goals to be reached, applied processing algorithms, common types of data, available datasets and already predefined categories to be used, pixel-based versus patch-based data processing, single- and multi-labelling of image patches, confidence calculations and annotations, as well as attainable runtimes, implementation effort and risk - all depending on the target area characteristics. When it came to time series of target area images, we also had to consider the chances offered by short and long data sequences.&amp;lt;/p&amp;gt;&amp;lt;p&amp;gt;It turned out that this large number of aspects can be grouped together depending on the applied human expert supervision approach for semantic classification, namely unsupervised, self-supervised, semi-supervised, and supervised algorithms together with their individual training and testing strategies. In future, we want provide some justifications for next-generation remote sensing applications that require (near) real-time capabilities.&amp;lt;/p&amp;gt;</jats:p>\n",
      "The recognition or understanding of the scenes observed with a synthetic aperture radar (SAR) system requires a broader range of cues beyond the spatial context. These encompass but are not limited to the imaging geometry, imaging mode, properties of the Fourier spectrum of the images, or behavior of the polarimetric signatures. In this article, we propose a change of paradigm for explainability in data science for the case of SAR data to ground explainable artificial intelligence (XAI) for SAR. It aims to use explainable data transformations based on well-established models to generate inputs for AI methods, to provide knowledgeable feedback for the training process, and to learn or improve high-complexity unknown or unformalized models from the data.\n",
      "In this paper, we proposed to investigate unsupervised anomaly detection in Synthetic Aperture Radar (SAR) images. Our approach considers anomalies as abnormal patterns that deviate from their surroundings without prior knowledge of their characteristics. This method deals with the crucial problems related to the presence of speckle, the spatial correlation structures in SAR images, and the lack of annotated data to train a detection algorithm. Our proposed method aims to address these issues through a self-supervised learning algorithm. First, we propose to mitigate the SAR speckle through the deep learning SAR2SAR algorithm. We then develop an Adversarial Autoencoder (AAE) to reconstruct anomaly-free SAR images from despeckled data taking into account potential spatial correlation structures. Finally, a change detection processing step is applied between the input and the output to detect anomalies \n",
      "<jats:p>In the first year of my PhD project, as the fifteenth Early Stage Researcher (ESR) of the MENELAOS-NT project, I have focused on two objectives of my thesis. In the first objective, I have exploited semantic data mining techniques for latent information discovery from various Earth Observation images. In the second goal and as the continuity of the first aspect, I have studied complex-valued deep architectures for Synthetic Aperture Radar (SAR) data processing in order to utilize both the amplitude and phase information in SAR images.</jats:p>\n",
      "This paper proposes an anomaly detection method for SAR imagery based on deep learning. It does not require ground truth of anomalies, which addresses a recurrent problem in remote sensing: the lack of labeled data to train neural networks. The proposed model combines an adversarial autoencoder followed by a statistical change detector based on the covariance matrix. A despeckling step is first performed, which allows to filter the speckle noise and to significantly improve the detection performances.\n",
      "Ce papier propose une methode de detection danomalies pour limagerie SAR basee sur lapprentissage profond. Elle ne necessite pas de verite terrain des anomalies, ce qui repond a un probleme recurrent en teledetection: le manque de donnees annotees pour entrainer les reseaux de neurones. Le modele propose combine un adversarial autoencoder suivi dun detecteur statistique de changement base sur la matrice de covariance. Une etape de despeckling est prealablement effectuee, ce qui permet de filtrer le bruit de speckle et dameliorer significativement les performances de detection. AbstractThis paper proposes an anomaly detection method for SAR imagery based on deep learning. It does not require ground truth of anomalies, which addresses a recurrent problem in remote sensing: the lack of labeled data to train neural networks. The proposed model combines an adversarial autoencoder followed by a statistical change detector based on the covariance matrix. A despeckling step is first performed, which allows to filter the speckle noise and to significantly improve the detection performances.\n",
      "Dimensionality reduction for visualization is widely used in visual data mining where the data is represented by high dimensional features. However, this leads to have an unbalanced and occluded distribution of visual data in display space giving rise to difficulties in browsing images. In this paper, we propose an approach to the visualization of images in a 3D display space in such a way that:(1) images are not occluded and the provided space is used efficiently;(2) similar images are positioned close together. An immersive virtual environment is employed as a 3D display space. Experiments are performed on an optical image dataset represented by color features. A library of dimensionality reduction is employed to reduce the dimensionality to 3D. The results confirm that the proposed technique can be used in immersive visual data mining for exploring and browsing large-scale datasets.\n",
      "This paper aims at defining an analysis model for high resolution spotlight SAR imagery, which is able to integrate the radiometric, geometric and texture properties of the SAR data, in order to facilitate large data-base queries by informational content indexing of the images. Each SAR scene is described by a number of parameters computed based on Short-Time Fourier Transform. A phase correction algorithm is applied to the spotlight images prior to feature extraction. The classification is done using a Bayesian SVM classifier. The method allowed for the recognition of more than one hundred targets and structures in the scenes.\n",
      "The digital and sensing technologies, ie Big Data, are revolutionary developments massively impacting the Earth Observation (EO) domains. While, Artificial Intelligence (AI) is providing now the methods to valorize the Big Data. Today the accepted trends assume more data we analyze, the smarter the analysis paradigms will perform. However, the data deluge, diversity, or the broad range of specialized applications are posing new major challenges. From the perspective of the data valorization and applications the multi-mission and related data use for global applications still need more efforts. From the methodological side the challenges are related to, the reproducibility, the trustworthiness, physics awareness, and over all, the explainability of the methods and results.\n",
      "Scene classification is one of the most important tasks in the remote sensing field. In general, remotely sensed data comprises targets of different nature with many detailed classes. Therefore, the classification of patches in a satellite scene is a challenging issue. To address the problem, the preferred alternative is to transform to polar coordinates and analyze angular distances. Prior works have so far considered angular distances between points, while ignoring that the target class is not a point, but a distribution. In this paper, we take advantage of this critical fact by using a point-to-probability distribution measure rather than an norm. In this paper, two similarity measures (Euclidean and Mahalanobis) in two different feature space are experimentally investigated through some remote sensing datasets.\n",
      "In the context of fast growing data archives, with continuous changes in volume and diversity, information mining has proven to be a difficult, yet highly recommended task. The first and perhaps the most important part of the process is data representation for efficient and reliable image classification. This paper is presenting a new approach for describing the content of Earth Observation Very High Resolution images, by comparison with traditional representations based on specific features. The benefit of data compression is exploited in order to express the scene content in terms of dictionaries. The image is represented as a distribution of recurrent patterns, removing redundant information, but keeping all the explicit features, like spectral, texture and context. Further, a data domain analysis is performed using Support Vector Machine aiming to compare the influence of data representation to semantic scene annotation. WorldView2 data and a reference map are used for algorithm evaluation.\n",
      "As Deep Learning attracts Earth Observation (EO) community's interest, the challenge to derive explainable, actionable information creates a bottleneck in EO models' development. Computer Vision proved that effective results of the DL algorithms imply a considerable amount of training data sets. This is not the case in EO where images are characterized by a broad variety of sensor data, ranging from multispectral to Synthetic Aperture Radar (SAR) with variable number of spectral bands, polarization or spatial resolution. In this paper we present effective methodologies for fast training with reduced data sets of simple deep neural networks, while preserving the similar performance of state of the art methods. The hybrid solutions we provide imply the reduction of input data dimension in a convolutional neural network. We replaced dataset's patches with histograms of pixel intensity, Bag-of-Words or down-sampled images. Following the proposed approaches, the training time and the dataset size are significantly reduced, while the performance of classification is preserved. These optimized implementations enable the deployment of lightweight deep learning models for real time processing tasks able to exhibit accurate results for instantce, a disaster management scenerio. We demonstrated the computational efficiency of these approaches on various, complex data, both multispectral and SAR, with different resolutions.\n",
      "Deep learning models have achieved remarkable success in many different fields and attracted many interests. Several researchers attempted to apply deep learning models to Synthetic Aperture Radar (SAR) data processing, but it did not have the same breakthrough as the other fields, including optical remote sensing. SAR data are in complex domain by nature and processing them with Real-Valued (RV) networks neglects the phase component which conveys important and distinctive information. A Complex-Valued (CV) end-to-end deep network is developed in this study for the reconstruction and classification of CV-SAR data. Azimuth subaperture decomposition is utilized to incorporate physics-aware attributes of the CV-SAR into the deep model. Moreover, the correlation coefficient amplitude (Coherence) of the CV-SAR images depends on the SAR system characteristics and physical properties of the target. This coherency should be considered and preserved in the processing chain of the CV-SAR data. The coherency preservation of the CV deep networks for CV-SAR images, which is mostly neglected in the literature, is evaluated in this study. Furthermore, a large-scale CV-SAR annotated dataset for the evaluation of the CV deep networks is lacking. A semantically annotated CV-SAR dataset from Sentinel-1 Single Look Complex StripMap mode data (S1SLC&#x005F;CVDL dataset) is developed and introduced in this study. The experimental analysis demonstrated the better performance of the developed CV deep network for CV-SAR data classification and reconstruction in comparison to the equivalent RV model and more complicated RV architectures, as well as its coherency preservation and physics-aware capability.\n",
      "<jats:p>With more and more SAR applications, the demand for enhanced high-quality SAR images has increased considerably. However, high-quality SAR images entail high costs, due to the limitations of current SAR devices and their image processing resources. To improve the quality of SAR images and to reduce the costs of their generation, we propose a Dialectical Generative Adversarial Network (Dialectical GAN) to generate high-quality SAR images. This method is based on the analysis of hierarchical SAR information and the “dialectical” structure of GAN frameworks. As a demonstration, a typical example will be shown, where a low-resolution SAR image (e.g., a Sentinel-1 image) with large ground coverage is translated into a high-resolution SAR image (e.g., a TerraSAR-X image). A new algorithm is proposed based on a network framework by combining conditional WGAN-GP (Wasserstein Generative Adversarial Network—Gradient Penalty) loss functions and Spatial Gram matrices under the rule of dialectics. Experimental results show that the SAR image translation works very well when we compare the results of our proposed method with the selected traditional methods.</jats:p>\n",
      "The techniques based on fractals show promising results in the field of image understanding and visualization of high complexity data. In the aim to give an introduction to the theory of fractals the following topics will be summarised in this paper: the definition and analysis of fractals based on self-similarity and self-affinity behaviours, definitions for fractal dimension, fractal synthesis, multiresolution approach in the analysis and synthesis of fractals, fractals and hierarchic stochastic processes. The derived techniques with applications in geo-information processing and understanding will be underlined: generation of synthetic DEMs, fractal resampling of actual DEMs, algorithms for computation of the fractal dimension, unknown information modelling and data fusion, multiresolution synthesis and analysis of fractal images, multiresolution analysis and fractal dimension estimation. The paper presents also several experiments using fractals to generate accurate models for landforms and cover types, generation of synthetic images for model based picture processing, and image processing techniques for the analysis of remotely sensed images. The techniques have been applied both for optical and Synthetic Aperture Radar (SAR) image interpretation.\n",
      "Optical remote sensing instruments accumulate abundant data from across all Earth's land surfaces, making it possible both to understand the effects of climate change and to monitor, investigate and manage ground-level events in detail. Processing data using resources located near on-board satellite sensors can bring major benefits in terms of minimizing analysis time and quickly initiating active actions in critical situations. In satellite missions, long-term production on-board algorithms may encounter unexplored samples, i.e., abnormal ground-level events, and need to be able to discriminate and take the correct action. In this matter, the authors present a field programmable gate array (FPGA)-based solution for natural anomaly detection in multispectral imagery using deep convolutional neural networks. The effects of weather-induced hazards and natural disasters, considered anomalies in this sense, are \n",
      "Quantum machine learning is the synergy between quantum computing resources and machine learning methods. In particular, quantum machine learning refers to quantum algorithms promising to compute some machine learning methods and optimization problems (polynomially) faster than conventional algorithms. Quantum algorithms for computing any problems are algorithms using a quantum computer. This work (I) identifies intractable real-world problems of practical significance which can be computed efficiently on a quantum computer, (II) provides an encoding strategy of real-world, large scale problems in a small-scale quantum computer, and (III) invents so-called hybrid classical-quantum (HPC+nQC) learning networks and analyses their performance in comparison to conventional machine (deep) learning methods in order to gain quantum advantage as early and efficiently as possible; here, HPC+nQC is referred to as high performance computing and n quantum computers, where n stands for n different types of quantum computers.\n",
      "Anomaly detection in Synthetic Aperture Radar (SAR) images is an important topic. However, the task is challenging due to the scarcity of anomalous samples and the lack of annotated data, which has led most algorithms in this field to be unsupervised. To address the issue, this article proposes a new loss that adds prior information. One of the main functions of an autoencoder is to reconstruct the input data as accurately as possible after encoding them in a latent vector. The proposed loss function guides the network using the Reed-Xiaoli (RX) detector and replaces any pixels in the input data deemed too abnormal with normal surrounding values. This approach incorporates a priori information in addition to the assumption that anomalies are largely under-represented compared to the rest of the image. An ablation study demonstrates that the proposed loss function improves detection performance.\n",
      "The article aims at presenting the most recent developments and trends in information extraction from Synthetic Aperture Radar SAR data.\n",
      "Spaceborne synthetic aperture radar (SAR) can provide accurate images of the ocean surface roughness day-or-night in nearly all weather conditions, being an unique asset for many geophysical applications. Considering the huge amount of data daily acquired by satellites, automated techniques for physical features extraction are needed. Even if supervised deep learning methods attain state-of-the-art results, they require a great amount of labelled data, which are difficult and excessively expensive to acquire for ocean SAR imagery. To this end, we use the subaperture decomposition (SD) algorithm to enhance the unsupervised learning retrieval on the ocean surface, empowering ocean researchers to search into large ocean databases. We empirically prove that SD improves the retrieval precision with over 20% for an unsupervised transformer auto-encoder network. Moreover, we show that SD brings an important performance boost when Doppler centroid images are used as input data, leading the way to new unsupervised physics guided retrieval algorithms.\n",
      "The recognition and classification of urban structures from SAR observations is a particularly complex task. In this article we present a new concept, aiming at the accurate and detailed classification of the city scenes observed with metric resolution SAR sensors.SAR images of build-up areas at resolution of 2-3 meters are characterized by strong patterns induced by the geometry of buildings and the phenomenology of scattering of the radar signals. Thus, resulting in high complexity images.The accuracy of image interpretation relies on the descriptive power of the low level image information extraction. The article presents a method based on the Bayesian concepts. A hierachical 3 layers model is used for the SAR observations. The first layer describes the speckle effect as a Gamma distribution. the second, the cross-section, is modeled as Gibbs Random Field (GRF), the third layer the parameters of the Gibbs random field is considered a Jeffrey's prior. The GRF describes the cross-section structures induced by the geometry of the buildings. The model is non-stationary, its parameters adapt locally to the image structures.\n",
      "The pavement distress measurement is a crucial aspect in guaranteeing the safety of transportation infrastructure. In this regard, we introduce a novel and cost-effective multi-sensor approach for pavement segmentation during low-light night conditions. By utilizing the low-cost Azure Kinect multi-sensor system, we generated a multi-sensor dataset that encompasses aligned IR, RGB, and depth images. Then we carried out the data annotation process on the RGB images. A total of 11,343 manual annotations were meticulously made on 791 images, which were randomly selected from a collection of 96,891 frames. Subsequently, four different deep learning-based image segmentation models were analyzed both quantitatively and qualitatively. The results indicated that the segmentation performance on the IR dataset outperformed that of the RGB dataset. The model with the highest mIoU (mean Intersection over Union) of 0.7169 was ConvNext when trained on the IR dataset. Furthermore, we proposed the use of relative height for evaluating the severity of pavement distress. On the aligned depth map, the relative height was calculated using the depth data from the corresponding pavement distress area. Additionally, a quantitative comparison between manual annotations and the results obtained through deep learning revealed that the latter was more effective in identifying more severe forms of pavement distress. Through this study, we established the feasibility of collecting pavement distress data during nighttime using a low-cost multi-sensor system.\n",
      "Multispectral (MS) remote sensing (RS) images are of great interest for various applications, yet, quite often, a MS product exhibits one or more noisy bands, strip lines or even missing bands which leads to decreased confidence in the information it contains. Meeting this challenge, the current paper proposes a UNet based neural network architecture to reconstruct a spectral band. The worst-case scenario is considered, that of a missing band, the reconstruction being performed based on the available bands. Besides the comparison with state of the art methods, both a qualitative and quantitative analysis is full-filled considering several metrics: Root-mean-square error (RMSE), Structural similarity index (SSIM), Signal to reconstruction error (SRE), Peak signal to noise ratio (PSNR) and Spectral angle mapper (SAM). The experiments focused on Sentinel-2 (S2) open data within the Copernicus programme. Various patterns of urban areas, agricultural regions, regions from North Pole or Kyiv, Ukraine are included in our dataset to prove the efficiency of band reconstruction regardless landcover diversity.\n",
      "Recent studies revealed that the time-domain synthetic aperture radar (SAR) processors are more appropriate for future innovative SAR missions (e.g., ROSE-L, Harmony) not only due to their ability to form the SAR image on user-defined regions of interest (ROIs) but also for the straightforward accommodation to configurations wherein the azimuth spectrum folding occurs (e.g., TOPSAR). In this letter, we propose an accelerated Back-Projection (BP) SAR processor working in conjunction with a fast routine for generating the elliptical grid (laying on arbitrary planes) necessary for the sub-aperture based BP speed-up. The proposed workflow forms all the sub-aperture SAR images on the same coarse elliptical grid which before the coarse-to-fine grid interpolation are translated in the azimuth base-band. The fine-resolution SAR image is obtained by coherently integrating the sub-aperture images together with the concatenation of the corresponding fraction from the azimuth spectrum (unfolding) making the Single Look Complex (SLC) outcome proper for further Doppler-based processing. Our validation experiments indicate that the most suitable family of imaging planes is the one containing the receiver (fan-like grid) on bistatic scenarios with relatively large transmitter-receiver separation. The processing gain has been enhanced by one order of magnitude under low amplitude and phase distortions.\n",
      "Sentinel-2 image super-resolution (SR) has proven advantageous in multiple data analysis pipelines, leading to a more comprehensive assessment of different environment-related metrics. This research aims to provide a method for super-resolving the 60-m bands provided by Sentinel-2 up to 10-m spatial resolution, using Gaussian process regression (GPR). While common GPR methods directly operate on raw data using carefully designed kernels, we propose a convolutional neural network (CNN)-based feature extraction kernel to directly process the input 10-m patches, applied in constructing the elements of the integrated covariance matrices. For each scene, a small number of training patches are sampled to optimize the CNN parameters and to construct the predictive mean function, the latter being further used for predicting super-resolved pixels for new input areas. We prove that our method is a reliable SR mechanism by assessing its performance both quantitatively, using metrics against other methods from literature, and qualitatively, through visual analysis of the results.\n",
      "Advanced Differential SAR Interferometry and specifically Persistent Scatterers (PS) Interferometry have become popular techniques since they offer the possibility of large-scale analysis and monitoring of Earth's surface. In this work, we address the exploitation of widely used interferometric phase filtering method, SquueSAR, for the PS detection within a two-step processing scheme based on a sequence of low and high-resolution processing. We propose a modification of the iterative approach proposed in [1], in order to avoid phase shifts. The effects of the modification quantify in a significan improvement of the detection performances, verified on both simulated an real data.\n",
      "Recent advances in Synthetic Aperture Radar (SAR) sensors have enabled the acquisition of very high-resolution images with wide swaths, large bandwidth and in multiple polarization channels. As a result of the significant increase of SAR data size, an effective compression of the acquired data is of paramount importance. However, conventional data compression methods demonstrate limited effectiveness when applied to SAR data. In order to tackle this problem, in this study, a Complex-Valued (CV) end-to-end deep learning-based architecture based on convolutional autoencoders is proposed to compress Single Look Complex (SLC) SAR data. By relying on dual polarization SAR data, one of the polarization channels of the data is used as the side information to assist the reconstruction of the compressed channel with lower data loss. The obtained results demonstrate the remarkable potential and capability \n",
      "In this paper, an efficient routine for elliptical grid generation employed for the back-projection sped-up is proposed. The grid accommodates the particular bistatic setup formed by a space-born transmitter (Sentinel-l) and a ground-based stationary receiver (COBIS). Herein, the adapted elliptical grid is designed such that the computational complexity of the standard back-projection algorithm used for SAR image formation decreases. Specifically, the computational load is mitigated by reducing the density of the points in the cross-range direction. Such an elliptical grid leads to the formation of the SAR image in any arbitrary plane, preserving the rangeazimuth (cross-range) spectrum of the final SAR image, making it suitable for further Doppler processing algorithms (e.g., common band selection in SAR interferometry).\n",
      "Sea ice is a crucial component of the Earths climate system and is highly sensitive to changes in temperature and atmospheric conditions. Accurate and timely measurement of sea ice parameters is important for understanding and predicting the impacts of climate change. Nevertheless, the amount of satellite data acquired over ice areas is huge, making the subjective measurements ineffective. Therefore, automated algorithms must be used in order to fully exploit the continuous data feeds coming from satellites. In this paper, we present a novel approach for sea ice segmentation based on SAR satellite imagery using hybrid convolutional transformer (ConvTr) networks. We show that our approach outperforms classical convolutional networks, while being considerably more efficient than pure transformer models. ConvTr obtained a mean intersection over union (mIoU) of 63.68% on the AI4Arctic data set, assuming \n",
      "In this paper we present a brief survey of the ant based multi-agent exploration algorithms and a performance comparison of these algorithms obtained by analyzing them in a variety of scenarios.\n"
     ]
    }
   ],
   "source": [
    "print(authors_texts[829])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "548fe614-5925-48a2-bd17-1a6efd289e38",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_md')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aa60bec-db7b-4a26-a136-daddba45c426",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "0425d20e-4646-4d08-b0a1-35b791136696",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('distributed systems', 6.803552805357417e-07)\n",
      "('opportunistic networks', 2.6617590155451938e-06)\n",
      "('mobile device', 6.649967853563537e-06)\n",
      "('data', 8.972991427147693e-06)\n",
      "('paper propose', 1.0452489146063027e-05)\n",
      "('network traffic', 1.6710213235148208e-05)\n",
      "('time information', 2.3021153053003897e-05)\n",
      "('cloud computing', 3.764742654793187e-05)\n",
      "('system architectures', 5.6103168632979394e-05)\n",
      "('scheduling algorithm', 5.6495559694195836e-05)\n"
     ]
    }
   ],
   "source": [
    "# extract keywords\n",
    "kw_extractor = yake.KeywordExtractor()\n",
    "max_ngram = 2\n",
    "deduplication_threshold = 0.2\n",
    "keywords_nr = 10\n",
    "custom_kw_extractor = yake.KeywordExtractor(lan=\"en\", n=max_ngram, dedupLim=deduplication_threshold, top=keywords_nr, features=None)\n",
    "\n",
    "text = authors_texts[534]\n",
    "doc = nlp(text)\n",
    "remove_pos = ['ADV', 'PRON', 'CCONJ', 'PUNCT', 'PART', 'DET', 'SPACE', 'NUM', 'SYM', 'PROPN']\n",
    "stop_words = ['paper', 'present', 'propose']\n",
    "transformed_text = ' '.join([token.text.lower() for token in doc if token.pos_ not in remove_pos and token.is_alpha])\n",
    "\n",
    "keywords = custom_kw_extractor.extract_keywords(transformed_text)\n",
    "for kw in keywords:\n",
    "    print(kw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9658cd5e-00a0-4a18-afdf-e0350e828933",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "829\n",
      "\n",
      "1672\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[26], line 17\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28mprint\u001b[39m(author_id)\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m text \u001b[38;5;129;01min\u001b[39;00m texts:\n\u001b[0;32m     14\u001b[0m     \u001b[38;5;66;03m# doc = nlp(text)\u001b[39;00m\n\u001b[0;32m     15\u001b[0m     \u001b[38;5;66;03m# print(doc.ents)\u001b[39;00m\n\u001b[1;32m---> 17\u001b[0m     keywords \u001b[38;5;241m=\u001b[39m \u001b[43mcustom_kw_extractor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mextract_keywords\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     18\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m kw \u001b[38;5;129;01min\u001b[39;00m keywords:\n\u001b[0;32m     19\u001b[0m         \u001b[38;5;28mprint\u001b[39m(kw)\n",
      "File \u001b[1;32mc:\\users\\ana_maria.nastase\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\yake\\yake.py:64\u001b[0m, in \u001b[0;36mKeywordExtractor.extract_keywords\u001b[1;34m(self, text)\u001b[0m\n\u001b[0;32m     61\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m []\n\u001b[0;32m     63\u001b[0m text \u001b[38;5;241m=\u001b[39m text\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m---> 64\u001b[0m dc \u001b[38;5;241m=\u001b[39m \u001b[43mDataCore\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstopword_set\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstopword_set\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwindowsSize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwindowsSize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     65\u001b[0m dc\u001b[38;5;241m.\u001b[39mbuild_single_terms_features(features\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfeatures)\n\u001b[0;32m     66\u001b[0m dc\u001b[38;5;241m.\u001b[39mbuild_mult_terms_features(features\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfeatures)\n",
      "File \u001b[1;32mc:\\users\\ana_maria.nastase\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\yake\\datarepresentation.py:30\u001b[0m, in \u001b[0;36mDataCore.__init__\u001b[1;34m(self, text, stopword_set, windowsSize, n, tagsToDiscard, exclude)\u001b[0m\n\u001b[0;32m     28\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfreq_ns[i\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.\u001b[39m\n\u001b[0;32m     29\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstopword_set \u001b[38;5;241m=\u001b[39m stopword_set\n\u001b[1;32m---> 30\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_build\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwindowsSize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\users\\ana_maria.nastase\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\yake\\datarepresentation.py:50\u001b[0m, in \u001b[0;36mDataCore._build\u001b[1;34m(self, text, windowsSize, n)\u001b[0m\n\u001b[0;32m     48\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_build\u001b[39m(\u001b[38;5;28mself\u001b[39m, text, windowsSize, n):\n\u001b[0;32m     49\u001b[0m     text \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpre_filter(text)\n\u001b[1;32m---> 50\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msentences_str \u001b[38;5;241m=\u001b[39m [ [w \u001b[38;5;28;01mfor\u001b[39;00m w \u001b[38;5;129;01min\u001b[39;00m split_contractions(web_tokenizer(s)) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (w\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(w) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(w) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m s \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(split_multi(text)) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(s\u001b[38;5;241m.\u001b[39mstrip()) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m     51\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnumber_of_sentences \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msentences_str)\n\u001b[0;32m     52\u001b[0m     pos_text \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n",
      "File \u001b[1;32mc:\\users\\ana_maria.nastase\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\yake\\datarepresentation.py:50\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     48\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_build\u001b[39m(\u001b[38;5;28mself\u001b[39m, text, windowsSize, n):\n\u001b[0;32m     49\u001b[0m     text \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpre_filter(text)\n\u001b[1;32m---> 50\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msentences_str \u001b[38;5;241m=\u001b[39m [ [w \u001b[38;5;28;01mfor\u001b[39;00m w \u001b[38;5;129;01min\u001b[39;00m split_contractions(\u001b[43mweb_tokenizer\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m)\u001b[49m) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (w\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(w) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(w) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m s \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(split_multi(text)) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(s\u001b[38;5;241m.\u001b[39mstrip()) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m     51\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnumber_of_sentences \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msentences_str)\n\u001b[0;32m     52\u001b[0m     pos_text \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n",
      "File \u001b[1;32mc:\\users\\ana_maria.nastase\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\segtok\\tokenizer.py:306\u001b[0m, in \u001b[0;36mweb_tokenizer\u001b[1;34m(sentence)\u001b[0m\n\u001b[0;32m    280\u001b[0m \u001b[38;5;129m@_matches\u001b[39m(\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[0;32m    281\u001b[0m \u001b[38;5;124m    (?<=^|[\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124ms<\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m(\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124m[\u001b[39m\u001b[38;5;124m{\u001b[39m\u001b[38;5;124m])            # visual border\u001b[39m\n\u001b[0;32m    282\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    300\u001b[0m \u001b[38;5;124m    \u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m)\n\u001b[0;32m    301\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mweb_tokenizer\u001b[39m(sentence):\n\u001b[0;32m    302\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    303\u001b[0m \u001b[38;5;124;03m    The web tokenizer works like the :func:`word_tokenizer`, but does not split URIs or\u001b[39;00m\n\u001b[0;32m    304\u001b[0m \u001b[38;5;124;03m    e-mail addresses. It also un-escapes all escape sequences (except in URIs or email addresses).\u001b[39;00m\n\u001b[0;32m    305\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 306\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [token \u001b[38;5;28;01mfor\u001b[39;00m i, span \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(web_tokenizer\u001b[38;5;241m.\u001b[39msplit(sentence))\n\u001b[0;32m    307\u001b[0m             \u001b[38;5;28;01mfor\u001b[39;00m token \u001b[38;5;129;01min\u001b[39;00m ((span,) \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m%\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m word_tokenizer(unescape(span)))]\n",
      "File \u001b[1;32mc:\\users\\ana_maria.nastase\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\segtok\\tokenizer.py:307\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    280\u001b[0m \u001b[38;5;129m@_matches\u001b[39m(\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[0;32m    281\u001b[0m \u001b[38;5;124m    (?<=^|[\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124ms<\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m(\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124m[\u001b[39m\u001b[38;5;124m{\u001b[39m\u001b[38;5;124m])            # visual border\u001b[39m\n\u001b[0;32m    282\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    300\u001b[0m \u001b[38;5;124m    \u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m)\n\u001b[0;32m    301\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mweb_tokenizer\u001b[39m(sentence):\n\u001b[0;32m    302\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    303\u001b[0m \u001b[38;5;124;03m    The web tokenizer works like the :func:`word_tokenizer`, but does not split URIs or\u001b[39;00m\n\u001b[0;32m    304\u001b[0m \u001b[38;5;124;03m    e-mail addresses. It also un-escapes all escape sequences (except in URIs or email addresses).\u001b[39;00m\n\u001b[0;32m    305\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m    306\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [token \u001b[38;5;28;01mfor\u001b[39;00m i, span \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(web_tokenizer\u001b[38;5;241m.\u001b[39msplit(sentence))\n\u001b[1;32m--> 307\u001b[0m             \u001b[38;5;28;01mfor\u001b[39;00m token \u001b[38;5;129;01min\u001b[39;00m ((span,) \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m%\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[43mword_tokenizer\u001b[49m\u001b[43m(\u001b[49m\u001b[43munescape\u001b[49m\u001b[43m(\u001b[49m\u001b[43mspan\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m)]\n",
      "File \u001b[1;32mc:\\users\\ana_maria.nastase\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\segtok\\tokenizer.py:237\u001b[0m, in \u001b[0;36mword_tokenizer\u001b[1;34m(sentence)\u001b[0m\n\u001b[0;32m    211\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    212\u001b[0m \u001b[38;5;124;03mThis tokenizer extends the alphanumeric :func:`symbol_tokenizer` by splitting fewer cases:\u001b[39;00m\n\u001b[0;32m    213\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    234\u001b[0m \u001b[38;5;124;03m6. Subscript digits are attached if prefixed with letters that look like a chemical formula.\u001b[39;00m\n\u001b[0;32m    235\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    236\u001b[0m pruned \u001b[38;5;241m=\u001b[39m HYPHENATED_LINEBREAK\u001b[38;5;241m.\u001b[39msub(\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124m1\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124m2\u001b[39m\u001b[38;5;124m'\u001b[39m, sentence)\n\u001b[1;32m--> 237\u001b[0m tokens \u001b[38;5;241m=\u001b[39m [token \u001b[38;5;28;01mfor\u001b[39;00m span \u001b[38;5;129;01min\u001b[39;00m space_tokenizer(pruned) \u001b[38;5;28;01mfor\u001b[39;00m\n\u001b[0;32m    238\u001b[0m           token \u001b[38;5;129;01min\u001b[39;00m word_tokenizer\u001b[38;5;241m.\u001b[39msplit(span) \u001b[38;5;28;01mif\u001b[39;00m token]\n\u001b[0;32m    240\u001b[0m \u001b[38;5;66;03m# splice the sentence terminal off the last word/token if it has any at its borders\u001b[39;00m\n\u001b[0;32m    241\u001b[0m \u001b[38;5;66;03m# only look for the sentence terminal in the last three tokens\u001b[39;00m\n\u001b[0;32m    242\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m idx, word \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mreversed\u001b[39m(tokens[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m3\u001b[39m:]), \u001b[38;5;241m1\u001b[39m):\n",
      "File \u001b[1;32mc:\\users\\ana_maria.nastase\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\segtok\\tokenizer.py:238\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    211\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    212\u001b[0m \u001b[38;5;124;03mThis tokenizer extends the alphanumeric :func:`symbol_tokenizer` by splitting fewer cases:\u001b[39;00m\n\u001b[0;32m    213\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    234\u001b[0m \u001b[38;5;124;03m6. Subscript digits are attached if prefixed with letters that look like a chemical formula.\u001b[39;00m\n\u001b[0;32m    235\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    236\u001b[0m pruned \u001b[38;5;241m=\u001b[39m HYPHENATED_LINEBREAK\u001b[38;5;241m.\u001b[39msub(\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124m1\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124m2\u001b[39m\u001b[38;5;124m'\u001b[39m, sentence)\n\u001b[0;32m    237\u001b[0m tokens \u001b[38;5;241m=\u001b[39m [token \u001b[38;5;28;01mfor\u001b[39;00m span \u001b[38;5;129;01min\u001b[39;00m space_tokenizer(pruned) \u001b[38;5;28;01mfor\u001b[39;00m\n\u001b[1;32m--> 238\u001b[0m           token \u001b[38;5;129;01min\u001b[39;00m \u001b[43mword_tokenizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mspan\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m token]\n\u001b[0;32m    240\u001b[0m \u001b[38;5;66;03m# splice the sentence terminal off the last word/token if it has any at its borders\u001b[39;00m\n\u001b[0;32m    241\u001b[0m \u001b[38;5;66;03m# only look for the sentence terminal in the last three tokens\u001b[39;00m\n\u001b[0;32m    242\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m idx, word \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mreversed\u001b[39m(tokens[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m3\u001b[39m:]), \u001b[38;5;241m1\u001b[39m):\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# extract keywords\n",
    "kw_extractor = yake.KeywordExtractor()\n",
    "language = \"en\"\n",
    "max_ngram_size = 3\n",
    "deduplication_threshold = 0.9\n",
    "numOfKeywords = 100\n",
    "custom_kw_extractor = yake.KeywordExtractor(lan=language, n=max_ngram_size, dedupLim=deduplication_threshold, top=numOfKeywords, features=None)\n",
    "        \n",
    "for author_id in authors_texts:\n",
    "    texts = authors_texts[author_id]\n",
    "    print(author_id)\n",
    "    \n",
    "    for text in texts:\n",
    "        # doc = nlp(text)\n",
    "        # print(doc.ents)\n",
    "\n",
    "        keywords = custom_kw_extractor.extract_keywords(text)\n",
    "        for kw in keywords:\n",
    "            print(kw)\n",
    "\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eae95ec-4c63-4107-9ebc-8cf8fb3e7221",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
